{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the template I uploaded yesterday, please update your current template as follows:\n",
    "\n",
    "1) include all possible wrangling functions, including t-tests, chi-squared, anova, correlation heatmaps, normality tests (one of them), missing value solutions, transformations etc.Ã‚Â\n",
    "\n",
    "2) include all classification and regression algorithms\n",
    "\n",
    "3) FS: feature selection algorithms (I included RFFS, RFE, MI and PCA but you can add only RFFS as for me, it works good).Ã‚Â\n",
    "\n",
    "4) CV: cross validation approaches (include stratified K-fold definitely)\n",
    "\n",
    "5) REG: regularization (lasso, ridge regression) methods (include Lasso definitely).\n",
    "\n",
    "6) Include methods for addressing class imbalance\n",
    "\n",
    "7) Include any other helper/logistic function you want to add\n",
    "\n",
    "8) Include function for executing ML (classification) without FS, REG and CV. Output: Accuracy, precision (+ve), recall (+ve), AUC, ROC curve\n",
    "\n",
    "9) Include function for executing ML (classification) with FS and without REG and CV. Output: Accuracy, precision (+ve), recall (+ve), AUC, ROC curve\n",
    "\n",
    "10) Include function for executing ML (classification) with REG and without FS and CV. Output: Accuracy, precision (+ve), recall (+ve), AUC, ROC curve\n",
    "\n",
    "11) Include function for executing ML (classification) with CV and without FS and REG. Output: Accuracy, precision (+ve), recall (+ve), AUC, ROC curve\n",
    "\n",
    "12) Include function for executing ML (classification) with CV and with FS and with REG. Output: Accuracy, precision (+ve), recall (+ve), AUC, ROC curve\n",
    "\n",
    "NB: 8-12 above can be merged as a single function as well\n",
    "\n",
    "Output Required:\n",
    "\n",
    "1) Completed template 2) Completed thorough wrangling for all three datasets and include interpretations. 3) Filled up Results.Template excel attached. 4) A detailed commentary on the results regarding performance comparison of algorithms and the effect of REG, CV, FS etc. You can also use different methods of CV, REG and FS to add breadth to your assignment and for bonus marks. Record all results in the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#import basic modules\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import seaborn as sns\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt        \n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#import feature selection modules\n",
    "from sklearn.feature_selection import mutual_info_classif,RFE,RFECV\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "#import classification modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# import regression modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#import split methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#import performance scores\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# example of grid searching key hyperparametres for logistic regression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC   \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sb.set(color_codes=True, font_scale=1.2)\n",
    "\n",
    "# need to install xgboost first\n",
    "# pip install xgboost in conda environment\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except:\n",
    "    print(\"Failed to import xgboost, make sure you have xgboost installed\")\n",
    "    print(\"Use following command to install it: pip install xgboost\")\n",
    "    XGBClassifier = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except:\n",
    "    print(\"Failed to import lightgbm, make sure that you have lightgbm installed\")\n",
    "    print(\"Use following command to install it: conda install -c conda-forge lightgbm\")\n",
    "    lgb = None\n",
    "\n",
    "# Load Data\n",
    "def load_data(file_name):\n",
    "    def readcsv(file_name):\n",
    "        return pd.read_csv(file_name)\n",
    "    def readexcel(file_name):\n",
    "        return pd.read_excel(file_name)\n",
    "    def readjson(file_name):\n",
    "        return pd.read_json(file_name)\n",
    "    func_map = {\n",
    "        \"csv\": readcsv,\n",
    "        \"xls\": readexcel,\n",
    "        \"xlsx\": readexcel,\n",
    "        \"txt\": readcsv,\n",
    "        \"json\": readjson\n",
    "    }\n",
    "    \n",
    "    # default reader = readcsv\n",
    "    reader = func_map.get(\"csv\")\n",
    "    \n",
    "    for k,v in func_map.items():\n",
    "        if file_name.endswith(k):\n",
    "            reader = v\n",
    "            break\n",
    "    return reader(file_name)\n",
    "\n",
    "\n",
    "#data cleaning function\n",
    "def cleaningup(df, to_date=[], to_numeric=[], cols_to_delete=[], fill_na_map={}, cols_to_drop_na_rows=[], cols_to_interpolate=[]):\n",
    "    \"\"\"\n",
    "    We will perform all the generic cleanup stuff in this function,\n",
    "    Data specific stuff should be handled by driver program.\n",
    "    \n",
    "    Mandatory Parameter:\n",
    "    df : Dataframe to be cleaned\n",
    "    \n",
    "    Optional Parameters:\n",
    "    to_date:  List of columns to convert to date\n",
    "    to_numeric:  List of columns to convert to numeric\n",
    "    cols_to_delete: All the useless columns that we need to delete from our dataset\n",
    "    fill_na_map:  A dictionary containing map for column and a value to be filled in missing places\n",
    "                    e.g. {'age': df['age'].median(), 'city': 'Karachi'}\n",
    "    cols_to_drop_na_rows: List of columns where missing value in not tolerable and we couldn't risk predicting                     value for it, so we drop such rows.\n",
    "    cols_to_interpolate: List of columns where missing values have to be replaced by forward interpolation\n",
    "    \"\"\"\n",
    "    \n",
    "    # columns to convert to date format\n",
    "    def change_type_to_date(df, to_date):\n",
    "        # Deal with incorrect data in date column\n",
    "        for i in to_date:\n",
    "            df[i] = pd.to_datetime(df[i], errors='coerce')\n",
    "        return df\n",
    "    \n",
    "    # columns to convert to numerical format\n",
    "    def change_type_to_numeric(df, to_numeric):\n",
    "        # Deal with incorrect data in numeric columns\n",
    "        for i in to_numeric:\n",
    "            df[i] = pd.to_numeric(df[i], errors='coerce')\n",
    "        return df\n",
    "    \n",
    "    # columns to delete\n",
    "    def drop_useless_colums(df, cols_to_delete):\n",
    "        # Drop useless columns before dealing with missing values\n",
    "        for i in cols_to_delete:\n",
    "            df = df.drop(i, axis=1)\n",
    "        return df\n",
    "    \n",
    "    #drop all rows which contain more than 40% missing values\n",
    "    def drop_useless_rows(df):\n",
    "        min_threshold = math.ceil(len(df.columns)*0.4)\n",
    "        df = df.dropna(thresh=min_threshold)\n",
    "        return df\n",
    "    \n",
    "    # drop rows in which columns specified by the driver program has missing values\n",
    "    def drop_na_rows(df, cols_to_drop_na_rows):\n",
    "        for i in cols_to_drop_na_rows:\n",
    "            df = df.drop(df[df[i].isnull()].index)\n",
    "        return df\n",
    "    \n",
    "    # Deal with missing values according to map, e.g., {'age': df['age'].median(), 'city': 'Karachi'}\n",
    "    def fill_na_vals(df, fill_na_map):\n",
    "        for col,val in fill_na_map.items():\n",
    "            df[col].fillna(val, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # Deal with missing values according to the interpolation\n",
    "    def fill_na_interpolate(df, cols_to_interpolate):\n",
    "        for i in cols_to_interpolate:\n",
    "            df[i] = df[i].interpolate(method ='linear', limit_direction ='forward')\n",
    "        return df\n",
    "    \n",
    "    try:\n",
    "        df = change_type_to_date(df, to_date)\n",
    "        df = change_type_to_numeric(df, to_numeric)\n",
    "        df = drop_useless_colums(df, cols_to_delete)\n",
    "        df = drop_useless_rows(df)\n",
    "        df = drop_na_rows(df, cols_to_drop_na_rows)\n",
    "        df = fill_na_vals(df, fill_na_map)\n",
    "        df = fill_na_interpolate(df, cols_to_interpolate)\n",
    "        print(\"df is all cleaned up..\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"Failed to perform cleanup, exception=%s\" % str(e))\n",
    "    finally:\n",
    "        return df\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#basic analysis\n",
    "def basicanalysis(df):\n",
    "    print(\"Shape is:\\n\", df.shape)\n",
    "    print(\"\\n Columns are:\\n\", df.columns)\n",
    "    print(\"\\n Types are:\\n\", df.dtypes)\n",
    "    print(\"\\n Statistical Analysis of Numerical Columns:\\n\", df.describe())\n",
    "\n",
    "#string column analysis analysis\n",
    "def stringcolanalysis(df):\n",
    "    stringcols = df.select_dtypes(exclude=[np.number, \"datetime64\"])\n",
    "    fig = plt.figure(figsize = (8,10))\n",
    "    for i,col in enumerate(stringcols):\n",
    "        fig.add_subplot(4,2,i+1)\n",
    "        fig.savefig('Categorical.png')\n",
    "        df[col].value_counts().plot(kind = 'bar', color='black' ,fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.title(col)\n",
    "\n",
    "#numerical analysis\n",
    "def numcolanalysis(df):\n",
    "    numcols = df.select_dtypes(include=np.number)\n",
    "    \n",
    "    # Box plot for numerical columns\n",
    "    for col in numcols:\n",
    "        fig = plt.figure(figsize = (5,5))\n",
    "        sb.boxplot(df[col], color='grey', linewidth=1)\n",
    "        plt.tight_layout()\n",
    "        plt.title(col)\n",
    "        plt.savefig(\"Numerical.png\")\n",
    "    \n",
    "    # Lets also plot histograms for these numerical columns\n",
    "    df.hist(column=list(numcols.columns),bins=25, grid=False, figsize=(15,12),\n",
    "                 color='#86bf91', zorder=2, rwidth=0.9)\n",
    "\n",
    "# Perform correlation analysis over numerical columns\n",
    "def correlation_anlysis(df):\n",
    "    # NOTE: If label column is non-numeric, 'encode' it before calling this function \n",
    "    numcols = df.select_dtypes(include=np.number)\n",
    "    corr = numcols.corr()\n",
    "    ax = sb.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sb.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "    \n",
    "    ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right')\n",
    "\n",
    "\n",
    "# Apply label encoding on specified columns\n",
    "def apply_label_encoding(df, cols=[]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in cols:\n",
    "        le.fit(df[i])\n",
    "        df[i] = le.transform(df[i])\n",
    "    return df\n",
    "\n",
    "\n",
    "# One-Hot/dummy encoding on specified columns\n",
    "def onehotencoding(df):\n",
    "    df = pd.get_dummies(df)\n",
    "    return df\n",
    "\n",
    "# One Hot encoding with Pandas categorical dtype\n",
    "def onehotencoding_v2(df, cols=[]):\n",
    "    for col in cols:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "        dfDummies = pd.get_dummies(df[col], prefix = col)\n",
    "        df = pd.concat([df, dfDummies], axis=1)\n",
    "        df = df.drop(col, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "#Train Test Split: splitting manually\n",
    "def traintestsplit(df,split,random=None, label_col=''):\n",
    "    #make a copy of the label column and store in y\n",
    "    y = df[label_col].copy()\n",
    "    \n",
    "    #now delete the original\n",
    "    X = df.drop(label_col,axis=1)\n",
    "    \n",
    "    #manual split\n",
    "    trainX, testX, trainY, testY= train_test_split(X, y, test_size=split, random_state=random)\n",
    "    return X, trainX, testX, trainY, testY\n",
    "\n",
    "#helper function which only splits into X and y\n",
    "def XYsplit(df, label_col):\n",
    "    y = df[label_col].copy()\n",
    "    X = df.drop(label_col,axis=1)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "# #### For Cross Validation, lets create generator functions for different cross validation techniques, this will help us run an iterator over all folds\n",
    "def cross_valid_kfold(X, y, split=10, random=None, shuffle=False):\n",
    "    \"\"\"\n",
    "    Generator function for KFold cross validation\n",
    "    \n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=split, random_state=random, shuffle=shuffle)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "        trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "        yield trainX,trainY,testX,testY\n",
    "    \n",
    "def cross_valid_repeated_kf(X, y, split=10, random=None, repeat=10):\n",
    "    \"\"\"\n",
    "    Generator function for Repeated KFold cross validation\n",
    "    \n",
    "    \"\"\"\n",
    "    kf = RepeatedKFold(n_splits=split, random_state=random, n_repeats=repeat)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "        trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "        yield trainX,trainY,testX,testY\n",
    "        \n",
    "\n",
    "def cross_valid_stratified_kf(X, y, split=10, random=None, shuffle=False):\n",
    "    \"\"\"\n",
    "    Generator function for Stratified KFold cross validation\n",
    "    \n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=split, random_state=random, shuffle=shuffle)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "        trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "        yield trainX,trainY,testX,testY\n",
    "\n",
    "\n",
    "def cross_valid_strat_shuffle_kf(X, y, split=10, random=None):\n",
    "    \"\"\"\n",
    "    Generator function for StratifiedShuffle cross validation\n",
    "    \n",
    "    \"\"\"\n",
    "    sss = StratifiedShuffleSplit(n_splits=split, random_state=random)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "        trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "        yield trainX,trainY,testX,testY\n",
    "\n",
    "\n",
    "# Validation metrics for classification\n",
    "def validationmetrics(model, testX, testY, verbose=True):   \n",
    "    predictions = model.predict(testX)\n",
    "    \n",
    "    if model.__class__.__module__.startswith('lightgbm'):\n",
    "        for i in range(0, predictions.shape[0]):\n",
    "            predictions[i]= 1 if predictions[i] >= 0.5 else 0\n",
    "    \n",
    "    #Accuracy\n",
    "    accuracy = accuracy_score(testY, predictions)*100\n",
    "    \n",
    "    #Precision\n",
    "    precision = precision_score(testY, predictions, pos_label=1, labels=[0,1])*100\n",
    "    \n",
    "    #Recall\n",
    "    recall = recall_score(testY, predictions,pos_label=1,labels=[0,1])*100\n",
    "    \n",
    "    #get FPR (specificity) and TPR (sensitivity)\n",
    "    fpr , tpr, _ = roc_curve(testY, predictions)\n",
    "    \n",
    "    #AUC\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    \n",
    "    #F-Score\n",
    "    f_score = f1_score(testY, predictions)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Prediction Vector: \\n\", predictions)\n",
    "        print(\"\\n Accuracy: \\n\", accuracy)\n",
    "        print(\"\\n Precision of event Happening: \\n\", precision)\n",
    "        print(\"\\n Recall of event Happening: \\n\", recall)\n",
    "        print(\"\\n AUC: \\n\",auc_val)\n",
    "        print(\"\\n F-Score:\\n\", f_score)\n",
    "        #confusion Matrix\n",
    "        print(\"\\n Confusion Matrix: \\n\", confusion_matrix(testY, predictions,labels=[0,1]))\n",
    "    \n",
    "    res_map = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"auc_val\": auc_val,\n",
    "                \"f_score\": f_score,\n",
    "                \"model_obj\": model\n",
    "              }\n",
    "    return res_map\n",
    "\n",
    "\n",
    "#Validation metrics for Regression algorithms\n",
    "def validationmetrics_reg(model,testX,testY, verbose=True):\n",
    "    predictions = model.predict(testX)\n",
    "    \n",
    "    # R-squared\n",
    "    r2 = r2_score(testY,predictions)\n",
    "    \n",
    "    # Adjusted R-squared\n",
    "    r2_adjusted = 1-(1-r2)*(testX.shape[0]-1)/(testX.shape[0]-testX.shape[1]-1)\n",
    "    \n",
    "    # MSE\n",
    "    mse = mean_squared_error(testY,predictions)\n",
    "    \n",
    "    #RMSE\n",
    "    rmse = math.sqrt(mse)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"R-Squared Value: \", r2)\n",
    "        print(\"Adjusted R-Squared: \", r2_adjusted)\n",
    "        print(\"RMSE: \", rmse)\n",
    "    \n",
    "    res_map = {\n",
    "                \"r2\": r2,\n",
    "                \"r2_adjusted\": r2_adjusted,\n",
    "                \"rmse\": rmse,\n",
    "                \"model_obj\": model\n",
    "              }\n",
    "    return res_map\n",
    "\n",
    "\n",
    "# Classification Algorithms\n",
    "\n",
    "def LogReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = LogisticRegression()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def KNN(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = KNeighborsClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def GadientBoosting(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = GradientBoostingClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def AdaBoost(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def SVM(trainX, testX, trainY, testY, svmtype=\"SVC\", verbose=True, clf=None):\n",
    "    # for one vs all\n",
    "    if not clf:\n",
    "        if svmtype == \"Linear\":\n",
    "            clf = svm.LinearSVC()\n",
    "        else:\n",
    "            clf = svm.SVC()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def DecisionTree(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = DecisionTreeClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def RandomForest(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = RandomForestClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def NaiveBayes(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = GaussianNB()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def MultiLayerPerceptron(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = MLPClassifier(hidden_layer_sizes=5)\n",
    "    clf.fit(trainX,trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def XgBoost(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "    clf.fit(trainX,trainY)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "def LightGbm(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    d_train = lgb.Dataset(trainX, label=trainY)\n",
    "    params = {}\n",
    "    params['learning_rate'] = 0.003\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'binary'\n",
    "    params['metric'] = 'binary_logloss'\n",
    "    params['sub_feature'] = 0.5\n",
    "    params['num_leaves'] = 10\n",
    "    params['min_data'] = 50\n",
    "    params['max_depth'] = 10\n",
    "    clf = lgb.train(params, d_train, 100)\n",
    "    return validationmetrics(clf,testX,testY,verbose=verbose)\n",
    "\n",
    "\n",
    "# Regression Algorithms\n",
    "def LinearReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf  = LinearRegression()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics_reg(clf, testX, testY, verbose=verbose)\n",
    "\n",
    "def RandomForestReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = RandomForestRegressor(n_estimators=100)\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics_reg(clf, testX, testY, verbose=verbose)\n",
    "\n",
    "def PolynomialReg(trainX, testX, trainY, testY, degree=3, verbose=True, clf=None):\n",
    "    poly = PolynomialFeatures(degree = degree)\n",
    "    X_poly = poly.fit_transform(trainX)\n",
    "    poly.fit(X_poly, trainY)\n",
    "    if not clf:\n",
    "        clf = LinearRegression() \n",
    "    clf.fit(X_poly, trainY)\n",
    "    return validationmetrics_reg(clf, poly.fit_transform(testX), testY, verbose=verbose)\n",
    "\n",
    "def SupportVectorRegression(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = SVR(kernel=\"rbf\")\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics_reg(clf, testX, testY, verbose=verbose)\n",
    "\n",
    "def DecisionTreeReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = DecisionTreeRegressor()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics_reg(clf, testX, testY, verbose=verbose)\n",
    "\n",
    "def GradientBoostingReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = GradientBoostingRegressor()\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics_reg(clf, testX, testY, verbose=verbose)\n",
    "\n",
    "def AdaBooostReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    if not clf:\n",
    "        clf = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics_reg(clf, testX, testY, verbose=verbose)\n",
    "\n",
    "def VotingReg(trainX, testX, trainY, testY, verbose=True, clf=None):\n",
    "    lr = LinearRegression()\n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    sv = SVR(kernel=\"rbf\")\n",
    "    dt = DecisionTreeRegressor()\n",
    "    gb = GradientBoostingRegressor()\n",
    "    ab = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "    if not clf:\n",
    "        clf = VotingRegressor([('rf', rf), ('dt', dt), ('gb', gb), ('ab', ab)])\n",
    "    clf.fit(trainX , trainY)\n",
    "    return validationmetrics_reg(clf, testX, testY, verbose=verbose)\n",
    "\n",
    "\n",
    "# Helper function to provide list of supported algorithms for Classification\n",
    "def get_supported_algorithms():\n",
    "    covered_algorithms = [LogReg, KNN, GadientBoosting, AdaBoost,\n",
    "                          SVM, DecisionTree, RandomForest, NaiveBayes,\n",
    "                          MultiLayerPerceptron]\n",
    "    if XGBClassifier:\n",
    "        covered_algorithms.append(XgBoost)\n",
    "    if lgb:\n",
    "        covered_algorithms.append(LightGbm)\n",
    "    return covered_algorithms\n",
    "\n",
    "# Helper function to provide list of supported algorithms for Regression\n",
    "def get_supported_algorithms_reg():\n",
    "    covered_algorithms = [LinearReg, RandomForestReg, PolynomialReg, SupportVectorRegression,\n",
    "                          DecisionTreeReg, GradientBoostingReg, AdaBooostReg, VotingReg]\n",
    "    return covered_algorithms\n",
    "\n",
    "\n",
    "# Helper function to run all algorithms provided in algo_list over given dataframe, without cross validation\n",
    "# By default it will run all supported algorithms \n",
    "def run_algorithms(df, label_col, algo_list=get_supported_algorithms(), feature_list=[]):\n",
    "    \"\"\"\n",
    "    Run Algorithms with manual split\n",
    "    \n",
    "    \"\"\"\n",
    "    # Lets make a copy of dataframe and work on that to be on safe side \n",
    "    _df = df.copy()\n",
    "    \n",
    "    if feature_list:\n",
    "        impftrs = feature_list\n",
    "        impftrs.append(label_col)\n",
    "        _df = _df[impftrs]\n",
    "    \n",
    "    _df, trainX, testX, trainY, testY = traintestsplit(_df, 0.2, 91, label_col=label_col)\n",
    "    algo_model_map = {}\n",
    "    score_map = {}\n",
    "    for algo in algo_list:\n",
    "        print(\"============ \" + algo.__name__ + \" ===========\")\n",
    "        \n",
    "        res = algo(trainX, testX, trainY, testY)\n",
    "        \n",
    "        score_map[ algo.__name__]=res\n",
    "        algo_model_map[algo.__name__] = res.get(\"model_obj\", None)\n",
    "        print (\"============================== \\n\")\n",
    "    \n",
    "    return algo_model_map,score_map\n",
    "        \n",
    "\n",
    "# With stratified kfold validation support\n",
    "def run_algorithms_cv(df, label_col, algo_list=get_supported_algorithms(), feature_list=[], cross_valid_method=cross_valid_stratified_kf):\n",
    "    \"\"\"\n",
    "    Run Algorithms with cross validation\n",
    "    \n",
    "    \"\"\"\n",
    "    _df = df.copy()\n",
    "    X,y = XYsplit(_df, label_col)\n",
    "    \n",
    "    # Select features if specified by driver program\n",
    "    if feature_list:\n",
    "        X = X[feature_list]\n",
    "    \n",
    "    result = {}\n",
    "    algo_model_map = {}\n",
    "    for algo in algo_list:\n",
    "        clf = None\n",
    "        result[algo.__name__] = dict()\n",
    "        for trainX,trainY,testX,testY  in cross_valid_method(X, y, split=10):\n",
    "            res_algo = algo(trainX, testX, trainY, testY, verbose=False, clf=clf)\n",
    "            # Get trained model so we could use it again in the next iteration\n",
    "            clf = res_algo.get(\"model_obj\", None)\n",
    "            \n",
    "            for k,v in res_algo.items():\n",
    "                if k == \"model_obj\":\n",
    "                    continue\n",
    "                if k not in result[algo.__name__].keys():\n",
    "                    result[algo.__name__][k] = list()\n",
    "                result[algo.__name__][k].append(v)\n",
    "                \n",
    "        algo_model_map[algo.__name__] = clf\n",
    "            \n",
    "    score_map = dict()\n",
    "    # let take average scores for all folds now\n",
    "    for algo, metrics in result.items():\n",
    "        print(\"============ \" + algo + \" ===========\")\n",
    "        score_map[algo] = dict()\n",
    "        for metric_name, score_lst in metrics.items():\n",
    "            score_map[algo][metric_name] = np.mean(score_lst)\n",
    "        print(score_map[algo])\n",
    "        print (\"============================== \\n\")\n",
    "        score_map[algo][\"model_obj\"] = algo_model_map[algo]\n",
    "    \n",
    "    return score_map\n",
    "\n",
    "\n",
    "# Helper function to get fetaure importance metrics via Random Forest Feature Selection (RFFS)\n",
    "def RFfeatureimportance(df, trainX, testX, trainY, testY, trees=35, random=None, regression=False):\n",
    "    if regression:\n",
    "        clf  = RandomForestRegressor(n_estimators=trees, random_state=random)\n",
    "    else:\n",
    "        clf  = RandomForestClassifier(n_estimators=trees, random_state=random)\n",
    "    clf.fit(trainX,trainY)\n",
    "    #validationmetrics(clf,testX,testY)\n",
    "    res = pd.Series(clf.feature_importances_, index=df.columns.values).sort_values(ascending=False)*100\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Helper function to select important features via RFFS, run supported ML algorithms over dataset with manual split and measure accuracy without Cross Validation - select features with importance >=threshold\n",
    "def MachineLearningwithRFFS(df, label_col, threshold=5, algo_list=get_supported_algorithms(), regression=False):\n",
    "    # lets create a copy of this dataframe and perform feature selection analysis over that\n",
    "    df_cpy = df.copy()\n",
    "    df_cpy, trainX, testX, trainY, testY = traintestsplit(df_cpy, 0.2, 91, label_col=label_col)\n",
    "    res = RFfeatureimportance(df_cpy, trainX, testX, trainY, testY, trees=10, regression=regression)\n",
    "    \n",
    "    impftrs = list(res[res > threshold].keys())\n",
    "    #impftrs.append(label_col)\n",
    "    \n",
    "    print (\"Selected Features =\" + str(impftrs))\n",
    "    print(df.shape)\n",
    "    results,score_map = run_algorithms(df, label_col, algo_list=algo_list, feature_list=impftrs)\n",
    "    return {\"selected_features\": impftrs}, score_map\n",
    "\n",
    "\n",
    "# Helper function to select important features via RFFS, run supported ML algorithms over dataset with cross validation and measure accuracy --- select features with importance >=threshold\n",
    "def MachineLearningwithRFFS_CV(df, label_col, threshold=5, algo_list=get_supported_algorithms(), regression=False):\n",
    "    # lets create a copy of this dataframe and perform feature selection analysis over that\n",
    "    df_cpy = df.copy()\n",
    "    df_cpy, trainX, testX, trainY, testY = traintestsplit(df_cpy, 0.2, 91, label_col=label_col)\n",
    "    res = RFfeatureimportance(df_cpy, trainX, testX, trainY, testY,\n",
    "                              trees=10, regression=regression)\n",
    "\n",
    "    impftrs = list(res[res > threshold].keys())\n",
    "    \n",
    "    print (\"Selected Features =\" + str(impftrs))\n",
    "    print(df.shape)\n",
    "    if regression:\n",
    "        cross_valid_method = cross_valid_kfold\n",
    "    else:\n",
    "        cross_valid_method = cross_valid_stratified_kf\n",
    "    results = run_algorithms_cv(df, label_col, algo_list=algo_list, feature_list=impftrs, cross_valid_method=cross_valid_method)\n",
    "    return {\"selected_features\": impftrs, \"results\": results}\n",
    "    \n",
    "\n",
    "\n",
    "# ## Mutual Information Feature Selection (MIFS)\n",
    "\n",
    "\n",
    "# \n",
    "# MachineLearningwithMIFS() => Helper function to select important features and run supported ML algorithms over dataset\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "# mutualinformation()  => Helper function to get fetaure importance metrics via Mutual Information Classifier/Regressor.\n",
    "def mutualinformation(df, label_col, regression=False):\n",
    "    df_cpy = df.copy()\n",
    "    y = df_cpy[label_col].copy()\n",
    "    X = df_cpy.drop(label_col,axis=1)\n",
    "    if regression:\n",
    "        mutual_info = mutual_info_regression(X,y,random_state=35)\n",
    "    else:\n",
    "        mutual_info = mutual_info_classif(X,y,random_state=35)\n",
    "    results = pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)*100\n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to select important features via MIFS, run supported ML algorithms over dataset with manual split and measure accuracy, without CV ... select features with importance >=threshold\n",
    "def MachineLearningwithMIFS(df, label_col, threshold=5, algo_list=get_supported_algorithms(), regression=False):\n",
    "    \n",
    "    # lets create a copy of this dataframe and perform feature selection analysis over that\n",
    "    df_cpy = df.copy()\n",
    "    res = mutualinformation(df_cpy, label_col=label_col, regression=regression)\n",
    "    \n",
    "    #include all selected features in impftrs\n",
    "    impftrs = list(res[res > threshold].keys())\n",
    "    \n",
    "    print (\"Selected Features =\" + str(impftrs))\n",
    "    \n",
    "    results = run_algorithms(df, label_col, algo_list=algo_list, feature_list=impftrs)\n",
    "    return {\"selected_features\": impftrs, \"results\": results}\n",
    "\n",
    "\n",
    "# Helper function to select important features via MIFS, run supported ML algorithms over dataset with manual split and measure accuracy, with CV ... select features with importance >=threshold\n",
    "def MachineLearningwithMIFS_CV(df, label_col, threshold=5, algo_list=get_supported_algorithms(), regression=False):\n",
    "    \n",
    "    # lets create a copy of this dataframe and perform feature selection analysis over that\n",
    "    df_cpy = df.copy()\n",
    "    res = mutualinformation(df_cpy, label_col=label_col, regression=regression)\n",
    "    \n",
    "    #include all selected features in impftrs\n",
    "    impftrs = list(res[res > threshold].keys())\n",
    "    \n",
    "    print (\"Selected Features =\" + str(impftrs))\n",
    "    if regression:\n",
    "        cross_valid_method = cross_valid_kfold\n",
    "    else:\n",
    "        cross_valid_method = cross_valid_stratified_kf\n",
    "    results = run_algorithms_cv(df, label_col, algo_list=algo_list, feature_list=impftrs, cross_valid_method=cross_valid_method)\n",
    "    return {\"selected_features\": impftrs, \"results\": results}\n",
    "\n",
    "\n",
    "# Helper function to select important features via REFS, run supported ML algorithms over dataset with manual split and measure accuracy, without CV ... select features with importance >=threshold\n",
    "# flexible enough to use any algorithm for recursive feature elimination and any alogorithm to run on selected features\n",
    "def GenericREFS(df, label_col,\n",
    "                algo_list=get_supported_algorithms(),\n",
    "                re_algo=RandomForestClassifier,\n",
    "                **kwargs):\n",
    "    \n",
    "    X,y = XYsplit(df, label_col)\n",
    "    clf = re_algo(**kwargs)\n",
    "    selector = RFE(estimator=clf, step=1)\n",
    "    selector = selector.fit(X,y)\n",
    "    feature_list = X.columns[selector.support_].tolist()\n",
    "    \n",
    "    results = run_algorithms(df, label_col, algo_list=algo_list, feature_list=feature_list)\n",
    "    return {\"selected_features\": feature_list, \"results\": results}\n",
    "\n",
    "\n",
    "# Helper function to select important features via REFS, run supported ML algorithms over dataset with manual split and measure accuracy, with CV ... select features with importance >=threshold\n",
    "# flexible enough to use any algorithm for recursive feature elimination and any alogorithm to run on selected features\n",
    "def GenericREFS_CV(df, label_col,\n",
    "                algo_list=get_supported_algorithms(),\n",
    "                regression=False,\n",
    "                re_algo=RandomForestClassifier,\n",
    "                **kwargs):\n",
    "    \n",
    "    X,y = XYsplit(df, label_col)\n",
    "    clf = re_algo(**kwargs)\n",
    "    selector = RFECV(estimator=clf, step=1, cv=10)\n",
    "    selector = selector.fit(X,y)\n",
    "    feature_list = X.columns[selector.support_].tolist()\n",
    "    if regression:\n",
    "        cross_valid_method = cross_valid_kfold\n",
    "    else:\n",
    "        cross_valid_method = cross_valid_stratified_kf\n",
    "    results = run_algorithms_cv(df, label_col, algo_list=algo_list, feature_list=feature_list, cross_valid_method=cross_valid_method)\n",
    "    return {\"selected_features\": feature_list, \"results\": results}\n",
    "\n",
    "# Helper function to provide list of classification algorithms to be used for recursive elimination feature selection\n",
    "def get_supported_algorithms_refs():\n",
    "    algo_list = [LogisticRegression, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "                          DecisionTreeClassifier, RandomForestClassifier]\n",
    "    return algo_list\n",
    "\n",
    "# Helper function to provide list of regression algorithms to be used for recursive elimination feature selection\n",
    "def get_supported_reg_algorithms_refs():\n",
    "    algo_list = [LinearRegression, RandomForestRegressor,\n",
    "                 DecisionTreeRegressor, GradientBoostingRegressor, AdaBoostRegressor]\n",
    "    return algo_list\n",
    "\n",
    "\n",
    "# Helper function to perform feature selection using PCA. It runs supported algorithms with over specified components and mesure performance stats, without Cross Validation\n",
    "from sklearn.decomposition import PCA\n",
    "def PCA_FS(df, label_col, n_components, algo_list=get_supported_algorithms()):\n",
    "    df_cpy = df.copy()\n",
    "    X,y = XYsplit(df_cpy, label_col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # First we need to normalize the data\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    # Now perform PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "\n",
    "    \n",
    "    algo_model_map = {}\n",
    "    score_map = {}\n",
    "    # At this stage we apply alogorithms\n",
    "    for algo in algo_list:\n",
    "        print(\"============ \" + algo.__name__ + \" ===========\")\n",
    "        res = algo(X_train, X_test, y_train, y_test)\n",
    "        algo_model_map[algo.__name__] = res.get(\"model_obj\", None)\n",
    "        score_map[ algo.__name__]=res\n",
    "        print(\"============================== \\n\")\n",
    "    return {\"n_components\": n_components, \"results\": score_map}\n",
    "\n",
    "\n",
    "# Helper function to perform feature selection using PCA. It runs supported algorithms with over specified components and mesure performance stats, with Cross Validation\n",
    "\n",
    "def PCA_FS_CV(df, label_col, n_components, algo_list=get_supported_algorithms(), regression=False):\n",
    "    df_cpy = df.copy()\n",
    "    X,y = XYsplit(df_cpy, label_col)\n",
    "    \n",
    "    cross_valid_method = cross_valid_kfold if regression else cross_valid_stratified_kf \n",
    "    result = {}\n",
    "    algo_model_map = {}\n",
    "    for algo in algo_list:\n",
    "        clf = None\n",
    "        result[algo.__name__] = dict()\n",
    "        for X_train,y_train,X_test,y_test in cross_valid_method(X, y, split=10):\n",
    "            # First we need to normalize the data\n",
    "            sc = StandardScaler()\n",
    "            X_train = sc.fit_transform(X_train)\n",
    "            X_test = sc.transform(X_test)\n",
    "            \n",
    "            # Now perform PCA\n",
    "            pca = PCA(n_components=n_components)\n",
    "            X_train = pca.fit_transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "            \n",
    "            # apply algo on this fold and save result for later usage\n",
    "            res_algo = algo(X_train, X_test, y_train, y_test, verbose=False, clf=clf)\n",
    "            # Get trained model so we could use it again in the next iteration\n",
    "            clf = res_algo.get(\"model_obj\", None)\n",
    "            \n",
    "            for k,v in res_algo.items():\n",
    "                if k == \"model_obj\":\n",
    "                    continue\n",
    "                if k not in result[algo.__name__].keys():\n",
    "                    result[algo.__name__][k] = list()\n",
    "                result[algo.__name__][k].append(v)\n",
    "            \n",
    "        algo_model_map[algo.__name__] = clf\n",
    "        \n",
    "    \n",
    "    score_map = dict()\n",
    "    # let take average scores for all folds now\n",
    "    for algo, metrics in result.items():\n",
    "        print(\"============ \" + algo + \" ===========\")\n",
    "        score_map[algo] = dict()\n",
    "        for metric_name, score_lst in metrics.items():\n",
    "            score_map[algo][metric_name] = np.mean(score_lst)\n",
    "        print(score_map[algo])\n",
    "        print (\"============================== \\n\")\n",
    "        score_map[algo][\"model_obj\"] =  algo_model_map[algo]\n",
    "    return {\"n_components\": n_components, \"results\": score_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_cat(df,type_cols):\n",
    "    cols = []\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    cols = df.select_dtypes(include=numerics).columns.tolist()\n",
    "    if type_cols != 'Numeric':\n",
    "        cols=list(set(df.columns.tolist())-set(cols))\n",
    "    return cols\n",
    "        \n",
    "        \n",
    "def num_plots (df,col_name):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18,5))\n",
    "    fig.suptitle('Numerical Analysis'+\" \"+col_name)\n",
    "    sns.boxplot(ax=axes[0], data=df,x=col_name)\n",
    "    sns.histplot(ax=axes[1],data=df, x=col_name, kde=True)\n",
    "    sm.qqplot(ax=axes[2],data=df[col_name], line ='45') \n",
    "    print(df[col_name].describe())\n",
    "    \n",
    "    #print(normality_test(df,col_name,'shapiro'))\n",
    "def target_num(df,col1,col2):\n",
    "    a_df = pd.DataFrame()\n",
    "    a_df[col2+'_yes'] = (df[df[col1] == 1][[col1,col2]].describe())[col2]\n",
    "    a_df[col2+'_no'] = (df[df[col1] == 0][[col1,col2]].describe())[col2]\n",
    "    a_df.drop(['count', '25%', '50%', '75%']).plot.bar(title = col2+' and ' +col1+ ' statistics')\n",
    "\n",
    "def cat_tar(df,col1,col2):\n",
    "    j_df = pd.DataFrame()    \n",
    "    j_df['yes'] = df[df[col1] == 1][col2].value_counts()\n",
    "    j_df['no'] = df[df[col1] == 0][col2].value_counts()\n",
    "    j_df.plot.bar(title = col2+' and ' +col1)\n",
    "            \n",
    "def scatter_plot(df,col1,col2):\n",
    "    sns.scatterplot(data=df, x=col1, y=col2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def rem_outliers(df,col):\n",
    "    mean = df[col].mean()\n",
    "    df[col] = np.where(stats.zscore(df[col])<=3, mean ,df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df,cat_column):\n",
    "    fig = plt.figure()\n",
    "    value_counts = df[cat_column].value_counts()\n",
    "    x_pos = np.arange(0, len(value_counts))\n",
    "    \n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(x_pos, value_counts.values, tick_label = value_counts.index)\n",
    "    ax.set_title(cat_column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingValues(data):\n",
    "    null_sum = data.isnull().sum()# instantiate columns for missing data\n",
    "    total = null_sum.sort_values(ascending=False)\n",
    "    percent = ( ((null_sum / len(data.index))*100).round(2) ).sort_values(ascending=False)\n",
    "\n",
    "    df_NA = pd.concat([total, percent], axis=1, keys=['Number of NA', 'Percent NA'])\n",
    "\n",
    "    df_NA = df_NA[ (df_NA.T != 0).any() ]\n",
    "    \n",
    "    return df_NA\n",
    "\n",
    "def mano(df,cols,all_cols=False):\n",
    "    if all_cols == False:\n",
    "        df= df[[cols]]        \n",
    "    msno.matrix(df)\n",
    "    msno.heatmap(df)\n",
    "    msno.bar(df)\n",
    "\n",
    "def cater_missing(df,column,method,value=0):\n",
    "    # method options is drop, mean and mode\n",
    "    if method == 'drop row':\n",
    "        df = df[df[column].notna()]\n",
    "    if method == 'drop column':\n",
    "        df.dropna(subset=[column], inplace=True)\n",
    "    if method == 'mean':\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "    if method == 'mode':\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_rep (df,col1,value,strip=False):    \n",
    "    for key in value:\n",
    "        df[col1] = df[col1].replace(key,value[key])\n",
    "    if strip == True:\n",
    "        df[col1] = df[col1].replace(' ','')\n",
    "def col_strip(df):\n",
    "#Strip white spaces from column names\n",
    "    df= df.rename(columns=lambda x: x.strip())  \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T - Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(a,b):\n",
    "    a=np.array(a)\n",
    "    b=np.array(b)\n",
    "   \n",
    "    t2, p2 = stats.ttest_ind(a,b)\n",
    "    print(\"t = \" + str(t2))\n",
    "    print(\"p = \" + str(p2))  \n",
    "    if t2 > p2 :\n",
    "        print(\"We reject the null hypothesis and we can say that the means of both groups are different\")\n",
    "    else:\n",
    "        print(\"We accept the null hypothesis and we can say that the means of both groups is significantly same\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def ANOVA(data,col1,col2):\n",
    "    ov=pd.crosstab(data[col1],data[col2])   \n",
    "    edu_frame=data[[col1, col2]]    \n",
    "    groups = edu_frame.groupby(col1).groups\n",
    "    edu_class=edu_frame[col2]\n",
    "    lis_group = groups.keys()\n",
    "    lg=[]\n",
    "    for i in groups.keys():\n",
    "        globals()[i]  = edu_class[groups[i]].values\n",
    "        lg.append(globals()[i])\n",
    "    dfd = 0\n",
    "    for m in lis_group:       \n",
    "        dfd=len(m)-1+dfd   \n",
    "    print(stats.f_oneway(*lg))\n",
    "    stat_val = stats.f_oneway(*lg)[0]\n",
    "    crit_val = stats.f.ppf(q=1-0.05, dfn=len(lis_group)-1, dfd=dfd)\n",
    "    if stat_val >= crit_val :\n",
    "        print('Reject null hypothesies and conclude that atleast one group is different and the feature is releavant to the class.')\n",
    "    else:\n",
    "         print('Accept null hypothesies and conclude that atleast one group is same and the feature is not releavant to the class.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi squared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared(data,f1,f2,alpha=0.05):\n",
    "    ov=pd.crosstab(data[f1],data[f2])\n",
    "    b=stats.chi2_contingency(ov)\n",
    "    chi2_statistic=b[0]\n",
    "    p_value=b[1]\n",
    "    dof=b[2]\n",
    "    critical_value=stats.chi2.ppf(q=1-alpha, df=dof)\n",
    "    print('Significance level: ',alpha)\n",
    "    print('Degree of Freedom: ',dof)\n",
    "    print('chi-square statistic:',chi2_statistic)\n",
    "    print('critical_value:',critical_value)\n",
    "    print('p-value:',p_value)\n",
    "    \n",
    "    if chi2_statistic>=critical_value:\n",
    "        print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
    "    else:\n",
    "        print(\"Retain H0,There is no relationship between 2 categorical variables\")\n",
    "    \n",
    "    if p_value<=alpha:\n",
    "        print(\"Reject H0,There is a relationship between 2 categorical variables\")\n",
    "    else:\n",
    "        print(\"Retain H0,There is no relationship between 2 categorical variables\")\n",
    "    if abs(chi2_statistic) >= critical_value:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_heat (data):\n",
    "    str_list = [] # empty list to contain columns with strings (words)\n",
    "    for colname, colvalue in data.iteritems():\n",
    "        if type(colvalue[1]) == str:\n",
    "             str_list.append(colname)\n",
    "    # Get to the numeric columns by inversion            \n",
    "    num_list = data.columns.difference(str_list) \n",
    "    # Create Dataframe containing only numerical features\n",
    "    data_num = data[num_list]\n",
    "    f, ax = plt.subplots(figsize=(16, 12))\n",
    "    plt.title('Pearson Correlation of features')\n",
    "    # Draw the heatmap using seaborn\n",
    "    #sns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"PuBuGn\", linecolor='k', annot=True)\n",
    "    sns.heatmap(data_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "def encoder (df,col_name,method):\n",
    "    if method=='onehot':\n",
    "        df[col_name] = pd.Categorical(df[col_name])\n",
    "        dfDummies = pd.get_dummies(df[col_name], prefix = col_name)\n",
    "        df.drop([col_name],axis=1,inplace=True)\n",
    "        df = pd.concat([df, dfDummies], axis=1)\n",
    "        print(df.shape)\n",
    "    elif method == 'label_encoder':\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[col_name] = label_encoder.fit_transform(df[col_name])\n",
    "    elif method == 'ordinal':\n",
    "         ordinal_encoder = OrdinalEncoder()\n",
    "         df[col_name] = Ordinal_encoder.fit_transform(df[col_name])\n",
    "    return df\n",
    "\n",
    "def convert_target_boolean(data,target,tar_var_neg):\n",
    "    data[target]=data[target].apply(lambda x:0 if x==tar_var_neg else 1)\n",
    "    return data\n",
    "def copy (df):\n",
    "    df1 = df.copy()\n",
    "    return df1   \n",
    "def change_type(df,colname,type_col):\n",
    "    # using dictionary to convert specific columns\n",
    "    convert_dict = {colname: type_col}\n",
    "    df = df.astype(convert_dict)\n",
    "    return df\n",
    "def plot(df,cat_column):\n",
    "    fig = plt.figure()\n",
    "    value_counts = df[cat_column].value_counts()\n",
    "    x_pos = np.arange(0, len(value_counts))\n",
    "    \n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(x_pos, value_counts.values, tick_label = value_counts.index)\n",
    "    ax.set_title(cat_column)\n",
    "    plt.show()\n",
    "def rem_rows(df,dict_col):\n",
    "    for key in dict_col:\n",
    "        indexNames = df[ df[key] == dict_col[key] ].index\n",
    "        df = df.drop(indexNames , inplace=True)\n",
    "    return df\n",
    "\n",
    "def rem_cols(df,lis_col):\n",
    "    df = df.drop(lis_col, axis='columns', inplace=True)\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def sm_sample(data,target):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X = data.drop(columns = target)\n",
    "    # Scaling all the variables to a range of 0 to 1\n",
    "    features = X.columns.values\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaler.fit(X)\n",
    "    X = pd.DataFrame(scaler.transform(X))\n",
    "    X.columns = features\n",
    "    y =data[[target]]\n",
    "    X_sm, y_sm = sm.fit_resample(X, y)\n",
    "    TEST_SIZE = 0.3\n",
    "    RAND_STATE = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size = TEST_SIZE, random_state=RAND_STATE)\n",
    "    print(f'''Shape of X before SMOTE: {X_train.shape}\n",
    "    Shape of X after SMOTE: {X_sm.shape}''')\n",
    "\n",
    "    print('\\nBalance of positive and negative classes (%):')\n",
    "    print(y_sm.value_counts(normalize=True) * 100)\n",
    "    data=X_sm\n",
    "    data[target]=y_sm\n",
    "    return data\n",
    "\n",
    "\n",
    "def check_imbalance(df,target):\n",
    "    print(df[target].value_counts())\n",
    "    df[target].value_counts().plot(kind='bar', title='Count (target)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train(data,target):\n",
    "    X = data.drop(columns = target)\n",
    "    # Scaling all the variables to a range of 0 to 1\n",
    "    features = X.columns.values\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    scaler.fit(X)\n",
    "    X = pd.DataFrame(scaler.transform(X))\n",
    "    X.columns = features\n",
    "    y =data[[target]]\n",
    "    TEST_SIZE = 0.3\n",
    "    RAND_STATE = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state=RAND_STATE)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def batch_classify(X_train,X_test,y_test,Y_train, verbose=True):                    \n",
    "    dict_classifiers = {\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB() , \n",
    "    \"Logistic Regression\" : LogisticRegression(solver='lbfgs'),\n",
    "    \"Neural Net\": MLPClassifier(alpha=1),  \n",
    "    \"Linear SVM\": SVC(probability=True),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=18),\n",
    "    \"XGBoost\":XGBClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(n_estimators=50, random_state=0),\n",
    "    'Light GBM': LGBMClassifier(),\n",
    "\n",
    "    }\n",
    "    no_classifiers = len(dict_classifiers.keys())\n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,8)), columns = ['classifier', 'train_score','test_score',\n",
    "                                                                                  'precision','recall','f1_score','cohens_kappa',\n",
    "                                                                                 'roc_auc'])\n",
    "    count = 0\n",
    "    for key, classifier in dict_classifiers.items():\n",
    "        classifier.fit(X_train, np.ravel(Y_train))\n",
    "        \n",
    "        cf_matrix = confusion_matrix(y_test, (classifier.predict(X_test)))\n",
    "        print(cf_matrix)\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_pred=classifier.predict(X_test)\n",
    "        \n",
    "        y_test = np.asarray(y_test)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # generate a no skill prediction (majority class)\n",
    "        ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "\n",
    "        lr_probs = classifier.predict_proba(X_test)\n",
    "        # keep probabilities for the positive outcome only\n",
    "        lr_probs = lr_probs[:, 1]\n",
    "        # calculate scores\n",
    "        ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "        lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "        # summarize scores\n",
    "        print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "        print(key+' : ROC AUC=%.3f' % (lr_auc))\n",
    "        # calculate roc curves\n",
    "        ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "        lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "        # plot the roc curve for the model\n",
    "        pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "        pyplot.plot(lr_fpr, lr_tpr, marker='.', label=key)\n",
    "        # axis labels\n",
    "        pyplot.xlabel('False Positive Rate')\n",
    "        pyplot.ylabel('True Positive Rate')\n",
    "        # show the legend\n",
    "        pyplot.legend()\n",
    "        # show the plot\n",
    "        pyplot.show()\n",
    "        \n",
    "        print(\"Classification Report\"+\" \"+key)\n",
    "        print(classification_report(y_test, y_pred, labels=[1, 0]))\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score=accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        df_results.loc[count,'classifier'] = key\n",
    "        df_results.loc[count,'train_score'] = train_score\n",
    "        df_results.loc[count,'test_score'] = test_score\n",
    "        df_results.loc[count,'precision'] = precision\n",
    "        df_results.loc[count,'recall'] = recall\n",
    "        df_results.loc[count,'f1_score'] = f1\n",
    "        df_results.loc[count,'cohens_kappa'] = kappa\n",
    "        df_results.loc[count,'roc_auc'] = auc\n",
    "        # accuracy: (tp + tn) / (p + n)\n",
    "        print('Accuracy: %f' % test_score)\n",
    "        # precision tp / (tp + fp)\n",
    "        print('Precision: %f' % precision)\n",
    "        # recall: tp / (tp + fn)\n",
    "        print('Recall: %f' % recall)\n",
    "        # f1: 2 tp / (2 tp + fp + fn)\n",
    "        print('F1 score: %f' % f1)\n",
    "        print('Cohens kappa: %f' % kappa) \n",
    "        print('ROC_AUC: %f' % auc)\n",
    "     \n",
    "    \n",
    "        count=count+1\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(xtrain,ytrain,xtest,ytest):\n",
    "\n",
    "    dict_regressors = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=0.1),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(max_depth=2, random_state=0),\n",
    "    \"Elastic Net Regressor\": ElasticNet(random_state=0),\n",
    "    }\n",
    "    no_classifiers = len(dict_regressors.keys())\n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,3)), columns = ['classifier','RMSE','R2_Score'])\n",
    "    count = 0\n",
    "    for key, classifier in dict_regressors.items():\n",
    "        print(key)\n",
    "        clf=classifier.fit(x,y)\n",
    "        y_predicted = clf.predict(xtest)\n",
    "        # model evaluation\n",
    "        rmse = mean_squared_error(y_test, y_predicted)\n",
    "        r2 = r2_score(y_test, y_predicted)\n",
    "        #print('Slope:' ,clf.coef_)\n",
    "        #print('Intercept:', clf.intercept_)\n",
    "        print('Root mean squared error: ', rmse)\n",
    "        print('R2 score: ', r2)\n",
    "\n",
    "        df_results.loc[count,'classifier'] = key\n",
    "        df_results.loc[count,'RMSE'] = rmse\n",
    "        df_results.loc[count,'R2_Score'] = r2\n",
    "\n",
    "\n",
    "\n",
    "        count=count+1\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions to get the relevent dataframes with the combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_wcv_wfs(data,y):\n",
    "    results_wcv,data = run_algorithms(data,y)\n",
    "    df =pd.DataFrame.from_dict(data,orient='index')\n",
    "    df.index.name='Results without CV and FS'\n",
    "    return df\n",
    "\n",
    "def df_cv(data,y):\n",
    "    results_cv = run_algorithms_cv(data,y)\n",
    "    df1 =pd.DataFrame.from_dict(results_cv,orient='index')\n",
    "    df1.index.name='Results with CV'\n",
    "    return df1\n",
    "\n",
    "def df_rffs(data, y):\n",
    "    res_rffs,score=MachineLearningwithRFFS(data, y, threshold=5, algo_list=get_supported_algorithms())\n",
    "    df2 =pd.DataFrame.from_dict(score,orient='index')\n",
    "    df2.index.name='Results with FS'\n",
    "    return df2\n",
    "\n",
    "def df_RFFS_CV(data,y):\n",
    "    res_RFFS_CV=MachineLearningwithRFFS_CV(data, y, threshold=5, algo_list=get_supported_algorithms(), regression=False)\n",
    "    df3 =pd.DataFrame.from_dict(res_RFFS_CV['results'],orient='index')\n",
    "    df3.index.name='Results with FS and CV'\n",
    "    return df3\n",
    "\n",
    "def df_RFE(data,y):\n",
    "    res_RFE=GenericREFS(data,y,algo_list=get_supported_algorithms(),re_algo=RandomForestClassifier)\n",
    "    df4 =pd.DataFrame.from_dict(res_RFE['results'][1],orient='index')\n",
    "    df4.index.name='Results with RFE'\n",
    "    return df4\n",
    "\n",
    "def df_RFE_CV(data,y):\n",
    "    res_RFE_CV=GenericREFS_CV(data,y,algo_list=get_supported_algorithms(),regression=False,\n",
    "                re_algo=RandomForestClassifier)\n",
    "    df5 =pd.DataFrame.from_dict(res_RFE_CV['results'],orient='index')\n",
    "    df5.index.name='Results with RFE and CV'\n",
    "    return df5\n",
    "\n",
    "def df_PCA(data,y):\n",
    "    res_PCA=PCA_FS(data,y, 5, algo_list=get_supported_algorithms())\n",
    "    df6 =pd.DataFrame.from_dict(res_PCA['results'],orient='index')\n",
    "    df6.index.name='Results with PCA '\n",
    "    return df6\n",
    "\n",
    "def df_PCA_CV(data,y):\n",
    "    res_PCA_CV=PCA_FS_CV(data,y, 5, algo_list=get_supported_algorithms())\n",
    "    df7 =pd.DataFrame.from_dict(res_PCA_CV['results'],orient='index')\n",
    "    df7.index.name='Results with PCA and CV '\n",
    "    return df7\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def all_combinations(data,y):\n",
    "    df=df_wcv_wfs(data,y)\n",
    "    print('Done 1')\n",
    "    df1=df_cv(data,y)\n",
    "    print('Done 2')\n",
    "    df2=df_rffs(data, y)\n",
    "    print('Done 3')\n",
    "    df3=df_RFFS_CV(data, y)\n",
    "    print('Done 4')\n",
    "    df4=df_RFE(data,y)\n",
    "    print('Done 5')\n",
    "    df5=df_RFE_CV(data,y)\n",
    "    print('Done 6')\n",
    "    df6=df_PCA(data,y)\n",
    "    print('Done 7')\n",
    "    df7=df_PCA_CV(data,y)\n",
    "    print('Done 8')\n",
    "    return df,df1,df2,df3,df4,df5,df6,df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parametre Tuning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params_SVM(data,y):\n",
    "    X = data.drop(columns = y)\n",
    "    y =data[[y]]\n",
    "    model = LogisticRegression()\n",
    "    solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    penalty = ['l2']\n",
    "    c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "    # define grid search\n",
    "    grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = RandomizedSearchCV(estimator=model, param_distributions =grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "def best_params_KNN(data,y):\n",
    "    # define dataset\n",
    "    X = data.drop(columns =y)\n",
    "    y =data[[y]]\n",
    "    # define models and parameters\n",
    "    model = KNeighborsClassifier()\n",
    "    n_neighbors = range(1, 21, 2)\n",
    "    weights = ['uniform', 'distance']\n",
    "    metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "    # define grid search\n",
    "    grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = RandomizedSearchCV(estimator=model, param_distributions =grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "     \n",
    "def best_params_SVC(data,y):\n",
    "\n",
    "    # define dataset\n",
    "    X = data.drop(columns = y)\n",
    "    y =data[[y]]\n",
    "    # define model and parameters\n",
    "    model = SVC()\n",
    "    kernel = ['poly', 'rbf', 'sigmoid']\n",
    "    C = [50, 10, 1.0, 0.1, 0.01]\n",
    "    gamma = ['scale']\n",
    "    # define grid search\n",
    "    grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = RandomizedSearchCV(estimator=model, param_distributions =grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def best_params_RF(data,y):\n",
    "# define dataset\n",
    "    X = data.drop(columns = y)\n",
    "    y =data[[y]]\n",
    "    # define models and parameters\n",
    "    model = RandomForestClassifier()\n",
    "    n_estimators = [10, 100, 1000]\n",
    "    max_features = ['sqrt', 'log2']\n",
    "    # define grid search\n",
    "    grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = RandomizedSearchCV(estimator=model, param_distributions =grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "\n",
    "\n",
    "def best_param_gbc(data,y):\n",
    "    # define dataset\n",
    "    X = data.drop(columns = y)\n",
    "    y =data[[y]]\n",
    "    # define models and parameters\n",
    "    model = GradientBoostingClassifier()\n",
    "    n_estimators = [10, 100, 1000]\n",
    "    learning_rate = [0.001, 0.01, 0.1]\n",
    "    subsample = [0.5, 0.7, 1.0]\n",
    "    max_depth = [3, 7, 9]\n",
    "    # define grid search\n",
    "    grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = RandomizedSearchCV(estimator=model, param_distributions =grid, n_jobs=-1, cv=cv, scoring='f1',error_score=0)\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
