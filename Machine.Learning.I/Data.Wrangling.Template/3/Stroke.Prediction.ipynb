{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stroke Data Results\n",
    "The stroke dataset has 5110 rows and 12 columns. The cleaning function in template is called to change columns to numeric. The bmi column has missing values which are filled by linear interpolation and un-necessary columns are deleted.\n",
    "•\tThe heatmap of correlation shows that the correlation among features is not so high.\n",
    "•\tt-stats for equality of mean of all numeric columns suggest that mean of numeric columns are not equal\n",
    "•\tthe Chi-square statistics suggest that numeric columns are not linearly independent \n",
    "•\tThe data of numeric columns is not normal.\n",
    "The one hot encoding is applied to string columns to create dummies, which results in \n",
    "Rows=5110, and columns= 22)\n",
    "\n",
    "Machine Learning algorithms are applied in two stages.\n",
    "1.\tIn the first sage the issue of class imbalance is not addressed. Eleven different machine learning classification algorithms are applied and four different scenarios are considered\n",
    "a.\twithout focusing the cross validation (CV) and features selection.\n",
    "b.\tOnly cross validation (CV: Stratified K-Fold) is considered\n",
    "c.\tOnly feature selection (random forest based algorithm is used) criterion is considered\n",
    "d.\tBoth cross validation (CV: Stratified K-Fold) and features selection (random forest based algorithm is used) are considered.\n",
    "The results of this stage indicate that\n",
    "•\tWith the application of CV the precision and accuracy increase in comparison to the bench mark category which is (without CV and RFFS)\n",
    "•\tThe performance in terms all four criterions (precision, recall, AUC and accuracy) worsens with the application of features selection criterion in comparison to the benchmark category\n",
    "•\tThe final Selected Features are ['avg_glucose_level', 'age', 'bmi', 'hypertension']\n",
    "Indicating that categorical variables do not play any role.\n",
    "•\tWith the application of both CV and RFFS criterions, almost all 11 algorithms outperform the benchmark as well as the other two categories.\n",
    "•\t The best performing algorithm seems to be the Random Forest. The performance of all remaining algorithms is considerably worse.\n",
    "\n",
    "2.\tIn the second stage the class imbalance issue is resolved through SMOT oversampling (to increase the under sampled category which is stroke=1). The results show that \n",
    "\n",
    "Original data shape: (5110, 22)\n",
    "Resampled data shape: (9722, 22)\n",
    "The above four different scenarios are considered\n",
    "a.\twithout focusing the cross validation (CV) and features selection.\n",
    "b.\tOnly cross validation (CV: Stratified K-Fold) is considered\n",
    "c.\tOnly feature selection (random forest based algorithm is used) criterion is considered\n",
    "d.\tBoth cross validation (CV: Stratified K-Fold) and features selection (random forest based algorithm is used) are considered.\n",
    "The results of this stage indicate that\n",
    "•\tWith the application of CV the precision and accuracy increase in comparison to the bench mark category which is (without CV and RFFS)\n",
    "•\tThe performance in terms all four criterions (precision, recall, AUC and accuracy) worsens a little bit with the application of features selection criterion in comparison to the benchmark category\n",
    "•\tSelected Features are =['age', 'avg_glucose_level', 'smoking_status_Unknown', 'smoking_status_never smoked', 'bmi', 'smoking_status_formerly smoked', 'Residence_type_Urban', 'ever_married_No', 'Residence_type_Rural', 'smoking_status_smokes', 'work_type_Private', 'work_type_Govt_job', 'work_type_Self-employed']\n",
    "\n",
    "•\tWith the application of both CV and RFFS criterions, almost all 11 algorithms underperform than the CV only based scenario but outperform the rest of two scenarios.\n",
    "•\t The best performing algorithm seems to be the Random Forest.\n",
    "\n",
    "\n",
    "Overall it seems that \n",
    "•\tWith the application of SMOT oversampling the performance improves in comparison to the strategy of without addressing the class imbalancing issue.\n",
    "•\tThe Random forest outperforms all the remaining algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TempML1 as template\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5110, 12)\n",
      "id                     int64\n",
      "gender                object\n",
      "age                  float64\n",
      "hypertension           int64\n",
      "heart_disease          int64\n",
      "ever_married          object\n",
      "work_type             object\n",
      "Residence_type        object\n",
      "avg_glucose_level    float64\n",
      "bmi                  float64\n",
      "smoking_status        object\n",
      "stroke                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"health.csv\"\n",
    "LABEL_COL = \"stroke\"\n",
    "healthdf = template.load_data(FILE_NAME)\n",
    "display(healthdf.head())\n",
    "print(healthdf.shape)\n",
    "print(healthdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is all cleaned up..\n"
     ]
    }
   ],
   "source": [
    "healthdf = template.cleaningup(healthdf, to_numeric=[\"age\",\"hypertension\",\"heart_disease\",\"avg_glucose_level\",\"bmi\",\"stroke\"], cols_to_interpolate=[\"bmi\"], cols_to_delete=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                object\n",
      "age                  float64\n",
      "hypertension           int64\n",
      "heart_disease          int64\n",
      "ever_married          object\n",
      "work_type             object\n",
      "Residence_type        object\n",
      "avg_glucose_level    float64\n",
      "bmi                  float64\n",
      "smoking_status        object\n",
      "stroke                 int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(healthdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is:\n",
      " (5110, 11)\n",
      "\n",
      " Columns are:\n",
      " Index(['gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
      "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
      "       'smoking_status', 'stroke'],\n",
      "      dtype='object')\n",
      "\n",
      " Types are:\n",
      " gender                object\n",
      "age                  float64\n",
      "hypertension           int64\n",
      "heart_disease          int64\n",
      "ever_married          object\n",
      "work_type             object\n",
      "Residence_type        object\n",
      "avg_glucose_level    float64\n",
      "bmi                  float64\n",
      "smoking_status        object\n",
      "stroke                 int64\n",
      "dtype: object\n",
      "\n",
      " Statistical Analysis of Numerical Columns:\n",
      "                age  hypertension  heart_disease  avg_glucose_level  \\\n",
      "count  5110.000000   5110.000000    5110.000000        5110.000000   \n",
      "mean     43.226614      0.097456       0.054012         106.147677   \n",
      "std      22.612647      0.296607       0.226063          45.283560   \n",
      "min       0.080000      0.000000       0.000000          55.120000   \n",
      "25%      25.000000      0.000000       0.000000          77.245000   \n",
      "50%      45.000000      0.000000       0.000000          91.885000   \n",
      "75%      61.000000      0.000000       0.000000         114.090000   \n",
      "max      82.000000      1.000000       1.000000         271.740000   \n",
      "\n",
      "              bmi       stroke  \n",
      "count  5110.00000  5110.000000  \n",
      "mean     28.92728     0.048728  \n",
      "std       7.77531     0.215320  \n",
      "min      10.30000     0.000000  \n",
      "25%      23.60000     0.000000  \n",
      "50%      28.10000     0.000000  \n",
      "75%      33.10000     0.000000  \n",
      "max      97.60000     1.000000  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAFoCAYAAADjHbhgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAASGklEQVR4nO3dfUyV9f/H8Rd4OBPsO8mbdFCRIEizFqSDDEKrfVtja2w1rJmmi8rWV2Nod4bfbDYz0v6gNKZluEw2WOmcOXWms8y11jAl5g0ZIiERN5rDlDvP5/eHdorZT/at8/bCeD7+wus657o+18frPAcf9Jww55wTACCkwr0eAAD8ExFXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQV3iuqqpKM2fOVGpqqm699Vbl5uZq//79kqQTJ04oLy9PKSkpuu+++1ReXq5x48YFn9vS0qL8/HylpqYqMzNThYWFam9v9+hKgN8RV3jqzJkzevLJJ3XzzTdr06ZNqqioUFRUlF555RX19PRo9uzZCg8PV0VFhV566SUVFxf3ev7cuXMlSeXl5SopKVF9fb0KCgq8uBSgNwd4qKWlxa1evdp1d3cHt23bts0lJye7PXv2uPHjx7u2trbgvrKyMpeUlOScc+6rr75yKSkprrOzM7i/qanJJSUluZqamit3EcCf8HkddwxsI0aM0NSpU1VWVqbDhw+rrq5OBw8eVCAQ0JEjRxQbG6thw4YFH5+amhr8+ujRozp37pzS09MvOW5tba0SExOvyDUAf4a4wlM///yzcnNzNWbMGGVlZSk7O1unTp3Sc889J5/PJ3eZN23r6elRTEyMSktLL9k3fPhwy2EDfWLNFZ7asmWLfD6f1q5dq7y8PGVmZqqpqUmSlJSUpMbGRp08eTL4+O+++y74dUJCgpqbmzVkyBDFxcUpLi5OPp9PS5cu7fUcwAvEFZ4aNWqUWltbtXv3bjU0NGjDhg0qKSmRdGEJID4+XgsWLFBNTY327NnT6xdaGRkZSkxMVEFBgaqrq3Xo0CHNnz9fJ06cUGxsrFeXBEiSwtzlfu4CjAUCAb3++uvavHmzuru7lZiYqJkzZ2revHlav369rrvuOi1cuFD79u1TTEyMsrOz9d5776m6ulqS1NTUpCVLlmjv3r0KDw/XpEmTVFhYqNGjR3t8ZRjoiCv6rba2NlVXV2vy5MnBbVu3btXy5cu1c+dOD0cG9I1lAfRbYWFhmjNnjkpLS9XQ0KDKykqtWLFC2dnZXg8N6BPfuaJf27Vrl4qLi3Xs2DENHTpUOTk5ys/PV0REhNdDAy6LuAKAAZYFAMAAcQUAA8QVAAz0+d9fT536VYHA/74sO3z4NWprO/OXBjVQMEd9Y476xhz1zWKOwsPDdO21Q/7f/X3GNRBwfymuvz0Xl8cc9Y056htz1LcrPUcsCwCAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAZ8Xg8Af9/8+f/RL7/84vUw0A9ER0frrbdWej0MiLj+I/zyyy+aMGGC18Po1yorKwfEHFVWVno9BFzEsgAAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABsziOmfOHKtDA0DI/Pe/L5oc1yyu9fX1VocGgJBpbGwwOS7LAgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAY8FkePC/vUcvDA/gTvO76B9O4rlmz3vLwV72RI/+llpb2v30cXkz4I153l7rca83q9cOyAAAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAGzuN54441WhwaAkImJud7kuGZxXbFihdWhASBkXnutyOS4LAsAgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYMDn9QDw90VHR6uystLrYfR7A2GOoqOjvR4CLiKu/wBvvbXS6yGYGTnyX2ppafd6GP0ac9Q/sSwAAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAY8PX1gPDwsL988L/z3IGCOeobc9Q35qhvoZ6jvo4X5pxzIT0jAIBlAQCwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMBDyuB45ckSPPPKIUlJSdP/99+vzzz8P9SmuOlVVVZo2bZomTpyoKVOm6J133pFzTl1dXVq0aJHS09OVnp6upUuX6vz5814P11Nnz57V/fffrzVr1kiS2tvblZ+fr4kTJyojI0OrV6/2eITeaW5u1jPPPKMJEyYoIyNDxcXFksR99AdVVVWaOnWqJkyYoHvuuUfr1q2T5NEcuRDq7Ox0d999t/vggw9cV1eX++yzz1xKSopraGgI5WmuKmfOnHF33HGHW7dunevp6XHHjh1z99xzj/voo4/c8uXL3bRp09ypU6fcTz/95HJyctyqVau8HrKnFixY4JKTk93777/vnHOuoKDAPfvss+7s2bPu6NGjbsqUKW7Lli0ej9IbDz30kFu0aJHr7Ox09fX1bvLkyW7z5s3cRxedP3/e3XnnnW7jxo3OOecOHjzoUlJS3DfffOPJHIX0O9evv/5aHR0dmjVrliIiInTvvfcqLS1NmzdvDuVprio//fSTbr/9dk2fPl2DBg3STTfdpH//+9/at2+fNm7cqKeeekrR0dEaPXq0nn76aX3yySdeD9kzW7duVV1dnW6//XZJF76L3b59u+bOnavIyEglJCRo+vTp+vjjjz0e6ZV34MABHT9+XC+//LL8fr9uuOEGrVu3TmlpadxHF50+fVqtra0KBAIKBAIKCwtTeHi4IiIiPJmjkMb1hx9+UEJCgsLCfn+3mPj4eH3//fehPM1VZezYsVq5cmXwz11dXfriiy+UnJyslpYWJSQkBPfFx8fr+PHj6urq8mKonmpsbNSyZcv05ptvKjz8wm15/PhxBQIBjRkzJvi4gXo/VVdXKykpSW+//bYyMzN17733aseOHRo8eDD30UXXXnutHn30Ub388su65ZZblJOTo8cff1xjxozxZI5CGtezZ89q8ODBvbYNHjxY586dC+VprlpdXV2aN2+e/H6/srOzJUmRkZHB/ZGRkXLOqaOjw6sheuL8+fN6/vnnlZ+fr+uvvz64/ddff5Xf79egQYOC2wbq/XT69Gl9++238vv92rVrl1auXKk1a9Zo165dkriPJCkQCCgyMlLLli3T/v379eGHH2rt2rWezVFI4xoVFXXJYDs6OhQVFRXK01yVWlpa9Nhjj6m1tVWlpaW65pprJKnXfP0WjYE2XyUlJRo1apRycnJ6bY+KilJ3d7cCgUBw20C9n/x+vyIjIzV37lz5/X4lJyfrwQcf1MaNGyVxH0nSjh079PXXX+uBBx6Q3+9Xenq6p3PU55tl/y8SEhL0/vvv99pWW1ur1NTUUJ7mqlNTU6MnnnhCd955pxYvXiy/3y9JGjlypGpraxUbGyvpwlzddNNN8vlC+tfS73366adqbm7WxIkTJV34CejAgQM6evSowsLCVFdXp/j4eEkX5mjs2LFeDtcT8fHxCgQC6unpUUREhCSpp6dHQ4cO5T66qLGx8ZIf830+n4YNG+bNHIXyt2OdnZ0uKyvLrVq1ynV2drqdO3e62267zdXX14fyNFeVkydPuoyMDFdUVHTJvqKiIvfwww+71tZW19TU5HJycty7777rwSj7l+nTpwf/tcCzzz7rnnnmGdfe3h781wKbNm3yeIRXXkdHh8vKynJFRUWus7PTHTp0yKWlpblt27ZxH1105MgRN378eFdWVuYCgYCrqqpyaWlpbseOHZ7MUcg/iaCmpkavvvqqDh8+rFGjRumFF17Q3XffHcpTXFVKS0v1xhtvKDIystcv+u666y4tW7ZMRUVF2r59u3p6epSTk6MXX3yx1xrjQDRjxgxNmTJFeXl5On36tBYvXqwvv/xSERERmjFjhmbPnu31ED3x448/6rXXXtOBAwfk9/s1a9Ys5eXlqbOzk/voos8//1zFxcU6fvy4RowYoSeeeEK5ubmezBEf8wIABvjvrwBggLgCgAHiCgAGiCsAGCCuAGCAuAKAAeIKAAaIKwAYIK4AYIC4wnNVVVWaOXOmUlNTdeuttyo3N1f79++XJJ04cUJ5eXlKSUnRfffdp/Lyco0bNy743JaWFuXn5ys1NVWZmZkqLCxUe3u7R1cC/I64wlNnzpzRk08+qZtvvlmbNm1SRUWFoqKi9Morr6inp0ezZ89WeHi4Kioq9NJLLwU/N+o3c+fOlSSVl5erpKRE9fX1Kigo8OJSgN5M3xYG6ENLS4tbvXq16+7uDm7btm2bS05Odnv27HHjx493bW1twX1lZWUuKSnJOefcV1995VJSUlxnZ2dwf1NTk0tKSnI1NTVX7iKAPzGw3vAR/c6IESM0depUlZWV6fDhw6qrq9PBgwcVCAR05MgRxcbGatiwYcHH//G9gY8ePapz584pPT39kuPW1tYqMTHxilwD8GeIKzz1888/Kzc3V2PGjFFWVpays7N16tQpPffcc/L5fHKXedO2np4excTEqLS09JJ9w4cPtxw20CfWXOGpLVu2yOfzae3atcrLy1NmZqaampokSUlJSWpsbNTJkyeDj//uu++CXyckJKi5uVlDhgxRXFyc4uLi5PP5tHTp0l7PAbxAXOGpUaNGqbW1Vbt371ZDQ4M2bNigkpISSReWAOLj47VgwQLV1NRoz549vX6hlZGRocTERBUUFKi6ulqHDh3S/PnzdeLEieDHeQBe4c2y4alAIKDXX39dmzdvVnd3txITEzVz5kzNmzdP69ev13XXXaeFCxdq3759iomJUXZ2tt577z1VV1dLkpqamrRkyRLt3btX4eHhmjRpkgoLCzV69GiPrwwDHXFFv9XW1qbq6mpNnjw5uG3r1q1avny5du7c6eHIgL6xLIB+KywsTHPmzFFpaakaGhpUWVmpFStWKDs72+uhAX3iO1f0a7t27VJxcbGOHTumoUOHKicnR/n5+cGPlwb6K+IKAAZYFgAAA8QVAAwQVwAwQFwBwABxBQADxBUADPwft+L2+mL5jNgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAFoCAYAAADjHbhgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZMElEQVR4nO3de1DVdf7H8ZeIl4TSVtzcwUteWnW2EMTUXUFFc03TIS/pKotriu54LaN1ybykLrWLzRq0kAaY5JQOzoIGOOngouKUm6xOaq6lK3ldNeO3pCiI8P39seNZT2gekTd4eT5mmMHD93y/7w+nnn79cjinnuM4jgAANcqrrgcAgHsRcQUAA8QVAAwQVwAwQFwBwABxBQADxBUunTp1Ul5eXl2P4VJUVKSsrKxaOVZMTIxmzZpVK8fC/cG7rgcAbmTp0qUqKSnRsGHDzI/16quviqd8oyYRV9yxajN2Dz74YK0dC/cHLgvAzf79+zVq1Cg98cQTGjp0qHbt2iVJSk5OVr9+/dyCt3PnTgUGBqqkpEQxMTFasGCBoqOj1bVrVw0cOFAbNmxw2/f69es1aNAgde3aVcOHD9fWrVtdX4uJidHLL7+s5557Tj169NDYsWOVmZmpTZs2qVOnTpKk8vJyvfnmm+rdu7eCg4M1adIkHTlyxLWPyMhIJSQkaOrUqQoICFDfvn21bt0619cLCgo0atQoBQQEKCQkRHFxcaqoqHAd/9rLAp9++qlGjx6twMBAhYWFKSUlxbX2jIwMjRgxQsnJyerdu7cCAwMVHR2tixcv1tCjgHsBcYWbNWvWaObMmcrKylKrVq0UHR0tx3E0bNgwnTlzRnv27HFtm5OTowEDBsjHx0fSf6Pj6+urjIwMRUREKCYmRjt37pQk5efnKzY2Vi+88IKysrI0ZswYzZo1y21/2dnZioiIUFpampKTkzV48GCFhYVpx44dkqSEhARt375db731ltLT09WuXTtFRkbq/Pnzrn0kJycrNDRUOTk5GjhwoBYtWqRz586poqJC06dPV69evbRx40YtXbpU69atU0ZGRpXvQUFBgaKiotSvXz9lZmZq9uzZSkpK0ocffuja5quvvtLu3buVlpam+Ph45ebmKj09vWYfDNzVuCwAN5MnT1bfvn0lSVFRUYqIiFBRUZFatmypJ598Uhs3blS3bt1UXl6uzZs3Ky4uznVff39/LVy4UF5eXurQoYM+++wzrV27Vr169dKKFSs0adIkDRkyRJLUpk0bffHFF3rvvfcUFBQkSWrXrp2effZZ1/4aN26syspKtWjRQqWlpVq1apXS0tLUrVs3SdK8efOUn5+vjz76SBEREZKknj17aty4cZKkF198UatXr9bBgwf1+OOPq7i4WH5+fvL391erVq2Umpqq5s2bV/kevP/++woJCdG0adNcc50+fVrLly93Hae8vFxLliyRn5+fOnbsqNDQUO3bt68mHwrc5ThzhZvWrVu7Pn/ooYckSaWlpZKk8PBwffzxx6qsrFR+fr68vLzUu3dv1/ZBQUHy8vrff1IBAQE6dOiQJOnQoUNKTExUUFCQ6yMzM1OFhYXXPfb3HTt2TJcvX9bEiRPd9nH8+HG3SwOPPvqo63NfX19J0pUrV9SsWTONHz9eb7zxhkJCQvTKK6+ouLhY/v7+VY51+PBhBQYGut0WHByss2fP6rvvvpMk+fj4yM/Pz+1Y5eXlN5wf9x/OXOGmfv36VW67eq1x0KBBWrx4sQoKCpSTk6MhQ4bI29v7hvetqKhwxbaiokLR0dEKCwtz2+ba+zdu3PiGc129Nrpy5coqZ5tXIypJDRo0uOH8c+fO1bhx45SXl6etW7dqypQpmj59umbMmOG2faNGjW64j6tzXO84wLU4c4XHfH19FRYWps2bNys/P7/KU6QOHDjg9ue9e/eqc+fOkqQOHTro5MmTatu2resjOztbOTk5NzxevXr1XJ+3adNG3t7eKioqct2/devWio+P1+eff37T2c+dO6dFixbJz89Pzz//vNLS0jRlypTrHr99+/Zu14Ilaffu3WrevLmaNWt202MBEnHFLQoPD1d6erqaNm1a5Z/OBw4c0LJly1RYWKjU1FTl5+crMjJS0n+v365du1Zr1qzRsWPHtGbNGiUmJqpVq1Y3PFaTJk108uRJnThxQj4+Pho7dqxiY2O1bds2HT16VK+99pry8vL02GOP3XTupk2bKjc3V7GxsSosLNSBAwe0Y8cOBQQEVNk2KipKO3bsUFJSkgoLC5Wdna0VK1YoMjLSLfjAD+GyAG5JaGioHnjgges+sT8kJERHjx5VeHi42rRpo8TERFe8Bg4cqPnz5ys1NVWxsbHy9/fX4sWLXT/gup7hw4crNzdXzzzzjHJzczVnzhx5e3tr7ty5unDhgrp06aKUlJQfvFZ7VYMGDfTuu+/q9ddf14gRI+Tt7a3+/ftr3rx5Vbbt0qWL3n77bcXHxyspKUktW7bUjBkzNGHCBM+/Ubjv1eOdCHAriouLFRISouzsbLVt29Z1e0xMjC5evKiEhIQ6nA64c3DmCo9cunRJ27dvV3Z2toKDg93CCqAq4gqP1K9fX/Pnz9fDDz+sd955p67HAe54XBYAAAM8WwAADBBXADBAXAHAwE1/oPV//1eiyspbvyzbvLmvvv32QrWGuhux3nvb/bTe+2mtUvXX6+VVTw8/7HPDr980rpWVTrXievW+9xPWe2+7n9Z7P61VslkvlwUAwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADZnGNjIy02jUA3PHM4lpcXGy1awC443FZAAAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMOBd1wMAQF2ZNCnC9Xlq6gc1um/OXAHAAHEFcF+69qz1en++XcQVAAwQVwAwQFwBwABxBQADxBXAfen7T73iqVgAcBfglwgA3LdSUz9QixYP6ptvztf4vjlzBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADZnFt2rSp1a4B4I5nFtfVq1db7RoA7nhcFgAAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUADBBXADBAXAHAAHEFAAPEFQAMEFcAMEBcAcAAcQUAA8QVAAx432wDL6961d757dz3bsR6723303rvp7VK1Vvvze5Tz3Ecp7oDAQCuj8sCAGCAuAKAAeIKAAaIKwAYIK4AYIC4AoAB4goABogrABggrgBgoNpx/fLLL/WrX/1KgYGBevrpp7Vt27brbvfvf/9bkyZNUlBQkPr376+//vWv1R62Lnm63q+//lpRUVHq0aOHQkJCtGTJEpWVldXytLfP0/VeVVlZqV//+tdavHhxLU1Yszxd74ULFxQTE6MePXqoZ8+eWrBggcrLy2t52tvn6XoLCws1YcIEde/eXaGhoVq2bJnu1l/q3Lt3r3r06HHDr9d4q5xqKCsrc8LCwpyVK1c6ly9fdnJzc53AwEDnxIkTVbYdPXq0Exsb65SVlTn/+Mc/nO7duzt79uypzmHrzK2sd/DgwU5cXJxTVlbmnDlzxhk5cqTzpz/9qQ6mrr5bWe9Vf/nLX5zOnTs7ixYtqsVJa8atrHfmzJnO1KlTnfPnzzvnzp1zhg8f7ixfvrwOpq6+W1nviBEjnMTERKeiosI5duyY06dPHyczM7P2h75NOTk5TnBwsBMYGHjDbWq6VdU6c/373/+u0tJSTZgwQQ0aNNCAAQPUo0cPZWVluW135MgR7du3T7NmzVLDhg3VrVs3DRs27K47e/V0vUVFRfrJT36iadOmqWHDhvrxj3+s8PBw7d69u44mrx5P13vVnj17lJOTo4EDB9bypDXD0/WePXtWW7Zs0eLFi+Xr66vmzZsrKSlJQ4cOraPJq+dWHt8jR46osrJSlZWVkqR69eqpUaNGtT3ybVm2bJlSUlI0bdq0G25j0apqxfVf//qXOnTooHr1/veqMO3bt9ehQ4eqDNyyZUv5+vr+4HZ3Ok/X+6Mf/Uipqany8fGRJDmOoy1btqhz5861Ou/t8nS90v/+mfzHP/5RTZo0qc0xa4yn6/3nP/+pRx55RFlZWerfv7/69OmjDz74QI888khtj3xbbuXxnTp1qpKSkhQQEKCnnnpKv/jFLzR48ODaHPe2jRs3ThkZGfrZz352w20sWlWtuF68eFGNGzd2u61x48a6dOmS220lJSUebXen83S916qsrNQf/vAHff3115o+fbr1iDXqVta7cOFChYeHKyAgoLbGq3Gervc///mPTp8+rcOHDysrK0sffPCBtmzZopSUlNoc97bdyuPr7e2tOXPmaM+ePVq/fr0++eQTrV27trZGrRGe/OVn0apqxbVJkyYqLS11u620tLTKmYun293pbnUdFy5c0PTp0/XJJ59o9erVatGiRW2MWWM8Xe/69et16tQp/fa3v63N8Wqcp+tt2LChKioq9Lvf/U4+Pj5q3bq1xo8fr82bN9fmuLfN0/Xu379fKSkp+s1vfqNGjRqpS5cumjhxotLT02tz3Fph0apqxbVDhw4qLCx0u+3IkSPq2LFjle3OnDmjkpKSH9zuTufpeiXpzJkzGjNmjMrLy5Wenq7WrVvX1pg1xtP1ZmVl6eDBg+rZs6e6d++u7Oxspaen33Wx9XS97du3lyRdvnzZdVtFRYX9gDXM0/WeOnWqyjMhvL295e1909fYv+uYtKo6PwUrKytz+vTp46xYscIpKytztmzZ4nTt2tU5duxYlW1HjhzpvPbaa05paamze/dup3v37s6uXbuq/RO4uuDpesvKypyhQ4c6s2fPdq5cuVJH096+W3l8r/X73//+rn22gKfrHTFihPPSSy85JSUlzvHjx51f/vKXTmpqah1MXX2ervebb75xunfv7vz5z392ysvLncLCQuepp55yVq1aVUeT356dO3f+4LMFarpV1Yqr4zjOl19+6YwdO9YJCgpynn76aedvf/ub4ziOs2HDBrcFnDp1ypk8ebITHBzshIWFOevWrav2sHXJk/Vu2rTJ+elPf+oEBAQ4gYGBro+RI0fW5ejV4unje627Na6O4/l6v/32W+ell15yfv7znzs9e/Z04uLi7sq/SD1d7549e5yxY8e6/v9dvny5U1FRUVdj35bvx9W6VbzNCwAY4NdfAcAAcQUAA8QVAAwQVwAwQFwBwABxBQADxBUunTp1Ul5eXl2P4VJUVHTDV+KqaTExMZo1a1atHAv3h3vv99hwz1i6dKlKSko0bNgw82O9+uqrd+2LQOPORFxxx6rN2D344IO1dizcH7gsADf79+/XqFGj9MQTT2jo0KHatWuXJCk5OVn9+vVzC97OnTsVGBiokpISxcTEaMGCBYqOjlbXrl01cOBAbdiwwW3f69ev16BBg9S1a1cNHz5cW7dudX0tJiZGL7/8sp577jn16NFDY8eOVWZmpjZt2qROnTpJksrLy/Xmm2+qd+/eCg4O1qRJk3TkyBHXPiIjI5WQkKCpU6cqICBAffv21bp161xfLygo0KhRoxQQEKCQkBDFxcW5Xnjl+5cFPv30U40ePVqBgYEKCwtTSkqKa+0ZGRkaMWKEkpOT1bt3bwUGBio6OloXL16soUcB9wLiCjdr1qzRzJkzlZWVpVatWik6OlqO42jYsGE6c+aM9uzZ49o2JydHAwYMcL04eEZGhnx9fZWRkaGIiAjFxMRo586dkqT8/HzFxsbqhRdeUFZWlsaMGaNZs2a57S87O1sRERFKS0tTcnKyBg8erLCwMO3YsUOSlJCQoO3bt+utt95Senq62rVrp8jISJ0/f961j+TkZIWGhrreGWHRokU6d+6cKioqNH36dPXq1UsbN27U0qVLtW7dOmVkZFT5HhQUFCgqKkr9+vVTZmamZs+eraSkJH344Yeubb766ivt3r1baWlpio+PV25u7j35UnyoPi4LwM3kyZPVt29fSVJUVJQiIiJUVFSkli1b6sknn9TGjRvVrVs3lZeXa/PmzYqLi3Pd19/fXwsXLpSXl5c6dOigzz77TGvXrlWvXr20YsUKTZo0SUOGDJEktWnTRl988YXee+89BQUFSZLatWunZ5991rW/xo0bq7KyUi1atFBpaalWrVqltLQ0devWTZI0b9485efn66OPPlJERIQkqWfPnho3bpwk6cUXX9Tq1at18OBBPf744youLpafn5/8/f3VqlUrpaamqnnz5lW+B++//75CQkJcbwvSrl07nT59WsuXL3cdp7y8XEuWLJGfn586duyo0NBQ7du3ryYfCtzlOHOFm2tff/ahhx6SJNeLCIeHh+vjjz9WZWWl8vPz5eXlpd69e7u2DwoKkpfX//6TCggIcL1NxqFDh5SYmKigoCDXR2Zmptvriv7Qa98eO3ZMly9f1sSJE932cfz4cbdLA48++qjr86tv2XHlyhU1a9ZM48eP1xtvvKGQkBC98sorKi4ulr+/f5VjHT58WIGBgW63BQcH6+zZs/ruu+8kST4+PvLz83M71t34LrCww5kr3NSvX7/KbVevNQ4aNEiLFy9WQUGBcnJyNGTIELcXTv7+fSsqKlyxraioUHR0tMLCwty2ufb+33+bje/vS5JWrlxZ5Wzz2vc9atCgwQ3nnzt3rsaNG6e8vDxt3bpVU6ZM0fTp0zVjxgy37a/3BnxX93F1jusdB7gWZ67wmK+vr8LCwrR582bl5+dXeYrUgQMH3P68d+9e15szdujQQSdPnlTbtm1dH9nZ2crJybnh8a59A702bdrI29tbRUVFrvu3bt1a8fHx+vzzz286+7lz57Ro0SL5+fnp+eefV1pamqZMmXLd47dv397tWrAk7d69W82bN1ezZs1ueixAIq64ReHh4UpPT1fTpk2r/NP5wIEDWrZsmQoLC5Wamqr8/HxFRkZK+u/127Vr12rNmjU6duyY1qxZo8TERLVq1eqGx2rSpIlOnjypEydOyMfHR2PHjlVsbKy2bdumo0eP6rXXXlNeXp4ee+yxm87dtGlT5ebmKjY2VoWFhTpw4IB27Nhx3TdWjIqK0o4dO5SUlKTCwkJlZ2drxYoVioyMdAs+8EO4LIBbEhoaqgceeOC6T+wPCQnR0aNHFR4erjZt2igxMdEVr4EDB2r+/PlKTU1VbGys/P39tXjxYtcPuK5n+PDhys3N1TPPPKPc3FzNmTNH3t7emjt3ri5cuKAuXbooJSXFo/cpa9Cggd599129/vrrGjFihLy9vdW/f3/NmzevyrZdunTR22+/rfj4eCUlJally5aaMWOGJkyY4Pk3Cvc93okAt6S4uFghISHKzs5W27ZtXbfHxMTo4sWLSkhIqMPpgDsHZ67wyKVLl7R9+3ZlZ2crODjYLawAqiKu8Ej9+vU1f/58Pfzww3rnnXfqehzgjsdlAQAwwLMFAMAAcQUAA8QVAAwQVwAwQFwBwABxBQAD/w/1ywhMa/pxyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAALBCAYAAAAOKdN6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAACK20lEQVR4nOzde1hU5d7/8Q+CI4Mmavro7mDKsFGzFIQH2mKeSjIPoOa2Iu2gRqSJVjvTdkmWinjYpkSaSpnHMhXP6a7UMndRJoZWHmAEd6nkKUs5DAzr90c/55G0RDnMOLxf1+V1ybrvtea7bsdZ82Hday0PwzAMAQAAAADcRg1nFwAAAAAAqFgEPQAAAABwMwQ9AAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAzBD0AAAC4pK5du2rx4sXOLqNckpKS1K9fv0p/nR9++EEtWrTQgQMHKv21cG0g6AEAAACAmyHoAQAAAICbIegBVSAjI0OPPPKIgoKCdPvtt+vvf/+7du/eLUn68ccfNWTIEAUGBioiIkLvvfeeWrRo4Vj3+PHjGjlypIKCgtShQwf985//1K+//uqkPQEAuKM/Ok4999xzeuqpp0r1feutt3TvvfdKkmw2m+Lj4/W///u/uuOOO/Tmm2+qW7duSktLK9PrXsn6gwYNUmJiYqllLVq00NatWyVJJSUlSk5OVufOnRUUFKSHH35YWVlZjr4bN25UZGSk2rRpo3vuuUepqamOttzcXMXGxio4OFghISGKi4vTyZMnHe2ffPKJoqKi1KZNG/Xs2VMrV64s0/5dyjfffKMHHnhAt99+uyIiIjRv3jyVlJTIMAx16dJFCxcuLNU/NjZW8fHxkvhOgCtD0AMq2dmzZ/X444+rVatWWrNmjZYvXy4fHx+NGzdOxcXFeuKJJ1SjRg0tX75cY8aM0cyZM0utP2LECEnSe++9p9mzZ+vw4cN6+umnnbErAAA39GfHqd69e+vTTz/VuXPnHP03btyoXr16SZImTJigHTt2KDk5WfPnz9e///1v/fe//y3za5d3/Qu9/vrrWrRokV544QWlpqaqUaNGiomJkd1u1/r16zV69Gg98MADWrt2rQYNGqSXXnpJ27ZtkySNHz9eRUVFWr58uRYvXqwff/xRkydPliQdPHhQcXFxio6O1vr16zV8+HAlJiZqw4YNV1zjyZMnNWTIEHXu3Fnr16/XP//5Ty1dulTz58+Xh4eHevbsqQ8++MDR/5dfftFnn32m3r17S+I7Aa6QAaBSHT9+3Jg7d65RVFTkWLZp0yajZcuWxvbt243WrVsbJ0+edLQtXbrUCAgIMAzDMD7//HMjMDDQKCwsdLQfO3bMCAgIMA4cOFB1OwEAcFt/dpwqKioy/va3vxlr1641DMMwDh8+bLRo0cLIyckxzp49a7Ru3dr46KOPHOtlZmYaAQEBxhdffHHZ1y3L+l26dDEWLVpkGIZhDBw40Jg8eXKpbQQEBBhbtmwxSkpKjDvuuMN45513HG1nzpwxEhISjJMnTxp9+/Y1xo8fX2rdcePGGffff79hGIbRu3dvIy4uzigoKDAMwzCys7ONb7/91jAMwxg9erTx4osvllp39uzZRr9+/S67j4ZhGLNmzTL69u1rGIZhzJw503jsscdKta9du9YICwszDMMwvv/+e6NFixbGsWPHDMMwjBUrVhidO3c2SkpKLvud4L///a8REBBg7N+/v0x1wf15OTtoAu6uYcOGGjBggJYuXap9+/YpOztb3333nUpKSrR//37deOONatCggaN/UFCQ4++ZmZnKz89XWFjYRdu1Wq3661//WiX7AABwX392nPLy8tK9996rDz74QL1799YHH3yg22+/XU2bNtWePXtUVFSk22+/3bEti8WiunXrlul1rVZruda/0OnTp3Xq1KlS26pbt67GjBkjScrKytKjjz5aap3g4GDHWbnY2Fg9//zzCgsL0x133KG7775bkZGRkn47o3fgwAGtX7/esW5xcbG8vK78a3RmZqbS0tJKHetLSkpUUFCg06dPq2XLlvrrX/+qDz74QI8++qg2btyoHj16yMPD47LfCVq3bn3F9cC9EfSASpabm6u///3vat68uTp27KgePXro9OnT+sc//iEvLy8ZhvGH6xYXF+uGG27Q22+/fVHb9ddfX5llAwCqiT87TklSr1699PDDD+vs2bP64IMP1KdPH0lSzZo1JelPj2N/przrFxcXl3lbtWrVumhZSUmJ7Ha7JKlHjx664447tHXrVm3fvl0TJ07UunXr9M4778hut2vQoEF64IEHrqrO39ccERGhUaNGXdR23XXXSfptvDdt2qSoqCh98cUXeu655xzr/tl3gp9//rnc9cG9cI0eUMk2bNggLy8vLViwQEOGDFGHDh107NgxSVJAQICOHDmiU6dOOfrv2bPH8XeLxaKffvpJtWvX1i233KJbbrlFXl5eSkhIKLUOAABX68+OU4ZhKCgoSI0bN9Z7772n/fv3q0ePHpKkpk2bqlatWtq7d69jWzk5Ofrll1/K9LpXur7JZCp1reCF1/Jdd911uv766/Xdd985lhUUFCg8PFwZGRny8/NTenp6qe2lp6fLYrFIkl577TX98MMPuu+++/Taa6/p9ddf1xdffKETJ07IYrEoJyfHcRy+5ZZb9Pnnn1/V8/0sFosOHTpUalsHDx5UUlKSatT47Wt5r169lJGRoRUrVqhZs2Zq2bKlY12+E+BKEPSASta4cWOdOHFC27Zt0w8//KBVq1Zp9uzZkn6bpunn56exY8fqwIED2r59e6mbsYSHh+uvf/2rnn76ae3du1fff/+9nn32Wf3444+68cYbnbVLAAA38mfHKZvNJknq2bOnXn/9dYWFhalRo0aSJB8fHw0YMECJiYn66quv9N133zmmSnp4eFz2da90/dtuu00fffSRvv76a+3bt0/jx4+XyWRytD/66KOaPXu2tm3bpkOHDumll15SnTp11LJlS8XExOj999/XsmXLlJ2drSVLlmjlypV6+OGHJf029fGVV17Rnj17lJOTo/Xr1zsurRg8eLC2bdumOXPmKCcnRx988IESExPVuHHjKx7rhx56SNnZ2ZowYYKsVqs+++wzxcfH67rrrnMEvRtvvFFt27bVG2+84bjpjcR3Alw5gh5Qye69914NGDBAY8aMUWRkpN577z1NmDBBHh4e+vbbb5WcnKyCggLdd999mjBhgv7+9787pqDUqFFDs2fPVr169fTwww9r0KBBatSokebNmydPT08n7xkAwB382XHq/Nm2yMhI5eXllQoekvSPf/xDISEheuKJJzR48GDdc8898vDwcBzHLudK1h88eLCCg4M1ePBgxcbGKjIyUk2aNCnV3r9/f7344ovq16+fTp06pTfffFMmk0ldu3ZVfHy83n77bfXq1UtLly7VhAkTHNfhjR8/XrfccouGDh2qyMhIHTlyRG+++aZq1Kih2267TbNmzdLGjRvVs2dPTZkyRbGxsRoyZMgVj3WTJk00f/587d27V1FRUY4xHzt2bKl+vXv3vmi8+U6AK+VhXO3EaADldvLkSe3du1edOnVyLPvggw80bdo0ffzxx06sDACAy/vwww/1t7/9TXXq1JEknTp1Sn/729+0detW3XDDDZW+PoA/xs1YACfy8PDQU089pWeeeUbdunVTbm6uXn/9dcf1DwAAuLI33nhDmzZt0lNPPaXi4mIlJSUpMDCwzCGtvOsD+GOc0QOcbMuWLZo5c6YOHTokX19fRUVFaeTIkWWe9gIAgLNkZWVp4sSJ2r17t2rUqKHw8HC9+OKLatSokcLCwhzX+F3KCy+8oHbt2v3h+teCiRMnasWKFX/Yfvvtt2vhwoVVWBHwfwh6AAAAqHD//e9/VVJS8oft119/vWPK5rXq1KlT+vXXX/+wvVatWqWuIwSqEkEPAAAAANwMd90EAAAAADdD0AMAAAAAN3NN33Xz9OlzKilh5ikAuKoaNTxUv35tZ5eBq8AxFgBc2+WOsdd00CspMTgIAQBQCTjGAsC1jambAAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZq7pxysAuPb51veWyatmmfvbiot05nRBJVYEoDrgsweAuyPoAXAqk1dNJWybVeb+YzvHSeLLFoDy4bMHgLtj6iYAAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuJlyB72tW7eqd+/eCgoKUrdu3fTuu+9Kkmw2m+Lj4xUWFqawsDAlJCTIbrc71tu0aZMiIiIUGBiogQMHKjs7u7ylAAAAAABUzqB35MgRxcXF6fnnn1d6erqSkpI0adIkZWRkKCkpSZmZmdq8ebPWrFmjtLQ0paSkSJIOHjyosWPHatKkSfryyy8VHBys4cOHq6SkpEJ2CgAAAACqs3IFvRtuuEGff/65OnTooJKSEp0+fVqenp6qU6eOUlNTFRMTo3r16qlJkyaKjY3VypUrJUlr165Vx44dFRISIpPJpLi4OOXm5mr37t0VsU8AAAAAUK2V+zl6derU0dmzZxUaGiq73a4nnnhCDRs21PHjx2WxWBz9/Pz8lJOTI5vNpqysLLVq1crR5unpqaZNmyozM1Pt2rUrb0kAAAAAUK1VyAPTzWazdu/erX379unxxx+Xt7e3Y/mFfQzDUEFBgfLy8hx9LmzPy8uriHIAAEA14VvfWyavmmXubysu0pnTPPgcgPurkKDn6ekpT09PtWnTRv3791dGRoYkqaDg/z5I8/PzJUk+Pj4ym80qLCwstY38/HzVrl27IsoBAADVhMmrphK2zSpz/7Gd4yQR9AC4v3Jdo/f5559rwIABpZYVFRWpbt26atSokaxWq2O51WpVs2bN5OXlJX9//1Jtdrtdhw8fLjXVEwAAAABwdcoV9Fq1aqXDhw9r4cKFstvt2rlzp1JTU9W/f39FRkYqOTlZJ0+eVG5urubMmaM+ffpIknr16qWtW7dqx44dstlsmjVrlho2bKi2bdtWxD4BAAAAQLVWrqmb9erV07x58zRx4kTNnDlTN9xwgyZOnKjQ0FC1bdtWiYmJioyMVHFxsaKiohQTEyNJatGihRITEzVhwgQdO3ZMrVu31uzZs+Xp6VkhOwUAAAAA1Vm5r9G7/fbbHQ9Jv1CtWrU0btw4jRs37pLrRUREKCIiorwvDwAAAAD4nXJN3QQAAAAAuB6CHgAAAAC4GYIeAAAAALgZgh4AAAAAuJkKeWA6ANflW99bJq+aZe5vKy7SmdM8TBgAAOBaRtAD3JzJq6YSts0qc/+xneMkEfQAAACuZUzdBAAAAAA3Q9ADAAAAADfD1E0AAIAy4JpnANcSgh4AAEAZcM0zgGsJQQ8AqhnOSgAA4P4IegBQzXBWAgAA98fNWAAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAcFE//fSThg0bpuDgYIWHh2vmzJmSJJvNpvj4eIWFhSksLEwJCQmy2+2O9TZt2qSIiAgFBgZq4MCBys7OdtIeAACchaAHAICLGjZsmP7nf/5Hn3/+ud59912lpqZq/fr1SkpKUmZmpjZv3qw1a9YoLS1NKSkpkqSDBw9q7NixmjRpkr788ksFBwdr+PDhKikpcfLeAACqEkEPwEV863urUaPryvzHt763s0sG3M4333yjnJwcvfDCCzKZTLr55pu1aNEihYaGKjU1VTExMapXr56aNGmi2NhYrVy5UpK0du1adezYUSEhITKZTIqLi1Nubq52797t3B0CAFQpHq8A4CLcfh9wvr179yogIECzZs3S6tWrVatWLT300EPq37+/jh8/LovF4ujr5+ennJwc2Ww2ZWVlqVWrVo42T09PNW3aVJmZmWrXrp0zdgUA4AQEPQAVgodwAxXrzJkzSk9PV1hYmLZs2SKr1aohQ4aoQYMGkiSz2ezoazabZRiGCgoKlJeXJ2/v0mfZzWaz8vLyqrR+AIBzEfQAVAjOAgIVy2QyyWw2a8SIEfLw8FDLli3Vr18/paamSpIKCv7v/09+fr4kycfHR2azWYWFhaW2lZ+fr9q1a1dd8QAAp+MaPQAAXJCfn59KSkpUXFzsWFZcXCxfX181atRIVqvVsdxqtapZs2by8vKSv79/qTa73a7Dhw+XmuoJAHB/BD0AAFxQeHi46tatqxkzZshms2nfvn1atWqVevbsqcjISCUnJ+vkyZPKzc3VnDlz1KdPH0lSr169tHXrVu3YsUM2m02zZs1Sw4YN1bZtW+fuEACgSjF1EwAAF1SrVi0tXrxYr776qu68806ZTCbFxMTonnvuUefOnZWYmKjIyEgVFxcrKipKMTExkqQWLVooMTFREyZM0LFjx9S6dWvNnj1bnp6eTt4jAEBVIugBAOCibr75Zs2dO/ei5bVq1dK4ceM0bty4S64XERGhiIiIyi4PAODCmLoJAAAAAG6GoAcAAAAAboagBwAAAABuhqAHAAAAAG6GoAcAAAAAboagBwAAAABuhqAHAAAAAG6G5+gBF/Ct7y2TV80y97cVF+nM6YJKrOj/uHJtAAAAcC0EPeACJq+aStg2q8z9x3aOk1Q1YcqVawMAAIBrYeomAAAAALgZgh4AAAAAuBmmbgK45nC9IgAAwJ+r1kGPL4vAtYnrFQEAAP5ctQ56fFlEReAXBgAAAHA11TroARXhan5h4FtfVxwOAcDdXc0vzgAAl0bQw1XhLFb5XN3ZZABwb3w2AkDFIejhqjDtFQAAAHBdPF4BAAAAANwMQQ8AAAAA3Ey5g15GRoaio6MVEhKizp07KykpSYZhyGazKT4+XmFhYQoLC1NCQoLsdrtjvU2bNikiIkKBgYEaOHCgsrOzy1sKAAAAAEDlDHrnzp3TE088oR49eigtLU0LFizQ6tWrtXTpUiUlJSkzM1ObN2/WmjVrlJaWppSUFEnSwYMHNXbsWE2aNElffvmlgoODNXz4cJWUlFTITgEAAABAdVaum7EcPXpU7dq108CBAyVJzZo1U7du3bRr1y6lpaVp4sSJqlevniQpNjZWM2bMUExMjNauXauOHTsqJCREkhQXF6clS5Zo9+7dateuXfn2CBB3BYVz8f4DAADOVq6g5+/vr+TkZMfPNptNn376qfr27av169fLYrE42vz8/JSTkyObzaasrCy1atXK0ebp6ammTZsqMzOToIcKwV1B4Uy8/wAAgLNV2M1YbDabnnnmGZlMJvXo0UOSZDabHe1ms1mGYaigoEB5eXny9vYutb7ZbFZeXl5FlQMAAAAA1VaFPEfv+PHjGjFihCTp7bffVo0av+XHgoL/+w11fn6+JMnHx0dms1mFhYWltpGfn6/atWtXRDkAAAAugancAJyl3EHvwIEDGjp0qNq3b69XXnlFJpNJktSoUSNZrVbdeOONkiSr1apmzZrJy8tL/v7+slqtjm3Y7XYdPny41FRPAACAax1TuQE4S7mmbp4+fVqDBw9Wr169NHnyZEfIk6TIyEglJyfr5MmTys3N1Zw5c9SnTx9JUq9evbR161bt2LFDNptNs2bNUsOGDdW2bdty7QwAAAAAoJxn9FavXq3jx49r6dKlWrZsmWP5nXfeqalTpyoxMVGRkZEqLi5WVFSUYmJiJEktWrRQYmKiJkyYoGPHjql169aaPXu2PD09y7c3AFCNMCUMAAD8kXIFvccee0yPPfbYH7aPGzdO48aNu2RbRESEIiIiyvPyAFCtMSUMAAD8kQq5GQsAuDrOfgEAgOqEoAegWuDsFwAAqE4q7Dl6AAAAAADXQNADAAAAADdD0AMAAAAAN0PQAwAAAAA3Q9ADAAAAADdD0AMAwMXl5eWpe/fuSklJkST9+uuvGjlypEJCQhQeHq65c+eW6r9kyRJ16tRJQUFBio2N1YkTJ5xRNgDAiXi8AqoUzzIDgCs3YcIE5eTkOH6Oj4+XJG3fvl1HjhzR0KFDddNNN6lHjx7avn27kpOTtWDBAt18880aP368xowZo/nz5zurfACAExD0XJg7hiKeZQYAV+aDDz5Qdna22rVrJ+m3s3ubN2/WmjVrZDabZbFYNHDgQK1YsUI9evRQamqq+vTpo4CAAEnS6NGj1b59e+Xm5qpx48bO3BUAQBUi6LkwQhEAVG9HjhzR1KlTtXDhQo0dO1aSlJOTo5KSEjVv3tzRz8/PTwsWLJAkZWVlqUOHDo62Bg0ayNfXV5mZmQQ9AKhGCHq4qjOHAIDKZbfb9dxzz2nkyJG66aabHMvPnTsnk8kkT09PxzJvb2/l5+dL+u2Mn7e3d6ltmc1mR3tV4dgCAM5F0MNVnjkEAFSm2bNnq3HjxoqKiiq13MfHR0VFRSopKVGNGr/dU62goEA+Pj6Sfgt1hYWFpdbJz893tFcVji0A4FwEPQAAXND69ev1008/KSQkRNJvZ+q++eYbZWZmysPDQ9nZ2fLz85MkWa1W+fv7S5L8/f1ltVod2zl16pR+/vlnWSyWqt8JAIDTEPQAAHBBmzZtKvXzoEGD1LlzZw0ZMkR5eXmaPn26EhMTlZubq8WLF+vpp5+WJEVFRWnMmDHq3r27/Pz8NGXKFLVv357r8wCgmuE5egAAXGNeeeUVeXt766677tIjjzyiBx54QJGRkZKkTp06acSIEYqLi1N4eLhOnz6tqVOnOrliAEBV44weXB4X9AOAtGjRIsfffX19NX369D/sGx0drejo6KooC5XEHR+xBKBqEfTg8rigHwBQ3fCIJQDlRdADgD/Ab9QBAMC1iqAHAH+A36gDAIBrFTdjAQAAAAA3wxk9N8ONSwAAAAAQ9NwMNy4BAAAAwNRNAAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAz3IwFAFwAd8wFAAAViaAHAC6AO+YCAICKxNRNAAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAz3IylClzN3fTOnC6oxIoAAAAAuDOCXhW4urvpEfQAAAAAXB2mbgIAAACAm+GM3hXiocYAAAAAXB1B7wrxUGMAAAAAro6pmwAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYqLOhlZGQoNDTU8bPNZlN8fLzCwsIUFhamhIQE2e12R/umTZsUERGhwMBADRw4UNnZ2RVVCgAAAABUaxUS9DZu3KjBgwerqOj/Hg6elJSkzMxMbd68WWvWrFFaWppSUlIkSQcPHtTYsWM1adIkffnllwoODtbw4cNVUlJSEeUAAAAAQLVW7qA3Y8YMzZ8/X8OGDSu1PDU1VTExMapXr56aNGmi2NhYrVy5UpK0du1adezYUSEhITKZTIqLi1Nubq52795d3nIAAAAAoNord9CLjo7WqlWr1Lp1a8eyX375RcePH5fFYnEs8/PzU05Ojmw2m7KysuTv7+9o8/T0VNOmTZWZmVnecgAAAACg2it30GvcuPFFy/Ly8iRJZrPZscxsNsswDBUUFCgvL0/e3t6l1jGbzY71AAAAAABXr1Luunk+4BUUFDiW5efnS5J8fHxkNptVWFhYap38/HzVrl27MsoBAAAAgGqlUoKer6+vGjVqJKvV6lhmtVrVrFkzeXl5yd/fv1Sb3W7X4cOHS031BAAAAABcnUp7jl5kZKSSk5N18uRJ5ebmas6cOerTp48kqVevXtq6dat27Nghm82mWbNmqWHDhmrbtm1llQMAAAAA1UalBb2RI0fq1ltvVWRkpCIjIxUaGqqYmBhJUosWLZSYmKgJEyYoLCxMX3/9tWbPni1PT8/KKgcAgGtORkaGoqOjFRISos6dOyspKUmGYfCsWgDAZXlV1IbCwsKUnp7u+LlWrVoaN26cxo0bd8n+ERERioiIqKiXBwDArZw7d05PPPGEhg8frkWLFum///2vhgwZogYNGujYsWOOZ9UWFBQoNjZWKSkpiomJcTyrdt68eWrTpo2Sk5M1fPhwrVu3TjVqVNrvdwEALoZPfAAAXNDRo0fVrl07DRw4UJ6enmrWrJm6deumXbt28axaAMBlVdgZPQAAUHH8/f2VnJzs+Nlms+nTTz9V3759tX79+j99Vm2rVq0cbRc+q7Zdu3ZVug+oWr71vWXyqlnm/rbiIp05XXD5jgCuSQQ9AABcnM1m0zPPPCOTyaQePXpo2rRpPKsWFzF51VTCtlll7j+2c5wkgh7grgh6AAC4sOPHj2vEiBGSpLfffttxnR3PqgUA/Bmu0QMAwEUdOHBA9913n5o1a6aFCxeqfv36PKsWAFAmBD0AAFzQ6dOnNXjwYPXq1UuTJ0+WyWRytPGsWgDA5TB1EwAAF7R69WodP35cS5cu1bJlyxzL77zzTk2dOlWJiYmKjIxUcXGxoqKiLvms2mPHjql169Y8qxYAqiGCHgAALuixxx7TY4899oftPKsWAPBnmLoJAAAAAG6GoAcAAAAAboagBwAAAABuhqAHAAAAAG6GoAcAAAAAboagBwAAAABuhqAHAAAAAG6GoAcAAAAAboagBwAAAABuhqAHAAAAAG6GoAcAAAAAboagBwAAAABuxsvZBQAAAMA5fOt7y+RVs8z9bcVFOnO6oBIrAlBRCHoAAADVlMmrphK2zSpz/7Gd4yQR9IBrAVM3AQAAAMDNEPQAAAAAwM0Q9AAAAADAzXCNHgAAAOCGuNlO9UbQAwAAAFzY1QY2brZTvRH0AAAAABdWlYGNs4Dug6AHAAAAQBKP3HAnBD0AAACUGWd8gGsDQQ8AAABlxhkf/B7h3zUR9AAAAFDpCAPui/Dvmgh6AAAAqHSEAaBq8cB0AAAAAHAznNEDAAAAUOWYzlu5CHoAAAAAqhzTeSsXQQ8AAAAuyR3P+FzNPgFXg6AHAAAAl+SOZ3yubp+AK0fQAwAAgNtwx7OAwNUg6AEAAMBtuONZQOBqEPQAAABQ7V3ttXNcb1e1OGNbdgQ9AAAAVHtXe+0c19tVLc7Ylh0PTAcAAAAAN8MZPQAAAABuq7pO93Rq0Nu/f7/i4+O1b98+NWnSRGPHjlWnTp2cWRIAAG6BYywA/Ka6Tvd02tRNm82mJ598Uvfcc4+++uorPffccxo1apR+/PFHZ5UEAIBb4BgLAHBa0EtLS1NBQYEeffRR1axZU3fddZdCQ0O1bt06Z5UEAIBb4BgLAOXjW99bjRpdV+Y/vvW9nV3yRZw2dTMrK0sWi0UeHh6OZX5+fjp48GCZt1GjhsflO12Gr/d1LrnO+X1z1fquZh1X3ydXr+9q1nH1fXL1+q5mHVffp6ut72o/byvicxpXjmPsn3PX/6euvI6r75Or13c167j6Prl6fSavmnrji7fL3H/YHY+pRo1CXedb64qvB/z1TOEV1Xbe5T6nPQzDMK5qy+X0xhtvKD09XfPmzXMsmzlzpvbv36833njDGSUBAOAWOMYCAJw2ddPHx0cFBaUvciwoKJCPj4+TKgIAwD1wjAUAOC3oWSwWHTp0qNQyq9Uqf39/J1UEAIB74BgLAHBa0AsLC5Onp6fmzp0rm82mLVu2KC0tTT179nRWSQAAuAWOsQAAp12jJ0kHDhzQyy+/rH379qlx48YaPXq0unTp4qxyAABwGxxjAaB6c2rQAwAAAABUPKdN3QQAAAAAVA6CHgAAAAC4GYIeAAAAALgZgh4AAAAAuJlqF/T279+vBx54QIGBgerevbs++eQTZ5ckScrIyFBoaKjjZ5vNpvj4eIWFhSksLEwJCQmy2+1Oqy06OlohISHq3LmzkpKSZBiGS9W4detW9e7dW0FBQerWrZveffddSa41jpKUl5en7t27KyUlRZL066+/auTIkQoJCVF4eLjmzp3rtNqWL1+u1q1bKygoyPEnNTXVZcbwp59+0rBhwxQcHKzw8HDNnDlTkuv8G69du7bU2AUFBalVq1YaPHiwy9SYkZGhAQMGKDg4WF27dtWiRYskuc4YwjW5+meDq7jS4/imTZsUERGhwMBADRw4UNnZ2U6o2rl+P2YFBQUXvdcGDx7saK/OY3a138Wq65j90XhVu/eYUY0UFhYaXbp0Md566y3DZrMZH330kREYGGj88MMPTq1rw4YNRnBwsBEYGOhYNm3aNCM6Oto4ffq0cfToUSMqKsp48803q7y2s2fPGnfccYexaNEio7i42Dh06JDRtWtXY/HixS5T448//mjcdtttxvbt2w3DMIzvv//euP32241vvvnGZWo8b+zYsUbLli2N+fPnG4ZhGE8//bQRFxdn5OXlGZmZmUbnzp2NDRs2OKW2l156yfjXv/510XJXGcP77rvPiI+PNwoLC43Dhw8bnTp1MtatW+cy9f3ed999Z4SGhhrff/+9S9Rot9uN9u3bG6mpqY76AgMDja+++sol6oPrcvXPBldwpcfxAwcOOP7/FRYWGv/617+MHj16GHa73Vm7UOUuNWbp6enGnXfeecn+1XnMrva7WHUdsz8br+r2HqtWQe/TTz81/va3vxklJSWOZTExMcbs2bOdVtO//vUvo2/fvkZKSkqpD7vw8HBj27Ztjp8/+OADIyIiosrrO3jwoDFs2LBSyxISEoxnnnnGZWo0DMP49ddfDcP47cvsf/7zHyMwMNDIyspyqRo3btxoPPjgg0Z0dLQxf/5849y5c8att95qHDx40NFn/vz5xmOPPeaU+vr162d88MEHFy13hTHcvXu3ERISYhQWFjqWHT582MjNzXWJ+n7PZrMZPXv2NBYuXGgYhmuM4alTp4yAgABj5cqVht1uN77//nujXbt2xu7du12iPrguV/5scAVXcxyfNm2aERcX52grLi42goODja+//rrqCneiPxqzxYsXGzExMZdcpzqP2dV+F6uuY/Zn41Xd3mPVaupmVlaWLBaLPDw8HMv8/Px08OBBp9UUHR2tVatWqXXr1o5lv/zyi44fPy6LxeJY5ufnp5ycHNlstiqtz9/fX8nJyY6fbTabPv30U7Vs2dJlapSkOnXq6OzZs7rtttv06KOPatCgQWrYsKHL1HjkyBFNnTpVU6ZMUY0av/23y8nJUUlJiZo3b16qPme8H4uKinTgwAGtWrVKHTp0ULdu3TR37lydOXPGJcZw7969CggI0KxZs9ShQwfddddd+vDDD+Xt7e0S9f3e0qVL5enpqYceeshl/j/Xr19fDz30kF544QXddtttioqK0uDBg9W8eXOXqA+uydU/G1zB1RzHs7Ky5O/v72jz9PRU06ZNlZmZWaW1O8ulxkySvv32Wx0/fly9e/dW+/btFRcXp9zcXEmq1mN2td/FquuY/dl4Vbf3WLUKenl5efL29i61zNvbW/n5+U6qSGrcuPFFy/Ly8iRJZrPZscxsNjvmFjuLzWbTM888I5PJpB49ejjqOs/ZNZrNZu3evVvvv/++3nvvPS1evNglarTb7Xruuec0cuRI3XTTTY7l586dk8lkkqenp2OZs96Pp06dUps2bdSvXz9t2bJFM2fO1NKlS11mDM+cOaP09HSZTCZt2bJFycnJSklJ0ZYtW1yivgvZbDalpKToqaeeUo0aNVzm/3NJSYnMZrOmTp2q3bt3a+HChVqwYIFLjiFch6t/NriCqzmOX+r7iNlsdqzn7i41ZpLk4+Oj4OBgvfPOO/rggw9Uq1YtPfnkk5Iu/R2uOo3ZeVfyXYwxKz1eDz30ULV7j3k5u4Cq5OPjc9EBqKCgQD4+Pk6q6NLO/4e9sNbzX/6dVevx48c1YsQISdLbb7/tOCvlSjV6enrK09NTbdq0Uf/+/ZWRkeESNc6ePVuNGzdWVFRUqeU+Pj4qKipSSUlJqfF0xvg1btxYS5Yscfx86623atCgQVqzZo2jrvOcMYYmk0lms1kjRoyQh4eHWrZsqX79+ik1NdUl6rvQ9u3bJUl33XWXJNf5//zhhx8qLS1Nzz33nCQpLCzMZccQrsPVPxtc1eX+35vNZhUWFpZaJz8/X7Vr1666Il3Qiy++WOrnsWPH6m9/+5t++OEHxkxX/l2suo/Z78fLx8en2r3HqtUZPYvFokOHDpVaZrVaS52mdQW+vr5q1KiRrFarY5nValWzZs3k5VX12fzAgQO677771KxZMy1cuFD169d3qRo///xzDRgwoNSyoqIi1a1b1yVqXL9+vbZt26aQkBCFhITo66+/1syZM7Vo0SJ5eHiUuqOTs96P+/fv1+uvv15qWWFhoRo1auQSY+jn56eSkhIVFxc7lhUXF7vU+/C8jz/+WPfee6/jAOwqNR45cuSiKXVeXl5q0KCBS9QH1+Tqnw2u6nL/7/39/Uu12e12HT58uNQUvOrGMAzNmDGj1Lic/8yqVatWtR+zq/kuVp3H7FLjVR3fY9Uq6IWFhcnT01Nz586VzWbTli1blJaWpp49ezq7tItERkYqOTlZJ0+eVG5urubMmaM+ffpUeR2nT5/W4MGD1atXL02ePFkmk8nlamzVqpUOHz6shQsXym63a+fOnUpNTVX//v1dosZNmzZp165d2rlzp3bu3Kng4GCNHDlSCQkJuvvuuzV9+nSdPXtWWVlZWrx4sVPGsHbt2po7d65WrlypkpISZWRkaPHixS4zhuHh4apbt65mzJghm82mffv2adWqVerZs6dL1Hehb775RoGBgaWWuUKN4eHhslqtWrZsmQzD0J49e7RixQqXHEO4Dlf/bHBlfzY+vXr10tatW7Vjxw7ZbDbNmjVLDRs2VNu2bZ1btBN5eHjo22+/1ZQpU/Trr7/qzJkzmjBhgjp16qRGjRpV6zG72u9i1XXM/mi8quV7zCm3gHGi/fv3Gw8++KARFBRkdO/e3diyZYuzSzIMwzC++OKLUneeKigoMMaPH2+0b9/eCA0NNSZOnGgUFxdXeV1vvfWWERAQYLRt29YIDAx0/BkxYoTL1GgYhpGRkWHcf//9Rrt27YxevXoZmzdvNgzDdcbxQgMHDnQ8XuHnn382nnnmGSM0NNQIDw835syZ47S6tm/fbvTt29cIDAw0unTpYixevNgwDNcZw8OHDxuPP/64ERoaanTo0MExhq5S33lt27Y1vvrqq1LLXKXGbdu2GX379jXatWtnREREGMuXL3ep+uCaXP2zwVVc6XF88+bNRvfu3Y3AwEDjoYceMqxWqzPKdqrfj9mJEyeMUaNGGaGhoUZwcLDxzDPPGD///LOjvbqOWXm+i1XHMfuz8apu7zEPwzAMZ4dNAAAAAEDFqVZTNwEAAACgOiDoAQAAAICbIegBAAAAgJsh6AEAAACAmyHoAQAAAICbIegBAAAAgJsh6AEAAACAmyHoAQAAAICbIegBAAAAgJsh6AEAAACAmyHoAQAAAICbIegBAAAAgJsh6AEAAACAmyHoAQAAAICbIegBAAAAgJsh6AEAAACAmyHoAQAAAICbIegBAAAAgJsh6AGVrEWLFtq6dWuFba9r165avHhxhW0PAICrUdHHt7L48ssv9f3331/1+osXL1bXrl0lST/88INatGihAwcOVFR5gEsh6AHXmBUrVui+++5zdhkAAFS5QYMG6dixYxWyrb/85S/67LPP5OfnVyHbA1yNl7MLAHBlGjRo4OwSAAC45nl6eqpRo0bOLgOoNJzRA6pARkaGevfurdtvv12DBg1SVlaWo61r1656//33FR0drTZt2ui+++5Tdna2EhMTFRISog4dOui9994r1Z+pmwAAV7B37171799ft99+u3r16qWvvvrK0Xb27Fm99NJLCg0NVVhYmOLi4pSbm+toz87OVmxsrEJCQnTbbbepV69epaaCtmjRQq+99prat2+vyMhIderUSZIUGxurMWPGlKm+jIwMDRgwQG3atNGDDz5Y6mzg76dufvTRR+rVq5duv/12de3aVfPnz3f0LSoq0rRp0xQeHq7g4GANGTJEVqvV0X7ixAk9++yzuuOOO3Tbbbfp7rvv1ooVKxztO3fuVP/+/dWmTRt16NBBU6ZMkd1ud7SnpKSoS5cuCgoK0oMPPqjdu3eXaf+AP0PQA6rAokWLNHz4cK1atUq1a9fWU089pZKSEkf79OnTNXToUK1cuVJnz57VgAEDVFxcrOXLlysyMlKvvvqqTp065cQ9AADgYsuWLdOIESO0bt063XTTTXr22WdlGIYkady4ccrOzlZKSooWLVokDw8PDR06VMXFxTIMQ7Gxsapdu7aWL1+uNWvWKCAgQGPHjpXNZnNsf8OGDVq4cKESExOVmpoqSZoyZYr++c9/Xra2n3/+WY8//rhatmyp1NRU9evXT++8884l+548eVKjRo3S/fffr02bNmn06NF67bXX9Pnnn0uSZs2apU8//VSvvfaali9frubNm2vQoEH69ddfJUmjR4/WqVOntGDBAm3YsEFdu3bVyy+/rBMnTshut2v48OG64447tHHjRk2dOlXvv/++Vq1aJUl69913tXjxYr388stKTU1Vp06d9Mgjj+iHH364+n8YQJIMAJUqICDAmDNnjuPnkydPGq1btzZ27NhhGIZhdOnSxXj11Vcd7VOmTDFCQ0ON4uJiR/+AgABj165djv6LFi2qwj0AAOBiAQEBxltvveX4+auvvjICAgKMEydOGIcPHzYCAgKMY8eOOdoLCwuNwMBAY+vWrca5c+eMefPmGadPn3a079mzxwgICDCOHDni2P6bb7550Wtu2bKlTPUtWbLECA8PN2w2m2PZSy+9ZHTp0sUwDMP473//awQEBBj79+83vv32WyMgIMDYtGlTqf05fvy4kZ+fb9x2223G119/XWr7ERERxuLFiw3DMIx33nnHOHz4sKPt1KlTRkBAgPHVV18Zp0+fNlq0aGG8/fbbRklJiWEYhvHNN98YP/zwg2EYhtG5c2dj7dq1pbb92GOPGZMnTy7TfgJ/hGv0gCrQtm1bx98bNGigG2+8UQcOHFD79u0lSTfddJOj3dvbWzfccIM8PT0lSbVq1ZKkUr/hBADAFdx8882Ov9etW1eSVFBQoMzMTElS9+7dS/XPz8+X1WpV586d9dBDD2n9+vXas2ePsrOz9d1330lSqSmNF27/Sh08eFAtWrRQzZo1HcvatGmjzz777KK+rVq1UkREhOLi4nTjjTeqU6dOioyMVMOGDXXgwAHZbDYNHjxYHh4ejnUKCwsd0zejo6O1adMmLViw4KJ9qVevnh5++GElJCRo3rx56tixo3r06KE2bdro3LlzOnLkiF588UWNGzfOsW2bzSaTyXTV+w5I3IwFqBLnQ9t5JSUlpQ48Xl6l/yteeCABAMBV/f74JkmGYchut6tmzZpavXr1Re2+vr46d+6cHnjgAZlMJnXr1k1dunSRj4+PHn744VJ9vb29r7o2Dw8PxzTS8y489v6+b1JSkvbt26etW7dq27ZtevfddzVx4kS1atVKkvTWW2/p+uuvL7VenTp1VFJSoqFDh+rYsWPq2bOn7r//fvn7++vee+919HvhhRcUHR3t2HZMTIyGDx/u2N/Jkyfr1ltvrbB9BySu0QOqxL59+xx/z83N1ZEjR+Tv7+/EigAAqDx+fn4qKipSXl6ebrnlFt1yyy1q2LChEhISlJ2drc8++0yHDh3S0qVLFRsbqy5duujkyZOSdFE4u1oBAQHat29fqRkx58+0/V5WVpYmTJigli1b6sknn9R7772nHj16aOPGjWratKm8vLx06tQpx77cfPPNmjlzpr755ht99913+vzzzzVv3jyNGDFCEREROnv2rGNfTpw4ofHjx6thw4Z67LHH9M477ygmJkYbNmxQ3bp11ahRI+Xm5jq2fcstt+idd97R9u3bK2QcUH0R9IAq8Prrr+vjjz/Wvn37NHr0aLVu3VphYWHOLgsAgErh5+enrl27avTo0dq5c6eysrL03HPPae/evbJYLGrcuLGKioq0ceNG/fjjj/rwww81adIkSX9+qYKPj48OHjyon3/++bI19OzZUzVq1NCLL76orKwsrVu3Tu+///4l+/r6+mrlypWaPn26/vvf/2rXrl3avXu32rRpo9q1a+vBBx/UxIkT9cknnygnJ0cvv/yytm7dqr/+9a9q1KiRPD09tWHDBv3444/asWOHnn/+ece++Pr66qOPPtLEiRN16NAhfffdd/rss8/Upk0bSdLQoUP1xhtvaOPGjTp8+LBef/11vffeezzfD+XG1E2gCjz55JOaMmWKjh49qr/97W+aMmWKs0sCAKBSJSYmKiEhQcOHD5fNZlNQUJAWLFig6667ToGBgXr66ac1ffp0nT17Vs2aNdPzzz+vV199Vd9++60sFssltzlkyBAlJyfrm2++UXJy8p++/nXXXacFCxbo5ZdfVt++fWWxWPToo49ecjppw4YN9cYbb2jatGlauHChateurZ49eyo2NlbSb3fV9PLy0gsvvKCzZ8+qVatWmj9/vuMawldeeUVvvPGG3njjDd14442Kjo7W+++/r2+//VYdO3bU3LlzNWnSJPXr109eXl7q2rWrXnzxRUnSww8/rIKCAk2dOlUnTpxQ8+bNNWvWLLVr164cow9IHkZFnR8HAAAAALgEpm4CAAAAgJth6iYAAACuKZs3b9aYMWP+tE9aWhqPKEC1xtRNAAAAXFPOnTunEydO/Gmfpk2b8rgiVGtM3QQAwImWL1+u1q1bKygoyPEnNTVVNptN8fHxCgsLU1hYmBISEko9SHrTpk2KiIhQYGCgBg4cqOzsbEfb0aNHNWTIEAUFBalr165auXKlE/YMqDy1a9cu9TiCS/0h5KG6I+gBAOBEe/fu1dChQ5Wenu7407dvXyUlJSkzM1ObN2/WmjVrlJaWppSUFEnSwYMHNXbsWE2aNElffvmlgoODNXz4cJWUlEiSRo0aJYvForS0NE2bNk2TJ0/W7t27nbiXAICqRtADAMCJvv32W7Vq1eqi5ampqYqJiVG9evXUpEkTxcbGOs7MrV27Vh07dlRISIhMJpPi4uKUm5ur3bt3y2q1as+ePYqLi5PJZFK7du3Uu3dvzuoBQDVzTd+M5fTpcyop4RJDAHBVNWp4qH792s4uw2UVFRXpwIEDWrVqlSZMmCCz2ay///3vuv/++3X8+PFSzxLz8/NTTk6ObDabsrKySoVDT09PNW3aVJmZmWrQoIGaNGmiOnXqlFp3/fr1V1Qbx1gAcG2XO8Ze00GvpMTgIAQAuGadOnVKbdq0Ub9+/fT6668rMzNTw4YNU1FRkSTJbDY7+prNZhmGoYKCAuXl5cnb27vUtsxms/Ly8lSrVq2L2ry9vZWfn39FtXGMBYBr2zUd9AAAuJY1btxYS5Yscfx86623atCgQVqzZo0kqaCgwNF2Pqj5+PjIbDarsLCw1Lby8/NVu3Zt+fj4lFrv/HZ8fHwqazcAAC6Ia/QAAHCS/fv36/XXXy+1rLCwUI0aNVKjRo1ktVody61Wq5o1ayYvLy/5+/uXarPb7Tp8+LAsFossFotyc3N17ty5Uuv6+/tX/g4BAFwGQQ8AACepXbu25s6dq5UrV6qkpEQZGRlavHix+vfvr8jISCUnJ+vkyZPKzc3VnDlz1KdPH0lSr169tHXrVu3YsUM2m02zZs1Sw4YN1bZtW/n5+alVq1aaNm2aCgsLlZ6ernXr1ikqKsq5OwsAqFJXFPQyMjIUGhrq+Jln/AAAcPVuuukmvfHGG1qyZImCg4M1atQoDR8+XPfee69GjhypW2+9VZGRkYqMjFRoaKhiYmIkSS1atFBiYqImTJigsLAwff3115o9e7Y8PT0lSUlJSfrxxx8VHh6uZ599Vs8//7xCQkKcuasAgCrmYRhGma603rhxo8aNGye73a709HRJ0vTp07Vr1y4lJyeroKBAsbGx6tGjh2JiYnTw4EENGDBA8+bNU5s2bZScnKyPPvpI69atU40aNXT//ferbdu2+sc//qG9e/fqiSee0Lx58xQYGFjm4k+ePMuF4gDgwmrU8ND119e5fEe4HI6xAODaLneMLdPNWGbMmKHt27dr2LBhSkpKcixPTU3VxIkTVa9ePUlSbGysZsyYoZiYmFLP+JGkuLg4LVmyRLt371a9evW0Z88epaSkXPSMnysJeriYb31vmbxqlrm/rbhIZ04XXL4jAABXgOMRADhXmYJedHS0nn76aaWlpTmW/fLLL05/xg8uZvKqqYRts8rcf2znOEkcWAEAFYvjEQA4V5mCXuPGjS9alpeXJ8m5z/gBAAAAAFzsqu+6eT7g8YwfAAAAAHAtVx30fH19ecYPAAAAALigcj1Hj2f8AAAAAIDrKdM1en9k5MiRSkxMVGRkpIqLixUVFXXJZ/wcO3ZMrVu3vugZP/Hx8QoPD1fdunV5xg8AAAAAVJAyP0fPFfGMn4s1anTdFd/l7PjxXyuxIgDVGc/Ru3aV9xjL8QgAKleFPEcP7o1nHQEAAADuhaAHnnUEAAAAuJly3YwFAAAAAOB6CHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAALiAvLw8de/eXSkpKZKkX3/9VSNHjlRISIjCw8M1d+7cUv2XLFmiTp06KSgoSLGxsTpx4oSjbf/+/XrggQcUGBio7t2765NPPqnSfQEAOB9BDwAAFzBhwgTl5OQ4fo6Pj5ckbd++XQsXLtSyZcu0ceNGx7Lk5GTNmzdP//nPf1SvXj2NGTNGkmSz2fTkk0/qnnvu0VdffaXnnntOo0aN0o8//lj1OwUAcBqCHgAATvbBBx8oOztb7dq1k/Tb2b3NmzdrxIgRMpvNslgsGjhwoFasWCFJSk1NVZ8+fRQQECCz2azRo0frs88+U25urtLS0lRQUKBHH31UNWvW1F133aXQ0FCtW7fOmbsIAKhiBD0AAJzoyJEjmjp1qqZMmaIaNX47LOfk5KikpETNmzd39PPz89PBgwclSVlZWfL393e0NWjQQL6+vsrMzFRWVpYsFos8PDwuuS4AoHog6AEA4CR2u13PPfecRo4cqZtuusmx/Ny5czKZTPL09HQs8/b2Vn5+vqTfzvh5e3uX2pbZbFZ+fv4l2y5cFwBQPRD0AABwktmzZ6tx48aKiooqtdzHx0dFRUUqKSlxLCsoKJCPj4+k30JdYWFhqXXy8/Pl4+MjHx8fFRQUlGq7cF0AQPVQ7qCXkZGhAQMGKDg4WF27dtWiRYsk/XYxeHx8vMLCwhQWFqaEhATZ7XbHeps2bVJERIQCAwM1cOBAZWdnl7cUAACuKevXr9e2bdsUEhKikJAQff3115o5c6YWLVokDw+PUsdGq9XqmK7p7+8vq9XqaDt16pR+/vlnWSwWWSwWHTp0qNTrXLguAKB6KFfQKykp0ZNPPqno6Gh9/fXXSk5O1r/+9S/t3LlTSUlJyszM1ObNm7VmzRqlpaU5bhl98OBBjR07VpMmTdKXX36p4OBgDR8+vNRvLgEAcHebNm3Srl27tHPnTu3cuVPBwcEaOXKkEhISdPfdd2v69Ok6e/assrKytHjxYvXp00eSFBUVpRUrVujbb79Vfn6+pkyZovbt26tx48YKCwuTp6en5s6dK5vNpi1btigtLU09e/Z07s4CAKpUuYLemTNndOLECZWUlKikpEQeHh6qUaOGatasqdTUVMXExKhevXpq0qSJYmNjtXLlSknS2rVr1bFjR4WEhMhkMikuLk65ubnavXt3RewTAADXvFdeeUXe3t6666679Mgjj+iBBx5QZGSkJKlTp04aMWKE4uLiFB4ertOnT2vq1KmSJJPJpHnz5mnbtm264447NHXqVM2YMUM333yzM3cHAFDFvMqzcv369fXQQw/phRde0Isvvii73a64uDg1b95cx48fl8VicfT18/NTTk6ObDabsrKy1KpVK0ebp6enmjZtqszMTMetpQEAqG7OX/4gSb6+vpo+ffof9o2OjlZ0dPQl2wICArR06dIKrw8AcO0oV9ArKSmR2WzW1KlTdc899yg9PV1PPfWUbrzxRkm/XSx+ntlslmEYKigo+MO7heXl5ZWnHAAAAACAyjl188MPP1RaWpp69+4tk8mksLAw9evXT6mpqZJU6q5f52/r7OPj84d3C6tdu3Z5ygEAAAAAqJxB78iRI7LZbKWWeXl5qUGDBmrUqFGpO4JZrVY1a9ZMXl5eF90tzG636/Dhw6WmegIAAAAArk65gl54eLisVquWLVsmwzC0Z88erVixQj179lRkZKSSk5N18uRJ5ebmas6cOY67hfXq1Utbt27Vjh07ZLPZNGvWLDVs2FBt27atiH0CAAAAgGqtXNfoBQQEKDk5WTNnztS0adPUsGFD/eMf/9Ddd9+tO++8U4mJiYqMjFRxcbGioqIUExMjSWrRooUSExM1YcIEHTt2TK1bt9bs2bPl6elZITsFAAAAANVZuYKe9Nstnjt16nTR8lq1amncuHEaN27cJdeLiIhQREREeV8eAAAAAPA75Zq6CQAAAABwPeU+o4fK41vfWyavmmXubysuqsRqAAAAAFwrCHouzORVUwnbZpW5/9jOcZVYDQAAAIBrBVM3AQAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzfB4BVyVq3nG35nTBZVYEQAAAIDzCHq4Klf3jD+CHgAAAFAVmLoJAAAAAG6GoAcAAAAAboagBwAAAABuhqAHAAAAAG6GoAcAAAAAboagBwAAAABuhqAHAAAAAG6GoAcAAAAAboagBwCAE23dulW9e/dWUFCQunXrpnfffVeSZLPZFB8fr7CwMIWFhSkhIUF2u92x3qZNmxQREaHAwEANHDhQ2dnZjrajR49qyJAhCgoKUteuXbVy5cqq3i0AgJMR9AAAcJIjR44oLi5Ozz//vNLT05WUlKRJkyYpIyNDSUlJyszM1ObNm7VmzRqlpaUpJSVFknTw4EGNHTtWkyZN0pdffqng4GANHz5cJSUlkqRRo0bJYrEoLS1N06ZN0+TJk7V7924n7ikAoKoR9AAAcJIbbrhBn3/+uTp06KCSkhKdPn1anp6eqlOnjlJTUxUTE6N69eqpSZMmio2NdZyZW7t2rTp27KiQkBCZTCbFxcUpNzdXu3fvltVq1Z49exQXFyeTyaR27dqpd+/enNUDgGrGy9kFAABQndWpU0dnz55VaGio7Ha7nnjiCTVs2FDHjx+XxWJx9PPz81NOTo5sNpuysrLUqlUrR5unp6eaNm2qzMxMNWjQQE2aNFGdOnVKrbt+/foq3S8AgHMR9AAAcDKz2azdu3dr3759evzxx+Xt7e1YfmEfwzBUUFCgvLw8R58L2/Py8lSrVq2L2ry9vZWfn1/5OwIAcBnlnrr5008/adiwYQoODlZ4eLhmzpwpqXwXkQMAUJ14enrKZDKpTZs26t+/vzIyMiRJBQUFjj7ng5qPj4/MZrMKCwtLbSM/P1+1a9eWj49PqfXOb8fHx6eS9wIA4ErKHfSGDRum//mf/9Hnn3+ud999V6mpqVq/fn25LiIHAKA6+PzzzzVgwIBSy4qKilS3bl01atRIVqvVsdxqtapZs2by8vKSv79/qTa73a7Dhw/LYrHIYrEoNzdX586dK7Wuv79/5e8QAMBllCvoffPNN8rJydELL7wgk8mkm2++WYsWLVJoaOhVX0QOAEB10apVKx0+fFgLFy6U3W7Xzp07lZqaqv79+ysyMlLJyck6efKkcnNzNWfOHPXp00eS1KtXL23dulU7duyQzWbTrFmz1LBhQ7Vt21Z+fn5q1aqVpk2bpsLCQqWnp2vdunWKiopy7s4CAKpUuYLe3r17FRAQoFmzZqlDhw6666679OGHH8rb2/uyF5Ff+JvFCy8iBwCguqhXr57mzZunjRs3KjQ0VOPHj9fEiRMVGhqqkSNH6tZbb1VkZKQiIyMVGhqqmJgYSVKLFi2UmJioCRMmKCwsTF9//bVmz54tT09PSVJSUpJ+/PFHhYeH69lnn9Xzzz+vkJAQZ+4qAKCKletmLGfOnFF6errCwsK0ZcsWWa1WDRkyRA0aNJB0dReRAwBQndx+++2Oh6RfqFatWho3bpzGjRt3yfUiIiIUERFxyba//OUvmjt3boXWCQC4tpQr6JlMJpnNZo0YMUIeHh5q2bKl+vXrp9TUVElXdxE5AAAAAKB8yjV108/PTyUlJSouLnYsKy4ulq+v71VfRA4AAAAAKJ9yBb3w8HDVrVtXM2bMkM1m0759+7Rq1Sr17Nnzqi8iBwAAAACUT7mmbtaqVUuLFy/Wq6++qjvvvFMmk0kxMTG655571LlzZyUmJioyMlLFxcWKioq65EXkx44dU+vWrUtdRA4AAAAAuHrlCnqSdPPNN1/ygu/yXEQOAAAAALh65X5gOgAAAADAtRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzXg5u4DqwLe+t0xeNcvc31ZcpDOnCyqxIgAAAADujKBXBUxeNZWwbVaZ+4/tHCeJoAcAAADg6jB1EwAAAADcDEEPAAAAANwMQQ8AAAAA3AxBDwAAJ8rIyFB0dLRCQkLUuXNnJSUlyTAM2Ww2xcfHKywsTGFhYUpISJDdbnest2nTJkVERCgwMFADBw5Udna2o+3o0aMaMmSIgoKC1LVrV61cudIJewYAcCaCHgAATnLu3Dk98cQT6tGjh9LS0rRgwQKtXr1aS5cuVVJSkjIzM7V582atWbNGaWlpSklJkSQdPHhQY8eO1aRJk/Tll18qODhYw4cPV0lJiSRp1KhRslgsSktL07Rp0zR58mTt3r3biXsKAKhqBD0AAJzk6NGjateunQYOHChPT081a9ZM3bp1065du5SamqqYmBjVq1dPTZo0UWxsrOPM3Nq1a9WxY0eFhITIZDIpLi5Oubm52r17t6xWq/bs2aO4uDiZTCa1a9dOvXv35qweAFQzFRb08vLy1L17d8dvG3/99VeNHDlSISEhCg8P19y5c0v1X7JkiTp16qSgoCDFxsbqxIkTFVUKAADXBH9/fyUnJzt+ttls+vTTT9WyZUsdP35cFovF0ebn56ecnBzZbDZlZWXJ39/f0ebp6ammTZsqMzNTVqtVTZo0UZ06dUqte/DgwarZKQCAS6iwoDdhwgTl5OQ4fo6Pj5ckbd++XQsXLtSyZcu0ceNGx7Lk5GTNmzdP//nPf1SvXj2NGTOmokqBC/Ot761Gja4r8x/f+t7OLhkAqoTNZtMzzzwjk8mkHj16SJLMZrOj3Ww2yzAMFRQUKC8vT97epT8fzWaz8vLydO7cuYvavL29lZ+fX/k7AQBwGRXywPQPPvhA2dnZateunaTfzu6dv6bAbDbLYrFo4MCBWrFihXr06KHU1FT16dNHAQEBkqTRo0erffv2ys3NVePGjSuiJLgoHh4PABc7fvy4RowYIUl6++23VaPGb7+HLSj4v8+/80HNx8dHZrNZhYWFpbaRn5+v2rVry8fHp9R657fj4+NTmbsAAHAx5T6jd+TIEU2dOlVTpkxxHJhycnJUUlKi5s2bO/pdOG3k91NOGjRoIF9fX2VmZpa3HAAArikHDhzQfffdp2bNmmnhwoWqX7++fH191ahRI1mtVkc/q9WqZs2aycvLS/7+/qXa7Ha7Dh8+LIvFIovFotzcXJ07d67UuhcedwEA7q9cQc9ut+u5557TyJEjddNNNzmWnzt3TiaTSZ6eno5lF04b+aMpJ0wrAQBUJ6dPn9bgwYPVq1cvTZ48WSaTydEWGRmp5ORknTx5Urm5uZozZ4769OkjSerVq5e2bt2qHTt2yGazadasWWrYsKHatm0rPz8/tWrVStOmTVNhYaHS09O1bt06RUVFOWkvAQDOUK6pm7Nnz1bjxo0vOnj4+PioqKhIJSUlpaafnJ828kdTTphWAgCoTlavXq3jx49r6dKlWrZsmWP5nXfeqalTpyoxMVGRkZEqLi5WVFSUYmJiJEktWrRQYmKiJkyYoGPHjql169aaPXu24xesSUlJio+PV3h4uOrWravnn39eISEhTtlHAIBzlCvorV+/Xj/99JPj4JGXl6dvvvlGmZmZ8vDwUHZ2tvz8/CSVnjby+yknp06d0s8//1zq7mIAALi7xx57TI899tgfto8bN07jxo27ZFtERIQiIiIu2faXv/zlortdAwCql3IFvU2bNpX6edCgQercubOGDBmivLw8TZ8+XYmJicrNzdXixYv19NNPS5KioqI0ZswYde/eXX5+fpoyZYrat2/PjVgAAAAAoAJU2gPTX3nlFXl7e+uuu+7SI488ogceeECRkZGSpE6dOmnEiBGKi4tTeHi4Tp8+ralTp1ZWKQAAAABQrVTI4xXOW7RokePvvr6+mj59+h/2jY6OVnR0dEW+PAAAAABAlXhGDwAAAADgHAQ9AAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAzBD0AAAAAcDMEPQAAAABwMwQ9AAAAAHAzBD0AAAAAcDMEPQAAAABwM17OLgC4HN/63jJ51Sxzf1txkc6cLqjEigAAAADXRtCDyzN51VTCtlll7j+2c5wkgh4AAACqL6ZuAgAAAICbIegBAAAAgJsh6AEA4AIyMjIUGhrq+Nlmsyk+Pl5hYWEKCwtTQkKC7Ha7o33Tpk2KiIhQYGCgBg4cqOzsbEfb0aNHNWTIEAUFBalr165auXJlVe4KAMAFlDvoZWRkKDo6WiEhIercubOSkpJkGEa5DlAAAFQnGzdu1ODBg1VUVORYlpSUpMzMTG3evFlr1qxRWlqaUlJSJEkHDx7U2LFjNWnSJH355ZcKDg7W8OHDVVJSIkkaNWqULBaL0tLSNG3aNE2ePFm7d+92xq4BAJykXEHv3LlzeuKJJ9SjRw+lpaVpwYIFWr16tZYuXVquAxQAANXFjBkzNH/+fA0bNqzU8tTUVMXExKhevXpq0qSJYmNjHWfm1q5dq44dOyokJEQmk0lxcXHKzc3V7t27ZbVatWfPHsXFxclkMqldu3bq3bs3Z/UAoJopV9A7evSo2rVrp4EDB8rT01PNmjVTt27dtGvXrqs+QAEAUJ1ER0dr1apVat26tWPZL7/8ouPHj8tisTiW+fn5KScnRzabTVlZWfL393e0eXp6qmnTpsrMzJTValWTJk1Up06dUusePHiwanYIAOASyhX0/P39lZyc7PjZZrPp008/VcuWLa/6AAUAQHXSuHHji5bl5eVJksxms2OZ2WyWYRgqKChQXl6evL29S61jNpuVl5enc+fOXdTm7e2t/Pz8SqgeAOCqKuxmLDabTc8884xMJpN69Ogh6eoOUAAAVHfnj58FBf/3TNDzQc3Hx0dms1mFhYWl1snPz1ft2rXl4+NTar3z2/Hx8ankqgEArqRCgt7x48f18MMP68SJE3r77bcd00Wu5gAFAEB15+vrq0aNGslqtTqWWa1WNWvWTF5eXvL39y/VZrfbdfjwYVksFlksFuXm5urcuXOl1r1wJg0AwP2VO+gdOHBA9913n5o1a6aFCxeqfv365TpAAQAAKTIyUsnJyTp58qRyc3M1Z84c9enTR5LUq1cvbd26VTt27JDNZtOsWbPUsGFDtW3bVn5+fmrVqpWmTZumwsJCpaena926dYqKinLuDgEAqpRXeVY+ffq0Bg8erMjISI0ePbpU2/kD1K233qri4uKLDlAPPPCAduzYof/93/9VcnKy4wDl6nzre8vkVbPM/W3FRZfvBADA74wcOVKJiYmKjIxUcXGxoqKiFBMTI0lq0aKFEhMTNWHCBB07dkytW7fW7Nmz5enpKem3RzPEx8crPDxcdevW1fPPP6+QkBBn7g4AoIqVK+itXr1ax48f19KlS7Vs2TLH8jvvvFNTp0696gOUKzN51VTCtlll7j+2c1wlVgMAcBdhYWFKT093/FyrVi2NGzdO48aNu2T/iIgIRUREXLLtL3/5i+bOnVspdQIArg3lCnqPPfaYHnvssT9sv9oDFAAAAADg6lXYXTcBAAAAAK6BoAcAAAAAbqZcUzcBV3U1N805c7rg8h0BAACAawBBD27p6m6aQ9ADAACAe2DqJgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBkvZxcAuBLf+t4yedUsc39bcZHOnC6oxIoAAABwrXCl75IEPeACJq+aStg2q8z9x3aOk0TQAwAAgGt9l2TqJgAAAAC4GYIeAAAAALgZpm4C5eRKc7EBAAAAyclBb//+/YqPj9e+ffvUpEkTjR07Vp06dXJmScAVu5q52L71RTgEUKk4xgJA9ea0oGez2fTkk09q0KBBWrRokT799FONGjVK69ev14033uissoAq4UoX6gJwPxxjAQBOu0YvLS1NBQUFevTRR1WzZk3dddddCg0N1bp165xVEuDSfOt7q1Gj68r8x7e+t7NLBuAkHGMBAE47o5eVlSWLxSIPDw/HMj8/Px08eLDKariaa6sAZ+EsIICycoVjLADAuZwW9PLy8uTtXfqMg7e3t/Lz88u8jRo1PC7f6U+YvGrqjS/eLnP/YXc8Jkny9b7uil/rStc5v29V8VpVtY6r75Or13c169So4aHrfGtd1S80rnSdX88UXlFtqB7K+zmNq+MKx1jp6j+HAeBaVlWffZdbz8MwDOOqtlxOCxYs0Mcff6xFixY5liUmJur48eOaNm2aM0oCAMAtcIwFADjtGj2LxaJDhw6VWma1WuXv7++kigAAcA8cYwEATgt6YWFh8vT01Ny5c2Wz2bRlyxalpaWpZ8+ezioJAAC3wDEWAOC0qZuSdODAAb388svat2+fGjdurNGjR6tLly7OKgcAALfBMRYAqjenBj0AAAAAQMVz2tRNAAAAAEDlIOgBAAAAgJsh6AEAAACAmyHoAQAAAICbIeg5QUZGhqKjoxUSEqLOnTsrKSlJhmHIZrMpPj5eYWFhCgsLU0JCgux2u7PLdRl5eXnq3r27UlJSJEm//vqrRo4cqZCQEIWHh2vu3LlOrtA1/PTTTxo2bJiCg4MVHh6umTNnShLvrz+QkZGhAQMGKDg4WF27dnU8YJrxulhGRoZCQ0MdP19ujDZt2qSIiAgFBgZq4MCBys7OdkLVqAz79+/XAw88oMDAQHXv3l2ffPLJJfsdPXpUQ4YMUVBQkLp27aqVK1dWcaWVr6xjkZ2draFDhyo0NFQdOnTQq6++qsLCwiqutvKUdRzOKykp0cCBA/XKK69UUYVVp6xjcfbsWY0ZM0ahoaEKCwvTuHHjVFRUVMXVVp6yjsOhQ4f06KOPKiQkRHfeeadmzJghd7xX5O+Pob9XKZ+XBqrU2bNnjTvuuMNYtGiRUVxcbBw6dMjo2rWrsXjxYmPatGlGdHS0cfr0aePo0aNGVFSU8eabbzq7ZJcxduxYo2XLlsb8+fMNwzCMp59+2oiLizPy8vKMzMxMo3PnzsaGDRucXKXz3XfffUZ8fLxRWFhoHD582OjUqZOxbt063l+XYLfbjfbt2xupqamGYRjGd999ZwQGBhpfffUV4/U7GzZsMIKDg43AwEDHsj8bowMHDjjGsrCw0PjXv/5l9OjRw7Db7c7aBVSQwsJCo0uXLsZbb71l2Gw246OPPjICAwONH3744aK+AwYMMCZOnGgUFhYaX3/9tRESEmKkp6dXfdGV5ErG4t577zWmTJliFBYWGrm5ucZ9991nJCYmOqHqincl43De66+/brRs2dIYP358FVZa+a5kLEaMGGE8+eSTxq+//mqcOHHC6Nu3rzFnzhwnVF3xrmQc+vXrZyQnJxt2u904fPiw0bFjR8dx2V1c6hj6e5XxeckZvSp29OhRtWvXTgMHDpSnp6eaNWumbt26adeuXUpNTVVMTIzq1aunJk2aKDY21i1/+3k1PvjgA2VnZ6tdu3aSfju7t3nzZo0YMUJms1kWi0UDBw7UihUrnFypc33zzTfKycnRCy+8IJPJpJtvvlmLFi1SaGgo769LOHPmjE6cOKGSkhKVlJTIw8NDNWrUUM2aNRmvC8yYMUPz58/XsGHDSi3/szFau3atOnbsqJCQEJlMJsXFxSk3N1e7d+92wh6gIqWlpamgoECPPvqoatasqbvuukuhoaFat25dqX5Wq1V79uxRXFycTCaT2rVrp969e7vV/6OyjsWpU6f0l7/8RcOGDZPJZNL//M//KCoqSrt27XJS5RWrrONwXnp6ujZs2KBu3bpVcaWVr6xj8dNPP+njjz/WK6+8ojp16uj666/XG2+8oV69ejmp8op1Je8Jq9XqOA5LkoeHh2rVqlXVJVeaPzqGXqiyPi8JelXM399fycnJjp9tNps+/fRTtWzZUsePH5fFYnG0+fn5KScnRzabzRmluowjR45o6tSpmjJlimrU+O0tm5OTo5KSEjVv3tzRz8/PTwcPHnRWmS5h7969CggI0KxZs9ShQwfddddd+vDDD+Xt7c376xLq16+vhx56SC+88IJuu+02RUVFafDgwWrevDnjdYHo6GitWrVKrVu3diz75Zdf/nSMsrKy5O/v72jz9PRU06ZNlZmZWaW1o+JlZWXJYrHIw8PDsexSn79Wq1VNmjRRnTp1/rTftaysY9GgQQOlpKSodu3akiTDMPTxxx+rZcuWVVpvZSnrOEj/N11x8uTJ8vHxqcoyq0RZx+L7779X48aNtW7dOnXt2lUdO3bUkiVL1Lhx46ouuVJcyXviySef1BtvvKE2bdro7rvvVvv27XXvvfdWZbmV6lLH0N+rrM9Lgp4T2Ww2PfPMMzKZTOrRo4ckyWw2O9rNZrMMw1BBQYGzSnQ6u92u5557TiNHjtRNN93kWH7u3DmZTCZ5eno6lnl7eys/P98ZZbqMM2fOKD09XSaTSVu2bFFycrJSUlK0ZcsWSby/fq+kpERms1lTp07V7t27tXDhQi1YsIDx+p1LffHIy8uT9MdjlJeXJ29v71LrmM1mx3q4dl3q3/ZSn7/nzp0rU79rWVnH4kIlJSWaMGGCsrOzNXz48MousUpcyTjEx8crKipKbdq0qaryqlRZx+Lnn3/WsWPHlJmZqXXr1mnJkiX6+OOPNX/+/Kost9JcyXvCy8tLo0ePVnp6ulavXq3//Oc/evfdd6uq1EpXlvBeWZ+XBD0nOX78uB5++GGdOHFCb7/9tiPBX/gl8vw/rjv+xqusZs+ercaNGysqKqrUch8fHxUVFTlO80u/jV11HitJMplMMpvNGjFihEwmk1q2bKl+/fopNTVVEu+v3/vwww+Vlpam3r17y2QyKSwsjPEqo/MB74/GyGw2X3Sjifz8fMcZDVy7fHx8LvqFx6U+f8va71p2pft49uxZDR8+XP/5z3+0aNEiNWrUqCrKrHRlHYfVq1fryJEjeuKJJ6qyvCpV1rEwmUyOX2bXrl1bN998sx5++GH9+9//rspyK01Zx2Hv3r2aP3++HnnkEdWqVUutWrXS4MGDtXz58qos1+kq6/OSoOcEBw4c0H333admzZpp4cKFql+/vnx9fdWoUSNZrVZHP6vVqmbNmsnLy8uJ1TrX+vXrtW3bNoWEhCgkJERff/21Zs6cqUWLFsnDw6PUXfysVmupqWLVkZ+fn0pKSlRcXOxYVlxczPvrDxw5cuSiqZheXl5q0KAB43UZl3tP+fv7l2qz2+06fPhwqameuDZZLBYdOnSo1LJLff5aLBbl5ubq3Llzf9rvWlbWsZCk3Nxc3X///SoqKtLy5ct18803V1WZla6s47Bu3Trt27dPYWFhCgkJ0fr167V8+XK3Cn5lHQs/Pz9JKnUMcqc7O5d1HI4cOXLRnUa9vLyq3bG2sj4vCXpV7PTp0xo8eLB69eqlyZMny2QyOdoiIyOVnJyskydPKjc3V3PmzFGfPn2cV6wL2LRpk3bt2qWdO3dq586dCg4O1siRI5WQkKC7775b06dP19mzZ5WVlaXFixdX+/EKDw9X3bp1NWPGDNlsNu3bt0+rVq1Sz549eX9dQnh4uKxWq5YtWybDMLRnzx6tWLGC8SqjPxujXr16aevWrdqxY4dsNptmzZqlhg0bqm3bts4tGuUWFhYmT09PzZ07VzabTVu2bFFaWpp69uxZqp+fn59atWqladOmqbCwUOnp6Vq3bt1FMzSuZWUdC5vNpqFDh6pFixZ68803dd111zmp4spR1nFISUlRenq645jeq1cvDRgwQG+++aaTKq94ZR2LFi1a6LbbblNiYqLy8vL0ww8/aOHChW5zM5ayjsP5m+y99tprKi4uVnZ2tt5+++2L+rm7Svu8LNc9O3HF3nrrLSMgIMBo27atERgY6PgzYsQIo6CgwBg/frzRvn17IzQ01Jg4caJRXFzs7JJdysCBAx2PV/j555+NZ555xggNDTXCw8Pd5pbE5XX48GHj8ccfN0JDQ40OHTo4xov316Vt27bN6Nu3r9GuXTsjIiLCWL58uWEYjNelfPHFF6VuDX25Mdq8ebPRvXt3IzAw0HjooYcMq9XqjLJRCfbv3288+OCDRlBQkNG9e3djy5YthmEYxpo1a0q9R44cOWI8/vjjRnBwsNGlSxfj/fffd1bJlaYsY7F582YjICDAaNOmTalj/3333efM0itUWd8TF3r++efd7vEKhlH2sTh58qTxzDPPGH/729+MsLAwY8qUKW51nCnrOKSnpxsPPvig43Nizpw5bvkont8fQ6vi89LDMNzwiYQAAAAAUI0xdRMAAAAA3AxBDwAAAADcDEEPAAAAANwMQQ8AAAAA3AxBDwAAAADcDEEPAAAAANwMQQ8AAAAA3AxBDwAAAADcDEEPAAAAANwMQQ8AAAAA3AxBDwAAAADcDEEPAAAAANwMQQ8AAAAA3AxBDwAAAADcDEEPAAAAANwMQQ8AAAAA3AxBDwAAAADcDEEPAAAAANwMQQ/VSosWLbR161Znl+Fw6tQprVu3rkpea8yYMYqLi6uS1wIAoLL98MMP+uijj8q1fosWLXTgwIEKrApwHV7OLgCozqZOnapz586pd+/elf5a//znP2UYRqW/DgAAVWHs2LG67bbbdPfddzu7FMAlEfQAJ6rK4HXddddV2WsBAADAuZi6iWpn79696t+/v26//Xb16tVLX331lSRp3rx56ty5c6nw9cUXXygwMFDnzp3TmDFjNG7cOD377LNq27atunXrpjVr1pTa9urVq3XPPfeobdu26tu3r7Zt2+ZoGzNmjP7xj3/o73//u0JDQ/Xggw8qNTVVmzdvVosWLSRJRUVFmjZtmsLDwxUcHKwhQ4bIarU6tjFo0CDNmjVLTz75pNq0aaNOnTrp/fffd7Tv3LlT/fv3V5s2bdShQwdNmTJFdrvd8foXTt38/PPPNWDAAAUGBqpLly6aP3++Y99XrVqlfv36ad68eQoPD1dgYKCeffZZ5eXlVdC/AgAAZfPee++pW7duuu2229S9e3etXr1aY8aM0Zdffqm33npLXbt2lfTb5Rmvvfaa2rdvr8jISNntduXk5GjYsGH63//9X4WFhenFF1/U2bNnL/k6H3/8sW6//XZt2rRJknT27Fm99NJLCg0NVVhYmOLi4pSbm1tl+w2UF0EP1c6yZcs0YsQIrVu3TjfddJOeffZZGYah3r17Kzc3V+np6Y6+GzZs0F133aXatWtL+i0A1alTR6tWrdJDDz2kMWPG6IsvvpAkbd++XRMnTtTIkSO1bt063X///YqLiyu1vfXr1+uhhx7SO++8o3nz5unee+9Vly5d9Nlnn0mSZs2apU8//VSvvfaali9frubNm2vQoEH69ddfHduYN2+e7rzzTm3YsEHdunXT+PHjdeLECdntdg0fPlx33HGHNm7cqKlTp+r999/XqlWrLhqDnTt3aujQoercubNSU1P19NNP64033tDSpUsdfQ4cOKBdu3bpnXfe0cyZM/XRRx9p+fLlFfuPAQDAn/juu+/08ssv69lnn9XmzZv18MMPa8yYMXr00UcVFBSkBx98UCtWrHD037BhgxYuXKjExESdPXtW0dHR8vLy0pIlS5SUlKSvv/5aL7zwwkWv8+WXX+rZZ5/Vq6++qu7du0uSxo0bp+zsbKWkpGjRokXy8PDQ0KFDVVxcXGX7D5QHUzdR7Tz++OPq1KmTJGno0KF66KGHdOrUKTVp0kT/+7//q40bN6pdu3YqKirSv//9b02ZMsWx7o033qj4+HjVqFFDFotFX375pd59913dcccdevPNNzVkyBD16NFDktS0aVN9++23evvttxUUFCRJat68ufr06ePYnre3t0pKStSoUSMVFBRowYIFeuedd9SuXTtJ0osvvqjt27dr7dq1euihhyRJYWFhio6OliSNGjVKixYt0r59+3TbbbfpzJkzatiwoW688UbddNNNSklJ0fXXX3/RGCxcuFAdOnTQsGHDHHUdO3ZMc+bMcbxOUVGRXn31VTVs2FD+/v668847tWfPnor8pwAA4E/9+OOP8vDw0F/+8hfdeOONio6O1i233KIbbrhBNWvWlNlsVoMGDRz9//73v8vf31+StHjxYtntdk2ZMkXe3t6SpMmTJ2vAgAHKzs6Wl9dvX4O/++47TZgwQWPGjHEco//73/9qw4YN+vTTT9W4cWNJv11XHxYWps8++0ydO3euukEArhJBD9XOzTff7Ph73bp1JUkFBQWSpKioKM2YMUMvvPCCtm/frho1aig8PNzRPygoSDVq/N+J8DZt2jjumnnw4EF98803evPNNx3tRUVFat68+SVf+/cOHz4sm82mwYMHy8PDw7G8sLCw1PTNZs2aOf5ep04dSVJxcbHq1aunhx9+WAkJCZo3b546duyoHj16qE2bNhe9VmZm5kU3gAkODtb06dP1yy+/SJJq166thg0blnotpm4CAKrSnXfeqTZt2mjAgAHy8/NT586d1bdvX8fx+/cuPM5mZmaqVatWjpAnSbfffrtq1qypzMxMtWzZUpL00ksvqaioSDfccEOpdSU5zu6dl5+fL6vVStDDNYGgh2rH09PzomXnr02755579Morr2jnzp3asGGDevTo4fiN36XWtdvtjuBnt9v17LPPqkuXLqX6XLj+hQeb3zt/Ld1bb7110Vm484FOkmrWrPmH9b/wwguKjo7W1q1btW3bNsXExGj48OF66qmnSvWvVavWH27jfB2Xeh0AAKqSt7e3li1bpvT0dH3yySfasmWLFi9erDlz5vxh//Mudaw77/yxTpJiYmJ06tQpjR8/Xhs2bJC3t7fsdrtq1qyp1atXX7Sur6/v1e8QUIW4Rg+4QJ06ddSlSxf9+9//1vbt2y866/Xdd9+V+jkjI8PxG0GLxaIff/xRt9xyi+PP+vXrtWHDhj98vQvP3DVt2lReXl46deqUY/2bb75ZM2fO1DfffHPZ2k+cOKHx48erYcOGeuyxx/TOO+8oJibmkq/v5+dX6tpBSdq1a5euv/561atX77KvBQBAVUhPT1dSUpLatWunp59+WuvWrVPr1q3173//+7LrWiwWff/9945ZO5K0Z88eFRUVyWKxOJbdc889evrpp5Wfn6/XX39d0m/HyaKiIuXl5TmOyQ0bNlRCQoKys7MrfD+BykDQA34nKipKy5cvl6+vrwIDA0u1fffdd5oxY4YOHTqklJQUbd++XYMGDZL02/V+7777rpYtW6bDhw9r2bJlSk5O1k033fSHr+Xj46Mff/xRP/zwg2rXrq0HH3xQEydO1CeffKKcnBy9/PLL2rp1q/76179etm5fX1999NFHmjhxog4dOqTvvvtOn3322SWnbg4dOlSfffaZ3njjDR06dEjr16/Xm2++qUGDBpUKnwAAOJPZbNabb76phQsX6ocfftBnn32mrKwstWnTRrVr11ZOTs4f3gmzd+/eqlWrlkaPHq0DBw7oq6++0gsvvKD27ds7ruM7r27duvrHP/6ht99+W/v375efn5+6du2q0aNHa+fOncrKytJzzz2nvXv3lgqJgCsj6AG/c+edd8psNl/yIeYdOnRQTk6OoqKilJqaquTkZEeQ6tatm1566SUtWLBAPXr00IIFC/TKK684bs5yKX379tWJEyfUs2dPHT9+XKNHj9Y999yjF154QZGRkTpw4IDmz5//p9f2nVezZk3NnTtXP/zwg/r166dHHnlE/v7+evHFFy/q26pVKyUlJWnTpk3q3bu3XnvtNT311FOKjY29gpECAKBytWzZUlOnTtXy5ct177336p///Kcee+wx3XfffXrwwQe1a9cuRUZGqqSk5KJ1zWazUlJSdPbsWfXv318jRoxQSEiIkpKSLvlaffv2VZs2bRQfHy/DMJSYmKjbbrtNw4cPV//+/R03TeO5tLhWeBhV+cRm4Bpw5swZdejQQevXr9ctt9ziWD5mzBjl5eVp1qxZTqwOAAAAuDxuxgL8f/n5+fr000+1fv16BQcHlwp5AAAAwLWEoAf8f56ennrppZdUv359zZ4929nlAAAAAFeNqZsAAAAA4Ga4GQsAAAAAuBmCHgAAAAC4GYIeAABOtHz5crVu3VpBQUGOP6mpqbLZbIqPj1dYWJjCwsKUkJAgu93uWG/Tpk2KiIhQYGCgBg4cWOohzkePHtWQIUMUFBSkrl27auXKlU7YMwCAM13TN2M5ffqcSkq4xBAAXFWNGh6qX7+2s8twaXv37tXQoUP19NNPl1o+ffp0ZWZmavPmzSooKFBsbKxSUlIUExOjgwcPauzYsZo3b57atGmj5ORkDR8+XOvWrVONGjU0atQotW3bVrNnz9bevXv1xBNPyGKxKDAwsMx1cYwFANd2uWPsNR30SkoMDkIAgGvat99+q8cff/yi5ampqZo4caLq1asnSYqNjdWMGTMUExOjtWvXqmPHjgoJCZEkxcXFacmSJdq9e7fq1aunPXv2KCUlRSaTSe3atVPv3r21cuXKKwp6HGMB4NrG1E0AAJykqKhIBw4c0KpVq9ShQwd169ZNc+fO1ZkzZ3T8+HFZLBZHXz8/P+Xk5MhmsykrK0v+/v6ONk9PTzVt2lSZmZmyWq1q0qSJ6tSpU2rdgwcPVum+AQCc65o+owcAwLXs1KlTatOmjfr166fXX39dmZmZGjZsmIqKiiRJZrPZ0ddsNsswDBUUFCgvL0/e3t6ltmU2m5WXl6datWpd1Obt7a38/PzK3yEAgMsg6AEA4CSNGzfWkiVLHD/feuutGjRokNasWSNJKigocLSdD2o+Pj4ym80qLCwsta38/HzVrl1bPj4+pdY7vx0fH5/K2g0AgAti6iYAAE6yf/9+vf7666WWFRYWqlGjRmrUqJGsVqtjudVqVbNmzeTl5SV/f/9SbXa7XYcPH5bFYpHFYlFubq7OnTtXat0Lp3oCANwfQQ8AACepXbu25s6dq5UrV6qkpEQZGRlavHix+vfvr8jISCUnJ+vkyZPKzc3VnDlz1KdPH0lSr169tHXrVu3YsUM2m02zZs1Sw4YN1bZtW/n5+alVq1aaNm2aCgsLlZ6ernXr1ikqKsq5OwsAqFIehmFcs7fUOnnyLHcEAwAXVqOGh66/vs7lO1Zjn332mf71r3/p0KFDql+/voYMGaKHHnpIhYWFSkxM1ObNm1VcXKyoqCg9//zz8vT0lCT9+9//1owZM3Ts2DG1bt1ar776qpo3by7pt+foxcfHa9euXapbt66GDRum/v37X1FdHGMBwLVd7hhbrYOeb31vmbxqlrm/rbhIZ04XXL4jAEASQe9axjEWAFzb5Y6x1fpmLCavmkrYNqvM/cd2jpPEQQgAgMvhGAsAzsU1egAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZgh6AAAAAOBmCHoAAAAA4GYIegAAAADgZsoc9PLy8tS9e3elpKRIkn799VeNHDlSISEhCg8P19y5c0v1X7JkiTp16qSgoCDFxsbqxIkTjrb9+/frgQceUGBgoLp3765PPvmkgnYHAAAAAFDmoDdhwgTl5OQ4fo6Pj5ckbd++XQsXLtSyZcu0ceNGx7Lk5GTNmzdP//nPf1SvXj2NGTNGkmSz2fTkk0/qnnvu0VdffaXnnntOo0aN0o8//liR+wUAAAAA1VaZgt4HH3yg7OxstWvXTtJvZ/c2b96sESNGyGw2y2KxaODAgVqxYoUkKTU1VX369FFAQIDMZrNGjx6tzz77TLm5uUpLS1NBQYEeffRR1axZU3fddZdCQ0O1bt26yttLAAAAAKhGLhv0jhw5oqlTp2rKlCmqUeO37jk5OSopKVHz5s0d/fz8/HTw4EFJUlZWlvz9/R1tDRo0kK+vrzIzM5WVlSWLxSIPD49LrgsAAAAAKJ8/DXp2u13PPfecRo4cqZtuusmx/Ny5czKZTPL09HQs8/b2Vn5+vqTfzvh5e3uX2pbZbFZ+fv4l2y5cFwAAAABQPn8a9GbPnq3GjRsrKiqq1HIfHx8VFRWppKTEsaygoEA+Pj6Sfgt1hYWFpdbJz8+Xj4+PfHx8VFBQUKrtwnUBAAAAAOXj9WeN69ev108//aSQkBBJv52p++abb5SZmSkPDw9lZ2fLz89PkmS1Wh3TNf39/WW1Wh3bOXXqlH7++WdZLBbZ7XbNnz+/1OtYrVYFBQVV6I4BAAAAQHX1p2f0Nm3apF27dmnnzp3auXOngoODNXLkSCUkJOjuu+/W9OnTdfbsWWVlZWnx4sXq06ePJCkqKkorVqzQt99+q/z8fE2ZMkXt27dX48aNFRYWJk9PT82dO1c2m01btmxRWlqaevbsWRX7CwAAAABu76ofmP7KK6/I29tbd911lx555BE98MADioyMlCR16tRJI0aMUFxcnMLDw3X69GlNnTpVkmQymTRv3jxt27ZNd9xxh6ZOnaoZM2bo5ptvrpg9AgDgGsTzagEAFelPp27+3qJFixx/9/X11fTp0/+wb3R0tKKjoy/ZFhAQoKVLl17JSwMA4Nb+7Hm1R44c0dChQ3XTTTepR48ejufVLliwQDfffLPGjx+vMWPGaP78+Y7n1Q4aNEiLFi3Sp59+qlGjRmn9+vW68cYbnbV7AIAqdtVn9AAAQMXgebUAgIpG0AMAwIl4Xi0AoDIQ9AAAcBKeVwsAqCwEPQAAnITn1QIAKssV3YwFAABUHJ5XCwCoLJzRAwDASXheLQCgshD0AABwQTyvFgBQHkzdBADARfC8WgBAReGMHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALgZgh4AAAAAuBmCHgAAAAC4GYIeAAAAALiZMgW9rVu3qnfv3goKClK3bt307rvvSpJsNpvi4+MVFhamsLAwJSQkyG63O9bbtGmTIiIiFBgYqIEDByo7O9vRdvToUQ0ZMkRBQUHq2rWrVq5cWbF7BgAAAADV1GWD3pEjRxQXF6fnn39e6enpSkpK0qRJk5SRkaGkpCRlZmZq8+bNWrNmjdLS0pSSkiJJOnjwoMaOHatJkybpyy+/VHBwsIYPH66SkhJJ0qhRo2SxWJSWlqZp06Zp8uTJ2r17d6XuLAAAAABUB5cNejfccIM+//xzdejQQSUlJTp9+rQ8PT1Vp04dpaamKiYmRvXq1VOTJk0UGxvrODO3du1adezYUSEhITKZTIqLi1Nubq52794tq9WqPXv2KC4uTiaTSe3atVPv3r05qwcAAAAAFcCrLJ3q1Kmjs2fPKjQ0VHa7XU888YQaNmyo48ePy2KxOPr5+fkpJydHNptNWVlZatWqlaPN09NTTZs2VWZmpho0aKAmTZqoTp06pdZdv359Be4aAAAAAFRPZQp6kmQ2m7V7927t27dPjz/+uLy9vR3LL+xjGIYKCgqUl5fn6HNhe15enmrVqnVRm7e3t/Lz88uzLwAAAAAAXUHQ8/T0lKenp9q0aaP+/fsrIyNDklRQUODocz6o+fj4yGw2q7CwsNQ28vPzVbt2bfn4+JRa7/x2fHx8rnpHAAAAAAC/uew1ep9//rkGDBhQallRUZHq1q2rRo0ayWq1OpZbrVY1a9ZMXl5e8vf3L9Vmt9t1+PBhWSwWWSwW5ebm6ty5c6XW9ff3r4h9AgDgmsGdrQEAleGyQa9Vq1Y6fPiwFi5cKLvdrp07dyo1NVX9+/dXZGSkkpOTdfLkSeXm5mrOnDnq06ePJKlXr17aunWrduzYIZvNplmzZqlhw4Zq27at/Pz81KpVK02bNk2FhYVKT0/XunXrFBUVVdn7CwCAy+DO1gCAynLZoFevXj3NmzdPGzduVGhoqMaPH6+JEycqNDRUI0eO1K233qrIyEhFRkYqNDRUMTExkqQWLVooMTFREyZMUFhYmL7++mvNnj1bnp6ekqSkpCT9+OOPCg8P17PPPqvnn39eISEhlbu3AAC4EO5sDQCoLGW6Ru/22293TCW5UK1atTRu3DiNGzfukutFREQoIiLikm1/+ctfNHfu3CsoFQAA98OdrQEAlaHMN2MBAACVgztbAwAqGkEPAAAn487WAICKdtlr9AAAQOXgztYAgMpC0AMAwEm4szUAoLIwdRMAACc5f2friRMnaubMmbrhhhscd7Zu27atEhMTFRkZqeLiYkVFRV3yztbHjh1T69atL7qzdXx8vMLDw1W3bl3ubA0A1ZCHYRiGs4u4WidPnlVJydWX36jRdUrYNqvM/cd2jtPx479e9esBQHVTo4aHrr++zuU7wuVwjAUA13a5YyxTNwEAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM0Q9AAAAADAzRD0AAAAAMDNEPQAAAAAwM2UKehlZGQoOjpaISEh6ty5s5KSkmQYhmw2m+Lj4xUWFqawsDAlJCTIbrc71tu0aZMiIiIUGBiogQMHKjs729F29OhRDRkyREFBQeratatWrlxZ4TsHAAAAANXRZYPeuXPn9MQTT6hHjx5KS0vTggULtHr1ai1dulRJSUnKzMzU5s2btWbNGqWlpSklJUWSdPDgQY0dO1aTJk3Sl19+qeDgYA0fPlwlJSWSpFGjRslisSgtLU3Tpk3T5P/X3t3GNlX+fxz/jI3SdUNAmIwHELIuAmJwjLn+FCGCOlHGhpIgGILcKHITB8Fw92RTRGG4BIMOkAxJMKjBcGfFiBG8SSBOgRIwKgzKIAjUMfWnbGvLtvN/sNDZP/jjbKwtO3u/Eh7sOlfb77mynC+f9TrtqlU6evRoRE8WAAAAADqCmwa9ixcvKjMzU1OmTFF8fLz69++vxx57TEeOHNHOnTs1a9Ysde/eXampqZo9e3bonblPPvlEI0eOVFZWlmw2mwoKCuTz+XT06FF5vV4dP35cBQUFstlsyszM1Lhx43hXDwAAAADawE2DXnp6ukpLS0M/B4NBffvttxo4cKCqqqrkdDpDx9LS0nT27FkFg0GdPn1a6enpoWPx8fHq16+fTp06Ja/Xq9TUVCUnJ4c9tqKioq3OCwAAAAA6rBZ9GEswGNTChQtls9n05JNPSpISExNDxxMTE2UYhvx+v2pra2W328Men5iYqNraWtXU1Fx3zG63q66urrXnAQBAu8R98ACASDAd9KqqqjR16lRdvnxZmzdvDr0b5/f7Q3OuBTWHw6HExEQFAoGw56irq1NSUpIcDkfY4649j8PhaPWJAADQ3nAfPAAgUkwFvZMnT2rChAnq37+/tmzZoh49eqhbt25KSUmR1+sNzfN6verfv78SEhKUnp4edqyhoUHnzp2T0+mU0+mUz+dTTU1N2GP/udUTAACr4z54AECk3DTo/fHHH5oxY4Zyc3O1atUq2Wy20LG8vDyVlpaqurpaPp9PGzZs0Pjx4yVJubm5+uqrr3TgwAEFg0GtXbtWvXr10n333ae0tDQNGjRIJSUlCgQC8ng8crvdys/Pj9iJAgBwu+E+eABApCTcbMKuXbtUVVWlDz74QB9++GFofMSIEXrzzTdVXFysvLw81dfXKz8/X7NmzZIkDRgwQMXFxVqxYoUuXbqkwYMHa/369YqPj5ckvf322yoqKtLw4cN1xx13aMmSJcrKyorQaQIAcHv7//fBl5SUtOo++C5dunAfPADg5kFv+vTpmj59+r8eLywsVGFh4Q2P5eTkKCcn54bH+vTpo40bN5osEwAA66qqqtJLL70kSdq8ebM6dWracMN98ACA1mrRp24CAIC2xX3wAIBIIOgBABAj3AcPAIiUm27dBAAAkcF98ACASIkzDMOIdRGtVV19RY2NrS8/JaWrVn691vT8ZQ8XqKrq71a/HgB0NJ06xalnz+SbT8Rthx4LALe3m/VYtm4CAAAAgMUQ9AAAAADAYgh6AAAAAGAxBD0AAAAAsBiCHgAAAABYDEEPAAAAACyGoAcAAAAAFkPQAwAAAACLIegBAAAAgMUQ9AAAAADAYgh6AAAAAGAxBD0AAAAAsBiCHgAAAABYDEEPAAAAACyGoAcAAAAAFkPQAwAAAACLIegBAAAAgMUQ9AAAAADAYgh6AAAAAGAxBD0AAAAAsBiCHgAAAABYDEEPAAAAACyGoAcAAAAAFkPQAwAAAACLaVHQO3bsmLKzs0M/B4NBFRUVyeVyyeVyaeXKlWpoaAgd//zzz5WTk6OMjAxNmTJFlZWVoWMXL17UzJkzNXToUI0ePVrbt2+/9bMBAAAAAJgPep999plmzJihq1evhsbefvttnTp1Snv37tXu3btVXl6uTZs2SZIqKiq0bNkyvfHGG/r+++81bNgwzZs3T42NjZKkBQsWyOl0qry8XCUlJVq1apWOHj3atmcHAAAAAB2QqaC3Zs0alZWVae7cuWHjO3fu1KxZs9S9e3elpqZq9uzZoXfmPvnkE40cOVJZWVmy2WwqKCiQz+fT0aNH5fV6dfz4cRUUFMhmsykzM1Pjxo3jXT0AQIfFrhkAQFsyFfSeffZZ7dixQ4MHDw6N/fXXX6qqqpLT6QyNpaWl6ezZswoGgzp9+rTS09NDx+Lj49WvXz+dOnVKXq9XqampSk5ODntsRUVFW5wTAADtCrtmAABtzVTQ692793VjtbW1kqTExMTQWGJiogzDkN/vV21trex2e9hjEhMTVVtbq5qamuuO2e121dXVtfgEAABoz9g1AwCIhFZ/6ua1gOf3+0Nj14Kaw+FQYmKiAoFA2GPq6uqUlJQkh8MR9rhrz+NwOFpbDgAA7RK7ZgAAkdDqoNetWzelpKTI6/WGxrxer/r376+EhASlp6eHHWtoaNC5c+fkdDrldDrl8/lUU1MT9th/Ni0AADoCds0AACLhlr5HLy8vT6WlpaqurpbP59OGDRs0fvx4SVJubq6++uorHThwQMFgUGvXrlWvXr103333KS0tTYMGDVJJSYkCgYA8Ho/cbrfy8/Pb4pwAAGjX2DUDALhVtxT05s+fr3vuuUd5eXnKy8tTdna2Zs2aJUkaMGCAiouLtWLFCrlcLh0+fFjr169XfHy8pKabzH/99VcNHz5cL7/8spYsWaKsrKxbPyMAANo5ds0AAG5VQksmu1wueTye0M9dunRRYWGhCgsLbzg/JydHOTk5NzzWp08fbdy4sSUvDwBAh3Ft18w999yj+vr663bNTJo0SQcOHND999+v0tLS0K6Z+Pj40K6ZpUuX6qeffpLb7db69etje0IAgKhqUdADAADRMX/+fBUXFysvL0/19fXKz8+/4a6ZS5cuafDgwdftmikqKtLw4cN1xx13sGsGADqgOMMwjFgX0VrV1VfU2Nj68lNSumrl12tNz1/2cIGqqv5u9esBQEfTqVOcevZMvvlE3HbosQBwe7tZj72le/QAAAAAALcfgh4AAAAAWAxBDwAAAAAshqAHAAAAABZD0AMAAAAAiyHoAQAAAIDFEPQAAAAAwGIIegAAAABgMQQ9AAAAALAYgh4AAAAAWAxBDwAAAAAsJiHWBQAAoqtbD7tsCZ1Nzw/WX9V///BHsCIAANDWCHoA0MHYEjpr5ddrTc9f9nCBJIIeAADtCVs3AQAAAMBiCHoAAAAAYDEEPQAAAACwGIIeAAAAAFgMQQ8AAAAALIagBwAAAAAWQ9ADAAAAAIvhe/QAAAAAoA1062GXLaGz6fnB+qv67x+R+a5agh4AAAAAtAFbQmet/Hqt6fnLHi6QFJmgx9ZNAAAAALAYgh4AAAAAWAxBDwAAAAAsJqZB78SJE5o0aZIyMjI0ZswYffPNN7EsBwAAy6DHAkDHFrOgFwwGNWfOHD3++OP64YcftGjRIi1YsEC//vprrEoCAMAS6LEAgJgFvfLycvn9fk2bNk2dO3fWI488ouzsbLnd7liVBACAJdBjAQAx+3qF06dPy+l0Ki4uLjSWlpamiooK08/RqVPczSfdRDd71xbNb4vXBIBYi9a1j2tmbNBjASB2bpceG7OgV1tbK7vdHjZmt9tVV1dn+jl69Ei65Trm/md6i+b37Jl8y68JALHGtc/a6LEAEDu3y7UvZls3HQ6H/P7wLwf0+/1yOBwxqggAAGugxwIAYhb0nE6nzpw5Ezbm9XqVnp4eo4oAALAGeiwAIGZBz+VyKT4+Xhs3blQwGNT+/ftVXl6usWPHxqokAAAsgR4LAIgzDMOI1YufPHlSr7zyin755Rf17t1bixcv1qhRo2JVDgAAlkGPBYCOLaZBDwAAAADQ9mK2dRMAAAAAEBkEPQAAAACwGIIeAAAAAFgMQQ8AAAAALMayQe/EiROaNGmSMjIyNGbMGH3zzTc3nHfx4kXNnDlTQ4cO1ejRo7V9+/YoVxp5ZteisrJSzz//vLKzs/XQQw/ptddeUyAQiHK1kWN2Ha5pbGzUlClTtHz58ihVGD1m1+LKlStaunSpsrOz5XK5VFhYqKtXr0a52sgxuw5nzpzRtGnTlJWVpREjRmjNmjWy4udYHTt2TNnZ2f96vCNcL2EOPbYZPbYJPbYZPbYJPTZcTHqsYUGBQMAYNWqU8d577xnBYND48ssvjYyMDOP8+fPXzZ04caLx+uuvG4FAwDh8+LCRlZVleDye6BcdIS1ZiyeeeMJYvXq1EQgEDJ/PZ0yYMMEoLi6OQdVtryXrcM0777xjDBw40Hj11VejWGnktWQtXnrpJWPOnDnG33//bVy+fNl46qmnjA0bNsSg6rbXknV4+umnjdLSUqOhocE4d+6cMXLkSGPnzp3RLzqC9uzZYwwbNszIyMj41zlWv17CHHpsM3psE3psM3psE3psuFj1WEu+o1deXi6/369p06apc+fOeuSRR5SdnS232x02z+v16vjx4yooKJDNZlNmZqbGjRtnqb84ml2L33//XX369NHcuXNls9l01113KT8/X0eOHIlR5W3L7Dpc4/F4tGfPHj322GNRrjTyzK7Fb7/9pn379mn58uVKTk5Wz549tW7dOuXm5sao8rbVkt8Jr9erxsZGNTY2SpLi4uLUpUuXaJccMWvWrFFZWZnmzp37r3M6wvUS5tBjm9Fjm9Bjm9Fjm9Bjm8Wyx1oy6J0+fVpOp1NxcXGhsbS0NFVUVITN83q9Sk1NVXJy8v+c156ZXYs777xTmzZtUlJSkiTJMAzt27dPAwcOjGq9kWJ2HaTmrRSrVq2Sw+GIZplRYXYtfv75Z/Xu3Vtut1ujR4/WyJEjtXXrVvXu3TvaJUdES34n5syZo3Xr1mnIkCF69NFH9eCDD+qJJ56IZrkR9eyzz2rHjh0aPHjwv87pCNdLmEOPbUaPbUKPbUaPbUKPbRbLHmvJoFdbWyu73R42ZrfbVVdXFzZWU1Njal57ZnYt/qmxsVErVqxQZWWl5s2bF+kSo6Il61BUVKT8/HwNGTIkWuVFldm1+PPPP3Xp0iWdOnVKbrdbW7du1b59+1RWVhbNciOmJb8TCQkJWrx4sTwej3bt2qWDBw/qo48+ilapEWfmPxYd4XoJc+ixzeixTeixzeixTeixzWLZYy0Z9BwOh/x+f9iY3++/7i9HZue1Zy09xytXrmjevHk6ePCg3n//faWkpESjzIgzuw67du3ShQsX9OKLL0azvKgyuxY2m00NDQ1atGiRkpKS1LdvX02dOlVffPFFNMuNGLPr8OOPP6qsrEzPPfecunTpokGDBmnGjBnatm1bNMuNuY5wvYQ59Nhm9Ngm9Nhm9Ngm9NiWidT10pJBz+l06syZM2FjXq9X6enp183z+Xyqqan5n/PaM7NrIUk+n0/PPPOMrl69qm3btqlv377RKjPizK6D2+3WL7/8IpfLpaysLH366afatm2bpZqS2bVIS0uTJAWDwdBYQ0ND5AuMErPrcOHChes+BS0hIUEJCQkRr/F20hGulzCHHtuMHtuEHtuMHtuEHtsykbpeWjLouVwuxcfHa+PGjQoGg9q/f7/Ky8s1duzYsHlpaWkaNGiQSkpKFAgE5PF45Ha7lZ+fH6PK257ZtQgGg3r++ec1YMAAvfvuu+ratWuMKo4Ms+uwadMmeTweHTp0SIcOHVJubq4mTpyod999N0aVtz2zazFgwADde++9Ki4uVm1trc6fP68tW7ZY5kZxs+uQmZkpSXrrrbdUX1+vyspKbd68+bp5VtcRrpcwhx7bjB7bhB7bjB7bhB7bMhG7Xt7SZ3bexk6cOGFMnjzZGDp0qDFmzBhj//79hmEYxu7du8M+2vTChQvGCy+8YAwbNswYNWqU8fHHH8eq5IgxsxZ79+417r77bmPIkCFGRkZG6N+ECRNiWXqbMvs78U9Lliyx3Ec/G4b5taiurjYWLlxoPPDAA4bL5TJWr15t1NfXx6rsNmd2HTwejzF58uTQdWLDhg1GQ0NDrMqOmO+++y7svDvi9RLm0GOb0WOb0GOb0WOb0GPDxaLHxhmGBb+REAAAAAA6MEtu3QQAAACAjoygBwAAAAAWQ9ADAAAAAIsh6AEAAACAxRD0AAAAAMBiCHoAAAAAYDEEPQAAAACwGIIeAAAAAFgMQQ8AAAAALOb/ANTWC0/xUQIJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x864 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template.basicanalysis(healthdf)\n",
    "template.stringcolanalysis(healthdf)\n",
    "template.numcolanalysis(healthdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template.correlation_anlysis(healthdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template.correlation(healthdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test for equality of mean between all numric columns\n",
      "['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke']\n",
      "(age,hypertension) => t-value=136.3303908087598, p-value=0.0\n",
      "(age,heart_disease) => t-value=136.4726367422864, p-value=0.0\n",
      "(age,avg_glucose_level) => t-value=-88.86334306898064, p-value=0.0\n",
      "(age,bmi) => t-value=42.747335654349925, p-value=0.0\n",
      "(age,stroke) => t-value=136.48997200146383, p-value=0.0\n",
      "(hypertension,heart_disease) => t-value=8.327414713584083, p-value=9.320689203295453e-17\n",
      "(hypertension,avg_glucose_level) => t-value=-167.40643548416358, p-value=0.0\n",
      "(hypertension,bmi) => t-value=-264.86157791968265, p-value=0.0\n",
      "(hypertension,stroke) => t-value=9.503622984959767, p-value=2.4828630276395242e-21\n",
      "(heart_disease,avg_glucose_level) => t-value=-167.47652032737852, p-value=0.0\n",
      "(heart_disease,bmi) => t-value=-265.3415120442796, p-value=0.0\n",
      "(heart_disease,stroke) => t-value=1.2098297457356277, p-value=0.22637221796027784\n",
      "(avg_glucose_level,bmi) => t-value=120.14136926118866, p-value=0.0\n",
      "(avg_glucose_level,stroke) => t-value=167.4850547627959, p-value=0.0\n",
      "(bmi,stroke) => t-value=265.400468853888, p-value=0.0\n"
     ]
    }
   ],
   "source": [
    "template.t_test(healthdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality Test for all numric columns\n",
      "['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke']\n",
      "Normaility Test for Column: age\n",
      "Statistics=0.967, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Normaility Test for Column: hypertension\n",
      "Statistics=0.337, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Normaility Test for Column: heart_disease\n",
      "Statistics=0.235, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Normaility Test for Column: avg_glucose_level\n",
      "Statistics=0.806, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Normaility Test for Column: bmi\n",
      "Statistics=0.955, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Normaility Test for Column: stroke\n",
      "Statistics=0.220, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n"
     ]
    }
   ],
   "source": [
    "template.Normality_test(healthdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.ANOVA_analysis(healthdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chisquare-test for Independence between all numric columns\n",
      "(age,hypertension) => chisqr-value=496.4441285756874, p-value=7.950648916458542e-53\n",
      "Dependent (reject H0)\n",
      "(age,heart_disease) => chisqr-value=544.6187743416522, p-value=2.8909739686706094e-61\n",
      "Dependent (reject H0)\n",
      "(age,avg_glucose_level) => chisqr-value=407657.6752319793, p-value=0.9891852058214933\n",
      "Independent (H0 holds true)\n",
      "(age,bmi) => chisqr-value=64611.62085993603, p-value=6.162068063170742e-225\n",
      "Dependent (reject H0)\n",
      "(age,stroke) => chisqr-value=491.7477217460024, p-value=5.161745862440517e-52\n",
      "Dependent (reject H0)\n",
      "(hypertension,heart_disease) => chisqr-value=58.336663503559144, p-value=2.208889768960281e-14\n",
      "Dependent (reject H0)\n",
      "(hypertension,avg_glucose_level) => chisqr-value=4182.856144874379, p-value=0.011730353829931574\n",
      "Dependent (reject H0)\n",
      "(hypertension,bmi) => chisqr-value=869.1713858592308, p-value=4.2833310152885746e-20\n",
      "Dependent (reject H0)\n",
      "(hypertension,stroke) => chisqr-value=81.6053682482931, p-value=1.661621901511823e-19\n",
      "Dependent (reject H0)\n",
      "(heart_disease,avg_glucose_level) => chisqr-value=4170.563760320915, p-value=0.016485566234292374\n",
      "Dependent (reject H0)\n",
      "(heart_disease,bmi) => chisqr-value=612.5047818457907, p-value=0.0028491388742449024\n",
      "Dependent (reject H0)\n",
      "(heart_disease,stroke) => chisqr-value=90.25956125843324, p-value=2.088784568522924e-21\n",
      "Dependent (reject H0)\n",
      "(avg_glucose_level,bmi) => chisqr-value=2071527.5628741041, p-value=0.0003194530634272288\n",
      "Dependent (reject H0)\n",
      "(avg_glucose_level,stroke) => chisqr-value=4171.560911409473, p-value=0.016045842421853904\n",
      "Dependent (reject H0)\n",
      "(bmi,stroke) => chisqr-value=793.3861804938861, p-value=8.125801115807824e-14\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "template.chisquare_test(healthdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthdf = template.onehotencoding(healthdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi',\n",
       "       'stroke', 'gender_Female', 'gender_Male', 'gender_Other',\n",
       "       'ever_married_No', 'ever_married_Yes', 'work_type_Govt_job',\n",
       "       'work_type_Never_worked', 'work_type_Private',\n",
       "       'work_type_Self-employed', 'work_type_children', 'Residence_type_Rural',\n",
       "       'Residence_type_Urban', 'smoking_status_Unknown',\n",
       "       'smoking_status_formerly smoked', 'smoking_status_never smoked',\n",
       "       'smoking_status_smokes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5105    0\n",
       "5106    0\n",
       "5107    0\n",
       "5108    0\n",
       "5109    0\n",
       "Name: stroke, Length: 5110, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthdf['stroke']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#healthdf=template.MinMax_Transformation(healthdf,'stroke')\n",
    "#healthdf=template.Standard_Transformation(healthdf,'stroke')\n",
    "healthdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Addressing Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.63992172211351\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.4943181818181818\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[957  11]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49793388429752067\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[964   4]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49793388429752067\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[964   4]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 90.70450097847358\n",
      "\n",
      " Precision of event Happening: \n",
      " 12.727272727272727\n",
      "\n",
      " Recall of event Happening: \n",
      " 12.962962962962962\n",
      "\n",
      " AUC: \n",
      " 0.5400214263850627\n",
      "\n",
      " F-Score:\n",
      " 0.12844036697247707\n",
      "\n",
      " Confusion Matrix: \n",
      " [[920  48]\n",
      " [ 47   7]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.6183953033268\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.4994834710743802\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[967   1]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 1 1 ... 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 40.31311154598826\n",
      "\n",
      " Precision of event Happening: \n",
      " 7.878787878787878\n",
      "\n",
      " Recall of event Happening: \n",
      " 96.29629629629629\n",
      "\n",
      " AUC: \n",
      " 0.6674318947046219\n",
      "\n",
      " F-Score:\n",
      " 0.1456582633053221\n",
      "\n",
      " Confusion Matrix: \n",
      " [[360 608]\n",
      " [  2  52]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:48:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49793388429752067\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[964   4]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without REG, CV and RFFS and addressing class imbalancing\n",
    "results_without_cv_reg_rffs= template.run_algorithms(healthdf,\"stroke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n",
      "[22:50:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n",
      "============ LogReg ===========\n",
      "{'accuracy': 95.14677103718199, 'precision': 10.0, 'recall': 0.4, 'auc_val': 0.502, 'f_score': 0.007692307692307693}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 94.30528375733857, 'precision': 7.392857142857143, 'recall': 2.4, 'auc_val': 0.5070632071724931, 'f_score': 0.03477855477855478}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 94.87279843444227, 'precision': 15.0, 'recall': 0.8, 'auc_val': 0.5024574238852131, 'f_score': 0.0150997150997151}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 95.00978473581213, 'precision': 16.666666666666664, 'recall': 1.6, 'auc_val': 0.506971827177394, 'f_score': 0.0291005291005291}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 90.37181996086103, 'precision': 12.368472967085244, 'recall': 16.083333333333336, 'auc_val': 0.5513077779467809, 'f_score': 0.13908529467200884}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 95.0293542074364, 'precision': 10.0, 'recall': 0.4, 'auc_val': 0.5013831385572203, 'f_score': 0.007692307692307693}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 41.81996086105674, 'precision': 7.391984954603626, 'recall': 94.38333333333334, 'auc_val': 0.6675565970373751, 'f_score': 0.13705956027610935}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 95.04892367906066, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.4995884773662552, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 94.95107632093934, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.49907428532799286, 'f_score': 0.0}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV only and without addressing class imbalancing\n",
    "results_cv = template.run_algorithms_cv(healthdf,\"stroke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_glucose_level                 25.849836\n",
      "age                               24.401399\n",
      "bmi                               23.514942\n",
      "hypertension                       3.160500\n",
      "heart_disease                      2.480187\n",
      "smoking_status_formerly smoked     2.061502\n",
      "gender_Female                      1.964351\n",
      "Residence_type_Urban               1.855011\n",
      "work_type_Private                  1.830559\n",
      "smoking_status_smokes              1.817578\n",
      "Residence_type_Rural               1.795672\n",
      "work_type_Self-employed            1.659606\n",
      "smoking_status_never smoked        1.658442\n",
      "gender_Male                        1.603758\n",
      "smoking_status_Unknown             1.316346\n",
      "work_type_Govt_job                 1.122081\n",
      "ever_married_No                    1.105450\n",
      "ever_married_Yes                   0.745560\n",
      "work_type_children                 0.057221\n",
      "gender_Other                       0.000000\n",
      "work_type_Never_worked             0.000000\n",
      "dtype: float64\n",
      "Selected Features =['avg_glucose_level', 'age', 'bmi', 'hypertension']\n",
      "(5110, 22)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.63992172211351\n",
      "\n",
      " Precision of event Happening: \n",
      " 7.6923076923076925\n",
      "\n",
      " Recall of event Happening: \n",
      " 1.8518518518518516\n",
      "\n",
      " AUC: \n",
      " 0.5030609121518214\n",
      "\n",
      " F-Score:\n",
      " 0.029850746268656716\n",
      "\n",
      " Confusion Matrix: \n",
      " [[956  12]\n",
      " [ 53   1]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49793388429752067\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[964   4]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.52054794520548\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.4989669421487603\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[966   2]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 90.90019569471625\n",
      "\n",
      " Precision of event Happening: \n",
      " 14.545454545454545\n",
      "\n",
      " Recall of event Happening: \n",
      " 14.814814814814813\n",
      "\n",
      " AUC: \n",
      " 0.5497972145699419\n",
      "\n",
      " F-Score:\n",
      " 0.14678899082568805\n",
      "\n",
      " Confusion Matrix: \n",
      " [[921  47]\n",
      " [ 46   8]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.03131115459882\n",
      "\n",
      " Precision of event Happening: \n",
      " 23.076923076923077\n",
      "\n",
      " Recall of event Happening: \n",
      " 5.555555555555555\n",
      "\n",
      " AUC: \n",
      " 0.5226124885215795\n",
      "\n",
      " F-Score:\n",
      " 0.08955223880597016\n",
      "\n",
      " Confusion Matrix: \n",
      " [[958  10]\n",
      " [ 51   3]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 88.16046966731899\n",
      "\n",
      " Precision of event Happening: \n",
      " 18.69158878504673\n",
      "\n",
      " Recall of event Happening: \n",
      " 37.03703703703704\n",
      "\n",
      " AUC: \n",
      " 0.6402471686562595\n",
      "\n",
      " F-Score:\n",
      " 0.24844720496894407\n",
      "\n",
      " Confusion Matrix: \n",
      " [[881  87]\n",
      " [ 34  20]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:50:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.52054794520548\n",
      "\n",
      " Precision of event Happening: \n",
      " 25.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 1.8518518518518516\n",
      "\n",
      " AUC: \n",
      " 0.5077096724823997\n",
      "\n",
      " F-Score:\n",
      " 0.034482758620689655\n",
      "\n",
      " Confusion Matrix: \n",
      " [[965   3]\n",
      " [ 53   1]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with RFFS only and without addressing class imbalancing\n",
    "res_rffs = template.MachineLearningwithRFFS(healthdf, \"stroke\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_glucose_level                 26.391147\n",
      "age                               24.368483\n",
      "bmi                               23.876272\n",
      "heart_disease                      2.855841\n",
      "hypertension                       2.466052\n",
      "work_type_Private                  2.339199\n",
      "smoking_status_never smoked        2.031167\n",
      "Residence_type_Rural               1.854332\n",
      "gender_Male                        1.817449\n",
      "work_type_Govt_job                 1.663745\n",
      "smoking_status_Unknown             1.601939\n",
      "smoking_status_formerly smoked     1.591068\n",
      "Residence_type_Urban               1.578195\n",
      "work_type_Self-employed            1.478487\n",
      "gender_Female                      1.401500\n",
      "smoking_status_smokes              1.033946\n",
      "ever_married_No                    0.895476\n",
      "ever_married_Yes                   0.675886\n",
      "work_type_children                 0.079815\n",
      "work_type_Never_worked             0.000000\n",
      "gender_Other                       0.000000\n",
      "dtype: float64\n",
      "Selected Features =['avg_glucose_level', 'age', 'bmi']\n",
      "(5110, 22)\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 611\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n",
      "[22:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 611\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n",
      "============ LogReg ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 94.34442270058707, 'precision': 8.428571428571427, 'recall': 2.4, 'auc_val': 0.5072687572354467, 'f_score': 0.03663070328392909}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 94.87279843444227, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.498662762694248, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 95.0293542074364, 'precision': 3.333333333333333, 'recall': 0.41666666666666663, 'auc_val': 0.5014664718905536, 'f_score': 0.007407407407407407}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 91.29158512720156, 'precision': 12.496686334435882, 'recall': 12.85, 'auc_val': 0.540797857462756, 'f_score': 0.1257540675171042}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 94.83365949119374, 'precision': 17.5, 'recall': 1.2, 'auc_val': 0.5041487819099044, 'f_score': 0.021996266823853035}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 92.11350293542074, 'precision': 18.039657475141347, 'recall': 17.283333333333335, 'auc_val': 0.5661536132870265, 'f_score': 0.17488650931038266}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 95.0880626223092, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.49979423868312756, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 95.00978473581213, 'precision': 10.0, 'recall': 0.4, 'auc_val': 0.5012802578987839, 'f_score': 0.007692307692307693}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV and RFFS and without addressing class imbalancing\n",
    "res_rffs_cv = template.MachineLearningwithRFFS_CV(healthdf, \"stroke\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without FS, REG and CV\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.63992172211351\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.4943181818181818\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[957  11]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49793388429752067\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[964   4]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49793388429752067\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[964   4]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 89.92172211350294\n",
      "\n",
      " Precision of event Happening: \n",
      " 12.307692307692308\n",
      "\n",
      " Recall of event Happening: \n",
      " 14.814814814814813\n",
      "\n",
      " AUC: \n",
      " 0.5446319253137435\n",
      "\n",
      " F-Score:\n",
      " 0.13445378151260504\n",
      "\n",
      " Confusion Matrix: \n",
      " [[911  57]\n",
      " [ 46   8]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.6183953033268\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.4994834710743802\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[967   1]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 1 1 ... 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 40.31311154598826\n",
      "\n",
      " Precision of event Happening: \n",
      " 7.878787878787878\n",
      "\n",
      " Recall of event Happening: \n",
      " 96.29629629629629\n",
      "\n",
      " AUC: \n",
      " 0.6674318947046219\n",
      "\n",
      " F-Score:\n",
      " 0.1456582633053221\n",
      "\n",
      " Confusion Matrix: \n",
      " [[360 608]\n",
      " [  2  52]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49793388429752067\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[964   4]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "Results with Features Selection\n",
      "avg_glucose_level                 26.364772\n",
      "age                               24.437413\n",
      "bmi                               22.030091\n",
      "smoking_status_formerly smoked     2.540089\n",
      "heart_disease                      2.500524\n",
      "hypertension                       2.469212\n",
      "work_type_Private                  2.395493\n",
      "Residence_type_Rural               2.108482\n",
      "work_type_Self-employed            2.062981\n",
      "smoking_status_Unknown             1.854725\n",
      "Residence_type_Urban               1.826187\n",
      "smoking_status_smokes              1.764078\n",
      "smoking_status_never smoked        1.602648\n",
      "gender_Female                      1.504748\n",
      "gender_Male                        1.323468\n",
      "work_type_Govt_job                 1.179547\n",
      "ever_married_Yes                   1.036487\n",
      "ever_married_No                    0.860103\n",
      "work_type_children                 0.138044\n",
      "work_type_Never_worked             0.000905\n",
      "gender_Other                       0.000000\n",
      "dtype: float64\n",
      "Selected Features =['avg_glucose_level', 'age', 'bmi']\n",
      "(5110, 22)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.63992172211351\n",
      "\n",
      " Precision of event Happening: \n",
      " 7.6923076923076925\n",
      "\n",
      " Recall of event Happening: \n",
      " 1.8518518518518516\n",
      "\n",
      " AUC: \n",
      " 0.5030609121518214\n",
      "\n",
      " F-Score:\n",
      " 0.029850746268656716\n",
      "\n",
      " Confusion Matrix: \n",
      " [[956  12]\n",
      " [ 53   1]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.22700587084148\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.49741735537190085\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[963   5]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.6183953033268\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.4994834710743802\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[967   1]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 89.82387475538161\n",
      "\n",
      " Precision of event Happening: \n",
      " 9.67741935483871\n",
      "\n",
      " Recall of event Happening: \n",
      " 11.11111111111111\n",
      "\n",
      " AUC: \n",
      " 0.5266299357208448\n",
      "\n",
      " F-Score:\n",
      " 0.10344827586206896\n",
      "\n",
      " Confusion Matrix: \n",
      " [[912  56]\n",
      " [ 48   6]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.83561643835617\n",
      "\n",
      " Precision of event Happening: \n",
      " 9.090909090909092\n",
      "\n",
      " Recall of event Happening: \n",
      " 1.8518518518518516\n",
      "\n",
      " AUC: \n",
      " 0.5040939700030609\n",
      "\n",
      " F-Score:\n",
      " 0.030769230769230767\n",
      "\n",
      " Confusion Matrix: \n",
      " [[958  10]\n",
      " [ 53   1]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 90.31311154598825\n",
      "\n",
      " Precision of event Happening: \n",
      " 17.391304347826086\n",
      "\n",
      " Recall of event Happening: \n",
      " 22.22222222222222\n",
      "\n",
      " AUC: \n",
      " 0.5816689623507806\n",
      "\n",
      " F-Score:\n",
      " 0.1951219512195122\n",
      "\n",
      " Confusion Matrix: \n",
      " [[911  57]\n",
      " [ 42  12]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 0 0 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.32485322896281\n",
      "\n",
      " Precision of event Happening: \n",
      " 16.666666666666664\n",
      "\n",
      " Recall of event Happening: \n",
      " 1.8518518518518516\n",
      "\n",
      " AUC: \n",
      " 0.5066766146311602\n",
      "\n",
      " F-Score:\n",
      " 0.03333333333333333\n",
      "\n",
      " Confusion Matrix: \n",
      " [[963   5]\n",
      " [ 53   1]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 610\n",
      "[LightGBM] [Info] Number of data points in the train set: 4088, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047701 -> initscore=-2.993936\n",
      "[LightGBM] [Info] Start training from score -2.993936\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 94.71624266144813\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[968   0]\n",
      " [ 54   0]]\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold cross validation\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 643\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 645\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n",
      "============ LogReg ===========\n",
      "{'accuracy': 95.14677103718199, 'precision': 10.0, 'recall': 0.4, 'auc_val': 0.502, 'f_score': 0.007692307692307693}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 94.30528375733857, 'precision': 7.392857142857143, 'recall': 2.4, 'auc_val': 0.5070632071724931, 'f_score': 0.03477855477855478}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 94.87279843444227, 'precision': 15.0, 'recall': 0.8, 'auc_val': 0.5024574238852131, 'f_score': 0.0150997150997151}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 95.00978473581213, 'precision': 16.666666666666664, 'recall': 1.6, 'auc_val': 0.506971827177394, 'f_score': 0.0291005291005291}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 90.54794520547946, 'precision': 12.080110458017435, 'recall': 15.266666666666666, 'auc_val': 0.5483557093484084, 'f_score': 0.13379443257886778}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 94.93150684931507, 'precision': 20.0, 'recall': 1.2, 'auc_val': 0.5046629739481666, 'f_score': 0.022507122507122508}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 41.81996086105674, 'precision': 7.391984954603626, 'recall': 94.38333333333334, 'auc_val': 0.6675565970373751, 'f_score': 0.13705956027610935}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 5.0, 'recall': 0.4, 'auc_val': 0.5018971193415638, 'f_score': 0.007407407407407407}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 94.95107632093934, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.49907428532799286, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold CV, FS\n",
      "avg_glucose_level                 26.233694\n",
      "age                               25.048208\n",
      "bmi                               20.512926\n",
      "hypertension                       2.704550\n",
      "smoking_status_formerly smoked     2.664843\n",
      "heart_disease                      2.495330\n",
      "Residence_type_Urban               2.402047\n",
      "smoking_status_never smoked        2.384055\n",
      "gender_Male                        1.978787\n",
      "gender_Female                      1.953229\n",
      "Residence_type_Rural               1.939997\n",
      "work_type_Self-employed            1.833099\n",
      "work_type_Private                  1.639918\n",
      "smoking_status_Unknown             1.638678\n",
      "smoking_status_smokes              1.417144\n",
      "ever_married_No                    1.325318\n",
      "work_type_Govt_job                 0.947441\n",
      "ever_married_Yes                   0.824139\n",
      "work_type_children                 0.056120\n",
      "work_type_Never_worked             0.000477\n",
      "gender_Other                       0.000000\n",
      "dtype: float64\n",
      "Selected Features =['avg_glucose_level', 'age', 'bmi']\n",
      "(5110, 22)\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 611\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 611\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 612\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 224, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048706 -> initscore=-2.972016\n",
      "[LightGBM] [Info] Start training from score -2.972016\n",
      "[LightGBM] [Info] Number of positive: 225, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613\n",
      "[LightGBM] [Info] Number of data points in the train set: 4599, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048924 -> initscore=-2.967333\n",
      "[LightGBM] [Info] Start training from score -2.967333\n",
      "============ LogReg ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 94.34442270058707, 'precision': 8.428571428571427, 'recall': 2.4, 'auc_val': 0.5072687572354467, 'f_score': 0.03663070328392909}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 94.87279843444227, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.498662762694248, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 95.0293542074364, 'precision': 3.333333333333333, 'recall': 0.41666666666666663, 'auc_val': 0.5014664718905536, 'f_score': 0.007407407407407407}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 91.2133072407045, 'precision': 11.20457718892254, 'recall': 11.216666666666667, 'auc_val': 0.5326309795421705, 'f_score': 0.11136124637967751}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 94.63796477495109, 'precision': 4.999999999999999, 'recall': 0.8, 'auc_val': 0.501222433476141, 'f_score': 0.013594470046082949}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 92.11350293542074, 'precision': 18.039657475141347, 'recall': 17.283333333333335, 'auc_val': 0.5661536132870265, 'f_score': 0.17488650931038266}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 95.0880626223092, 'precision': 5.0, 'recall': 0.4, 'auc_val': 0.5016913580246913, 'f_score': 0.007407407407407407}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 95.12720156555773, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 95.00978473581213, 'precision': 10.0, 'recall': 0.4, 'auc_val': 0.5012802578987839, 'f_score': 0.007692307692307693}\n",
      "============================== \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0f0bfca7e181>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#all results without addressing class imbalancing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_CImbalance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhealthdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stroke'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_supported_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Machine Learning\\Assignment8\\New folder\\TempML1.py\u001b[0m in \u001b[0;36mall_CImbalance\u001b[1;34m(df, label_col, algo_list, threshold, cross_valid_method, feature_list)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results with stratified kfold CV, FS\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[0mR4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMachineLearningwithRFFS_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_supported_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mR1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "#all results without addressing class imbalancing\n",
    "res_all=template.all_CImbalance(healthdf, 'stroke', algo_list=template.get_supported_algorithms(), threshold=5, feature_list=[]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  With Adressing Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep copy\n",
    "healthdf_bal1 = healthdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthdf_bal=template.SMOT_OverSampling(healthdf_bal1, 'stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Rural</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.690000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.210000</td>\n",
       "      <td>34.550000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.920000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.230000</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.120000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>75.334024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.331220</td>\n",
       "      <td>24.506100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>76.207089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>195.502774</td>\n",
       "      <td>27.207089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>59.421686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106.227501</td>\n",
       "      <td>37.693675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>79.016641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.920318</td>\n",
       "      <td>24.396672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9721</th>\n",
       "      <td>72.499985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219.820003</td>\n",
       "      <td>30.350053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9722 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  hypertension  heart_disease  avg_glucose_level        bmi  \\\n",
       "0     67.000000             0              1         228.690000  36.600000   \n",
       "1     61.000000             0              0         202.210000  34.550000   \n",
       "2     80.000000             0              1         105.920000  32.500000   \n",
       "3     49.000000             0              0         171.230000  34.400000   \n",
       "4     79.000000             1              0         174.120000  24.000000   \n",
       "...         ...           ...            ...                ...        ...   \n",
       "9717  75.334024             0              0          98.331220  24.506100   \n",
       "9718  76.207089             1              0         195.502774  27.207089   \n",
       "9719  59.421686             0              0         106.227501  37.693675   \n",
       "9720  79.016641             0              0          67.920318  24.396672   \n",
       "9721  72.499985             0              0         219.820003  30.350053   \n",
       "\n",
       "      gender_Female  gender_Male  gender_Other  ever_married_No  \\\n",
       "0                 0            1             0                0   \n",
       "1                 1            0             0                0   \n",
       "2                 0            1             0                0   \n",
       "3                 1            0             0                0   \n",
       "4                 1            0             0                0   \n",
       "...             ...          ...           ...              ...   \n",
       "9717              0            0             0                0   \n",
       "9718              0            0             0                0   \n",
       "9719              1            0             0                0   \n",
       "9720              0            0             0                0   \n",
       "9721              0            0             0                0   \n",
       "\n",
       "      ever_married_Yes  ...  work_type_Private  work_type_Self-employed  \\\n",
       "0                    1  ...                  1                        0   \n",
       "1                    1  ...                  0                        1   \n",
       "2                    1  ...                  1                        0   \n",
       "3                    1  ...                  1                        0   \n",
       "4                    1  ...                  0                        1   \n",
       "...                ...  ...                ...                      ...   \n",
       "9717                 1  ...                  1                        0   \n",
       "9718                 1  ...                  0                        1   \n",
       "9719                 1  ...                  0                        0   \n",
       "9720                 1  ...                  1                        0   \n",
       "9721                 1  ...                  0                        0   \n",
       "\n",
       "      work_type_children  Residence_type_Rural  Residence_type_Urban  \\\n",
       "0                      0                     0                     1   \n",
       "1                      0                     1                     0   \n",
       "2                      0                     1                     0   \n",
       "3                      0                     0                     1   \n",
       "4                      0                     1                     0   \n",
       "...                  ...                   ...                   ...   \n",
       "9717                   0                     0                     1   \n",
       "9718                   0                     0                     0   \n",
       "9719                   0                     0                     1   \n",
       "9720                   0                     0                     1   \n",
       "9721                   0                     0                     0   \n",
       "\n",
       "      smoking_status_Unknown  smoking_status_formerly smoked  \\\n",
       "0                          0                               1   \n",
       "1                          0                               0   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "...                      ...                             ...   \n",
       "9717                       0                               0   \n",
       "9718                       0                               1   \n",
       "9719                       0                               0   \n",
       "9720                       0                               0   \n",
       "9721                       0                               0   \n",
       "\n",
       "      smoking_status_never smoked  smoking_status_smokes  stroke  \n",
       "0                               0                      0       1  \n",
       "1                               1                      0       1  \n",
       "2                               1                      0       1  \n",
       "3                               0                      1       1  \n",
       "4                               1                      0       1  \n",
       "...                           ...                    ...     ...  \n",
       "9717                            0                      0       1  \n",
       "9718                            0                      0       1  \n",
       "9719                            0                      0       1  \n",
       "9720                            0                      0       1  \n",
       "9721                            0                      0       1  \n",
       "\n",
       "[9722 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthdf_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal data shape: (5110, 22)\n",
      "Resampled data shape: (9722, 22)\n"
     ]
    }
   ],
   "source": [
    "print('Orignal data shape:', healthdf.shape)\n",
    "print('Resampled data shape:', healthdf_bal.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.44730077120823\n",
      "\n",
      " Precision of event Happening: \n",
      " 95.5832389580974\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.44249726177436\n",
      "\n",
      " AUC: \n",
      " 0.9433171374716627\n",
      "\n",
      " F-Score:\n",
      " 0.9398663697104678\n",
      "\n",
      " Confusion Matrix: \n",
      " [[993  39]\n",
      " [ 69 844]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 89.30591259640103\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.48847926267281\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.02847754654984\n",
      "\n",
      " AUC: \n",
      " 0.8980881241668576\n",
      "\n",
      " F-Score:\n",
      " 0.8958958958958958\n",
      "\n",
      " Confusion Matrix: \n",
      " [[842 190]\n",
      " [ 18 895]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 96.09254498714654\n",
      "\n",
      " Precision of event Happening: \n",
      " 98.15880322209436\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.42825848849945\n",
      "\n",
      " AUC: \n",
      " 0.9593893544580011\n",
      "\n",
      " F-Score:\n",
      " 0.957351290684624\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1016   16]\n",
      " [  60  853]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 95.47557840616967\n",
      "\n",
      " Precision of event Happening: \n",
      " 97.03534777651083\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.2092004381161\n",
      "\n",
      " AUC: \n",
      " 0.9534491029657743\n",
      "\n",
      " F-Score:\n",
      " 0.9508379888268156\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1006   26]\n",
      " [  62  851]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.76606683804627\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.80952380952381\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.88499452354874\n",
      "\n",
      " AUC: \n",
      " 0.7911885385092166\n",
      "\n",
      " F-Score:\n",
      " 0.7896077432501273\n",
      "\n",
      " Confusion Matrix: \n",
      " [[757 275]\n",
      " [138 775]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.72750642673522\n",
      "\n",
      " Precision of event Happening: \n",
      " 92.0297555791711\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.85213581599123\n",
      "\n",
      " AUC: \n",
      " 0.9379234697776306\n",
      "\n",
      " F-Score:\n",
      " 0.9341963322545846\n",
      "\n",
      " Confusion Matrix: \n",
      " [[957  75]\n",
      " [ 47 866]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 96.76092544987146\n",
      "\n",
      " Precision of event Happening: \n",
      " 98.1859410430839\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.85213581599123\n",
      "\n",
      " AUC: \n",
      " 0.96650874109546\n",
      "\n",
      " F-Score:\n",
      " 0.9649025069637883\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1016   16]\n",
      " [  47  866]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 73.7789203084833\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.00372300819062\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.61883899233297\n",
      "\n",
      " AUC: \n",
      " 0.7503810166670912\n",
      "\n",
      " F-Score:\n",
      " 0.773936170212766\n",
      "\n",
      " Confusion Matrix: \n",
      " [[562 470]\n",
      " [ 40 873]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 95.16709511568124\n",
      "\n",
      " Precision of event Happening: \n",
      " 98.00703399765534\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.56626506024097\n",
      "\n",
      " AUC: \n",
      " 0.9495948911926775\n",
      "\n",
      " F-Score:\n",
      " 0.9467723669309173\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1015   17]\n",
      " [  77  836]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 90.48843187660668\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.44855967078189\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.09967141292442\n",
      "\n",
      " AUC: \n",
      " 0.9063898299328391\n",
      "\n",
      " F-Score:\n",
      " 0.9018567639257293\n",
      "\n",
      " Confusion Matrix: \n",
      " [[910 122]\n",
      " [ 63 850]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[00:11:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 93.26478149100257\n",
      "\n",
      " Precision of event Happening: \n",
      " 91.95278969957081\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.86637458926616\n",
      "\n",
      " AUC: \n",
      " 0.9329946636440051\n",
      "\n",
      " F-Score:\n",
      " 0.9289972899728997\n",
      "\n",
      " Confusion Matrix: \n",
      " [[957  75]\n",
      " [ 56 857]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 90.48843187660668\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.44855967078189\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.09967141292442\n",
      "\n",
      " AUC: \n",
      " 0.9063898299328391\n",
      "\n",
      " F-Score:\n",
      " 0.9018567639257293\n",
      "\n",
      " Confusion Matrix: \n",
      " [[910 122]\n",
      " [ 63 850]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without REG, CV and RFFS and with addressing class imbalancing\n",
    "results_without_cv_rffs = template.run_algorithms(healthdf_bal,\"stroke\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[00:14:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:14:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:14:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:14:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:15:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:15:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:15:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:15:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:15:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:15:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "============ LogReg ===========\n",
      "{'accuracy': 94.51941092628543, 'precision': 97.26000754570082, 'recall': 91.65631522464741, 'auc_val': 0.9452184788027818, 'f_score': 0.9369504446513423}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 89.67269570586917, 'precision': 83.90957861463545, 'recall': 98.1896806685764, 'auc_val': 0.8967249304974606, 'f_score': 0.904868384411421}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 96.11380736680498, 'precision': 98.88260427081256, 'recall': 93.32298189131409, 'auc_val': 0.9611628683212073, 'f_score': 0.9529041366444954}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 95.39381193457933, 'precision': 98.02533262437358, 'recall': 92.62356241708282, 'auc_val': 0.9539629122620223, 'f_score': 0.9454494382155023}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 77.43276278448141, 'precision': 74.77652752441243, 'recall': 82.86464538917197, 'auc_val': 0.7743307475853678, 'f_score': 0.7859386563951875}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 94.20003679596006, 'precision': 93.82073405110654, 'recall': 94.78164794956948, 'auc_val': 0.9420217845041027, 'f_score': 0.9384019413798829}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 97.21433435262372, 'precision': 98.98786856452361, 'recall': 95.44130943629004, 'auc_val': 0.972166873695507, 'f_score': 0.9657542649228865}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 74.68677967678767, 'precision': 67.45537590379736, 'recall': 95.51837486585376, 'auc_val': 0.746880624635587, 'f_score': 0.7900785835031016}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 94.94110531680475, 'precision': 97.92294292469589, 'recall': 91.69687597704936, 'auc_val': 0.94943257197421, 'f_score': 0.9421466636180147}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 90.44538971997005, 'precision': 89.47847583246258, 'recall': 91.71479030936025, 'auc_val': 0.9044705554288033, 'f_score': 0.9034409930526301}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 94.1900765102204, 'precision': 94.99091554763314, 'recall': 93.40448365317177, 'auc_val': 0.9419256639710667, 'f_score': 0.9357555417745687}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV only and with addressing class imbalancing\n",
    "results_cv = template.run_algorithms_cv(healthdf_bal,\"stroke\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                               21.591726\n",
      "avg_glucose_level                 11.217293\n",
      "smoking_status_Unknown             7.323820\n",
      "smoking_status_never smoked        6.778809\n",
      "bmi                                6.340713\n",
      "smoking_status_formerly smoked     5.747886\n",
      "Residence_type_Urban               5.579414\n",
      "ever_married_No                    4.813318\n",
      "Residence_type_Rural               4.320363\n",
      "smoking_status_smokes              4.220367\n",
      "work_type_Private                  4.201768\n",
      "work_type_Govt_job                 4.036544\n",
      "work_type_Self-employed            3.814539\n",
      "gender_Female                      2.988225\n",
      "gender_Male                        2.417544\n",
      "work_type_children                 1.750612\n",
      "ever_married_Yes                   1.230507\n",
      "hypertension                       0.942630\n",
      "heart_disease                      0.666329\n",
      "work_type_Never_worked             0.017593\n",
      "gender_Other                       0.000000\n",
      "dtype: float64\n",
      "Selected Features =['age', 'avg_glucose_level', 'smoking_status_Unknown', 'smoking_status_never smoked', 'bmi', 'smoking_status_formerly smoked', 'Residence_type_Urban', 'ever_married_No', 'Residence_type_Rural', 'smoking_status_smokes', 'work_type_Private', 'work_type_Govt_job', 'work_type_Self-employed']\n",
      "(9722, 22)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.88174807197943\n",
      "\n",
      " Precision of event Happening: \n",
      " 95.21640091116174\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.56626506024097\n",
      "\n",
      " AUC: \n",
      " 0.9374824880919024\n",
      "\n",
      " F-Score:\n",
      " 0.9335566722501395\n",
      "\n",
      " Confusion Matrix: \n",
      " [[990  42]\n",
      " [ 77 836]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 89.3573264781491\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.56457564575645\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.02847754654984\n",
      "\n",
      " AUC: \n",
      " 0.8985726202908887\n",
      "\n",
      " F-Score:\n",
      " 0.8963445167751627\n",
      "\n",
      " Confusion Matrix: \n",
      " [[843 189]\n",
      " [ 18 895]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.55012853470437\n",
      "\n",
      " Precision of event Happening: \n",
      " 96.32606199770379\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.894852135816\n",
      "\n",
      " AUC: \n",
      " 0.9439703847100877\n",
      "\n",
      " F-Score:\n",
      " 0.9405829596412557\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1000   32]\n",
      " [  74  839]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.36760925449872\n",
      "\n",
      " Precision of event Happening: \n",
      " 94.54545454545455\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.12814895947426\n",
      "\n",
      " AUC: \n",
      " 0.932384930843883\n",
      "\n",
      " F-Score:\n",
      " 0.928053541550474\n",
      "\n",
      " Confusion Matrix: \n",
      " [[984  48]\n",
      " [ 81 832]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.50899742930592\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.50427350427351\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.77546549835706\n",
      "\n",
      " AUC: \n",
      " 0.7887029088871341\n",
      "\n",
      " F-Score:\n",
      " 0.7873855544252288\n",
      "\n",
      " Confusion Matrix: \n",
      " [[753 279]\n",
      " [139 774]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.08740359897172\n",
      "\n",
      " Precision of event Happening: \n",
      " 92.99568965517241\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.5235487404162\n",
      "\n",
      " AUC: \n",
      " 0.9411254956400656\n",
      "\n",
      " F-Score:\n",
      " 0.937533948940793\n",
      "\n",
      " Confusion Matrix: \n",
      " [[967  65]\n",
      " [ 50 863]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 96.60668380462725\n",
      "\n",
      " Precision of event Happening: \n",
      " 97.63779527559055\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.07119386637459\n",
      "\n",
      " AUC: \n",
      " 0.9651815507272218\n",
      "\n",
      " F-Score:\n",
      " 0.9633740288568258\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1011   21]\n",
      " [  45  868]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 83.23907455012854\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.57838364167478\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.38992332968236\n",
      "\n",
      " AUC: \n",
      " 0.8353604693615901\n",
      "\n",
      " F-Score:\n",
      " 0.831958762886598\n",
      "\n",
      " Confusion Matrix: \n",
      " [[812 220]\n",
      " [106 807]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 92.44215938303341\n",
      "\n",
      " Precision of event Happening: \n",
      " 91.36069114470843\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.66155531215772\n",
      "\n",
      " AUC: \n",
      " 0.9245480866383079\n",
      "\n",
      " F-Score:\n",
      " 0.9200652528548123\n",
      "\n",
      " Confusion Matrix: \n",
      " [[952  80]\n",
      " [ 67 846]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 785\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 89.82005141388176\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.51685393258427\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.7710843373494\n",
      "\n",
      " AUC: \n",
      " 0.899901933314654\n",
      "\n",
      " F-Score:\n",
      " 0.8953488372093023\n",
      "\n",
      " Confusion Matrix: \n",
      " [[900 132]\n",
      " [ 66 847]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[00:15:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 93.21336760925449\n",
      "\n",
      " Precision of event Happening: \n",
      " 92.21621621621622\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.42825848849945\n",
      "\n",
      " AUC: \n",
      " 0.9322575715122646\n",
      "\n",
      " F-Score:\n",
      " 0.9281828073993471\n",
      "\n",
      " Confusion Matrix: \n",
      " [[960  72]\n",
      " [ 60 853]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 785\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 89.82005141388176\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.51685393258427\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.7710843373494\n",
      "\n",
      " AUC: \n",
      " 0.899901933314654\n",
      "\n",
      " F-Score:\n",
      " 0.8953488372093023\n",
      "\n",
      " Confusion Matrix: \n",
      " [[900 132]\n",
      " [ 66 847]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with RFFS and with addressing class imbalancing\n",
    "res_rffs = template.MachineLearningwithRFFS(healthdf_bal, \"stroke\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                               25.476969\n",
      "avg_glucose_level                 10.329728\n",
      "bmi                                7.788486\n",
      "ever_married_No                    7.048733\n",
      "smoking_status_Unknown             5.730555\n",
      "Residence_type_Rural               4.709759\n",
      "smoking_status_never smoked        4.558360\n",
      "Residence_type_Urban               4.522343\n",
      "gender_Male                        4.289824\n",
      "gender_Female                      4.052390\n",
      "ever_married_Yes                   3.466547\n",
      "smoking_status_smokes              3.309691\n",
      "work_type_Private                  3.277874\n",
      "work_type_Govt_job                 3.135808\n",
      "work_type_Self-employed            2.773439\n",
      "smoking_status_formerly smoked     2.752935\n",
      "hypertension                       0.976782\n",
      "work_type_children                 0.956480\n",
      "heart_disease                      0.816478\n",
      "work_type_Never_worked             0.021306\n",
      "gender_Other                       0.005513\n",
      "dtype: float64\n",
      "Selected Features =['age', 'avg_glucose_level', 'bmi', 'ever_married_No', 'smoking_status_Unknown', 'Residence_type_Rural', 'smoking_status_never smoked', 'Residence_type_Urban', 'gender_Male', 'gender_Female', 'ever_married_Yes', 'smoking_status_smokes', 'work_type_Private', 'work_type_Govt_job']\n",
      "(9722, 22)\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[00:17:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:17:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:17:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "============ LogReg ===========\n",
      "{'accuracy': 89.67421829731981, 'precision': 90.70970450099743, 'recall': 88.30105373454678, 'auc_val': 0.8967614774254062, 'f_score': 0.8916515137988569}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 89.80639826762929, 'precision': 84.17759615363396, 'recall': 98.06622387845294, 'auc_val': 0.8980617452953753, 'f_score': 0.9058868358814023}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 92.77053489483544, 'precision': 93.27859816095692, 'recall': 92.0871887173507, 'auc_val': 0.9277260205676814, 'f_score': 0.9225403493088994}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 91.41281683647792, 'precision': 91.91053791824608, 'recall': 90.62674812617774, 'auc_val': 0.9141497874785577, 'f_score': 0.9085011129803844}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 77.30930599435796, 'precision': 74.70095754782653, 'recall': 82.65884182151578, 'auc_val': 0.7730959684302143, 'f_score': 0.7845973451077823}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 93.3564153967831, 'precision': 92.3714586873082, 'recall': 94.61632063274773, 'auc_val': 0.933583035465308, 'f_score': 0.9313568207429785}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 96.30878366090197, 'precision': 96.6345664400266, 'recall': 95.95393819555352, 'auc_val': 0.9631066156277199, 'f_score': 0.9594621043879143}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 81.1159220771531, 'precision': 77.01704229375143, 'recall': 88.50449125831285, 'auc_val': 0.8111704734622827, 'f_score': 0.8229168270353225}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 86.07335295784536, 'precision': 82.28283847458695, 'recall': 79.51420048841905, 'auc_val': 0.8607488106404373, 'f_score': 0.8068966840383446}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 88.55257592867505, 'precision': 86.79346220171541, 'recall': 90.93213679113748, 'auc_val': 0.8855384017373522, 'f_score': 0.8867904152921489}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 91.5256366335503, 'precision': 89.86176394799622, 'recall': 93.4840841297606, 'auc_val': 0.9152711232793369, 'f_score': 0.9147154898421588}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV and RFFS and with addressing class imbalancing\n",
    "res_rffs_cv = template.MachineLearningwithRFFS_CV(healthdf_bal, \"stroke\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without FS, REG and CV\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.44730077120823\n",
      "\n",
      " Precision of event Happening: \n",
      " 95.5832389580974\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.44249726177436\n",
      "\n",
      " AUC: \n",
      " 0.9433171374716627\n",
      "\n",
      " F-Score:\n",
      " 0.9398663697104678\n",
      "\n",
      " Confusion Matrix: \n",
      " [[993  39]\n",
      " [ 69 844]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 89.30591259640103\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.48847926267281\n",
      "\n",
      " Recall of event Happening: \n",
      " 98.02847754654984\n",
      "\n",
      " AUC: \n",
      " 0.8980881241668576\n",
      "\n",
      " F-Score:\n",
      " 0.8958958958958958\n",
      "\n",
      " Confusion Matrix: \n",
      " [[842 190]\n",
      " [ 18 895]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 96.09254498714654\n",
      "\n",
      " Precision of event Happening: \n",
      " 98.15880322209436\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.42825848849945\n",
      "\n",
      " AUC: \n",
      " 0.9593893544580011\n",
      "\n",
      " F-Score:\n",
      " 0.957351290684624\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1016   16]\n",
      " [  60  853]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 95.47557840616967\n",
      "\n",
      " Precision of event Happening: \n",
      " 97.03534777651083\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.2092004381161\n",
      "\n",
      " AUC: \n",
      " 0.9534491029657743\n",
      "\n",
      " F-Score:\n",
      " 0.9508379888268156\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1006   26]\n",
      " [  62  851]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 78.76606683804627\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.80952380952381\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.88499452354874\n",
      "\n",
      " AUC: \n",
      " 0.7911885385092166\n",
      "\n",
      " F-Score:\n",
      " 0.7896077432501273\n",
      "\n",
      " Confusion Matrix: \n",
      " [[757 275]\n",
      " [138 775]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 93.88174807197943\n",
      "\n",
      " Precision of event Happening: \n",
      " 92.32409381663112\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.85213581599123\n",
      "\n",
      " AUC: \n",
      " 0.9393769581497237\n",
      "\n",
      " F-Score:\n",
      " 0.9357104267963263\n",
      "\n",
      " Confusion Matrix: \n",
      " [[960  72]\n",
      " [ 47 866]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 97.01799485861183\n",
      "\n",
      " Precision of event Happening: \n",
      " 98.96907216494846\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.6330777656079\n",
      "\n",
      " AUC: \n",
      " 0.9688049237117603\n",
      "\n",
      " F-Score:\n",
      " 0.9675251959686451\n",
      "\n",
      " Confusion Matrix: \n",
      " [[1023    9]\n",
      " [  49  864]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 73.7789203084833\n",
      "\n",
      " Precision of event Happening: \n",
      " 65.00372300819062\n",
      "\n",
      " Recall of event Happening: \n",
      " 95.61883899233297\n",
      "\n",
      " AUC: \n",
      " 0.7503810166670912\n",
      "\n",
      " F-Score:\n",
      " 0.773936170212766\n",
      "\n",
      " Confusion Matrix: \n",
      " [[562 470]\n",
      " [ 40 873]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 94.65295629820052\n",
      "\n",
      " Precision of event Happening: \n",
      " 95.91373439273553\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.55202628696605\n",
      "\n",
      " AUC: \n",
      " 0.9453182709697139\n",
      "\n",
      " F-Score:\n",
      " 0.9420289855072463\n",
      "\n",
      " Confusion Matrix: \n",
      " [[996  36]\n",
      " [ 68 845]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 90.48843187660668\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.44855967078189\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.09967141292442\n",
      "\n",
      " AUC: \n",
      " 0.9063898299328391\n",
      "\n",
      " F-Score:\n",
      " 0.9018567639257293\n",
      "\n",
      " Confusion Matrix: \n",
      " [[910 122]\n",
      " [ 63 850]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[00:17:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 93.26478149100257\n",
      "\n",
      " Precision of event Happening: \n",
      " 91.95278969957081\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.86637458926616\n",
      "\n",
      " AUC: \n",
      " 0.9329946636440051\n",
      "\n",
      " F-Score:\n",
      " 0.9289972899728997\n",
      "\n",
      " Confusion Matrix: \n",
      " [[957  75]\n",
      " [ 56 857]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 90.48843187660668\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.44855967078189\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.09967141292442\n",
      "\n",
      " AUC: \n",
      " 0.9063898299328391\n",
      "\n",
      " F-Score:\n",
      " 0.9018567639257293\n",
      "\n",
      " Confusion Matrix: \n",
      " [[910 122]\n",
      " [ 63 850]]\n",
      "============================== \n",
      "\n",
      "Results with Features Selection\n",
      "age                               26.677012\n",
      "ever_married_No                   10.442816\n",
      "avg_glucose_level                  9.814887\n",
      "bmi                                7.473192\n",
      "Residence_type_Urban               5.876703\n",
      "smoking_status_Unknown             4.702454\n",
      "Residence_type_Rural               4.537217\n",
      "smoking_status_never smoked        4.036372\n",
      "work_type_Self-employed            3.283100\n",
      "gender_Female                      3.230904\n",
      "work_type_Govt_job                 3.140732\n",
      "work_type_Private                  2.912684\n",
      "smoking_status_smokes              2.733578\n",
      "ever_married_Yes                   2.669164\n",
      "gender_Male                        2.595470\n",
      "smoking_status_formerly smoked     2.513391\n",
      "work_type_children                 1.427893\n",
      "hypertension                       1.021354\n",
      "heart_disease                      0.898211\n",
      "work_type_Never_worked             0.012865\n",
      "gender_Other                       0.000000\n",
      "dtype: float64\n",
      "Selected Features =['age', 'ever_married_No', 'avg_glucose_level', 'bmi', 'Residence_type_Urban']\n",
      "(9722, 22)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.22879177377892\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.58937198067633\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.55640744797371\n",
      "\n",
      " AUC: \n",
      " 0.7953595566197135\n",
      "\n",
      " F-Score:\n",
      " 0.7926078028747434\n",
      "\n",
      " Confusion Matrix: \n",
      " [[769 263]\n",
      " [141 772]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 89.25449871465295\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.89719626168224\n",
      "\n",
      " Recall of event Happening: \n",
      " 97.15224534501642\n",
      "\n",
      " AUC: \n",
      " 0.8970984360274078\n",
      "\n",
      " F-Score:\n",
      " 0.8946041351487644\n",
      "\n",
      " Confusion Matrix: \n",
      " [[849 183]\n",
      " [ 26 887]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.03856041131105\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.97609561752988\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.04709748083242\n",
      "\n",
      " AUC: \n",
      " 0.8526967277142397\n",
      "\n",
      " F-Score:\n",
      " 0.8482003129890453\n",
      "\n",
      " Confusion Matrix: \n",
      " [[841 191]\n",
      " [100 813]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.87403598971721\n",
      "\n",
      " Precision of event Happening: \n",
      " 76.23666343355964\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.08981380065718\n",
      "\n",
      " AUC: \n",
      " 0.8117475186156891\n",
      "\n",
      " F-Score:\n",
      " 0.8086419753086419\n",
      "\n",
      " Confusion Matrix: \n",
      " [[787 245]\n",
      " [127 786]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 77.9948586118252\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.0732635585157\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.118291347207\n",
      "\n",
      " AUC: \n",
      " 0.7834790536352598\n",
      "\n",
      " F-Score:\n",
      " 0.7820773930753565\n",
      "\n",
      " Confusion Matrix: \n",
      " [[749 283]\n",
      " [145 768]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 87.96915167095116\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.15548455804047\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.60898138006573\n",
      "\n",
      " AUC: \n",
      " 0.8800604107762976\n",
      "\n",
      " F-Score:\n",
      " 0.8736501079913608\n",
      "\n",
      " Confusion Matrix: \n",
      " [[902 130]\n",
      " [104 809]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 90.8483290488432\n",
      "\n",
      " Precision of event Happening: \n",
      " 87.92569659442725\n",
      "\n",
      " Recall of event Happening: \n",
      " 93.31872946330778\n",
      "\n",
      " AUC: \n",
      " 0.909907600804911\n",
      "\n",
      " F-Score:\n",
      " 0.9054197662061637\n",
      "\n",
      " Confusion Matrix: \n",
      " [[915 117]\n",
      " [ 61 852]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.5038560411311\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.84037558685446\n",
      "\n",
      " Recall of event Happening: \n",
      " 94.96166484118291\n",
      "\n",
      " AUC: \n",
      " 0.7756804172291704\n",
      "\n",
      " F-Score:\n",
      " 0.7914194431766316\n",
      "\n",
      " Confusion Matrix: \n",
      " [[621 411]\n",
      " [ 46 867]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.86889460154242\n",
      "\n",
      " Precision of event Happening: \n",
      " 75.45638945233266\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.48959474260678\n",
      "\n",
      " AUC: \n",
      " 0.79019991169753\n",
      "\n",
      " F-Score:\n",
      " 0.783570300157978\n",
      "\n",
      " Confusion Matrix: \n",
      " [[790 242]\n",
      " [169 744]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 81.59383033419023\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.93261455525607\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.34720700985761\n",
      "\n",
      " AUC: \n",
      " 0.8215616164446369\n",
      "\n",
      " F-Score:\n",
      " 0.8232971372161896\n",
      "\n",
      " Confusion Matrix: \n",
      " [[753 279]\n",
      " [ 79 834]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[00:17:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 1 0 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.03856041131105\n",
      "\n",
      " Precision of event Happening: \n",
      " 79.06542056074767\n",
      "\n",
      " Recall of event Happening: \n",
      " 92.66155531215772\n",
      "\n",
      " AUC: \n",
      " 0.8547806447778429\n",
      "\n",
      " F-Score:\n",
      " 0.8532526475037822\n",
      "\n",
      " Confusion Matrix: \n",
      " [[808 224]\n",
      " [ 67 846]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 3948, number of negative: 3829\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 7777, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507651 -> initscore=0.030605\n",
      "[LightGBM] [Info] Start training from score 0.030605\n",
      "Prediction Vector: \n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 81.59383033419023\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.93261455525607\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.34720700985761\n",
      "\n",
      " AUC: \n",
      " 0.8215616164446369\n",
      "\n",
      " F-Score:\n",
      " 0.8232971372161896\n",
      "\n",
      " Confusion Matrix: \n",
      " [[753 279]\n",
      " [ 79 834]]\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold cross validation\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[00:19:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:19:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 797\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "============ LogReg ===========\n",
      "{'accuracy': 94.51941092628543, 'precision': 97.26000754570082, 'recall': 91.65631522464741, 'auc_val': 0.9452184788027818, 'f_score': 0.9369504446513423}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 89.67269570586917, 'precision': 83.90957861463545, 'recall': 98.1896806685764, 'auc_val': 0.8967249304974606, 'f_score': 0.904868384411421}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 96.1240954326486, 'precision': 98.90330639605607, 'recall': 93.32298189131409, 'auc_val': 0.9612657489796437, 'f_score': 0.9530060436382393}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 95.39381193457933, 'precision': 98.02533262437358, 'recall': 92.62356241708282, 'auc_val': 0.9539629122620223, 'f_score': 0.9454494382155023}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 77.43276278448141, 'precision': 74.77652752441243, 'recall': 82.86464538917197, 'auc_val': 0.7743307475853678, 'f_score': 0.7859386563951875}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 94.20002622240831, 'precision': 93.81603401770113, 'recall': 94.82288471451146, 'auc_val': 0.9420219957580214, 'f_score': 0.9383145694710914}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 97.10122906965432, 'precision': 98.88483267118097, 'recall': 95.31802164930158, 'auc_val': 0.9710362427223025, 'f_score': 0.9643514556332526}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 74.68677967678767, 'precision': 67.45537590379736, 'recall': 95.51837486585376, 'auc_val': 0.746880624635587, 'f_score': 0.7900785835031016}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 94.663570730717, 'precision': 97.50531334120657, 'recall': 91.75978739405616, 'auc_val': 0.9466628218453451, 'f_score': 0.9372588119779763}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 90.44538971997005, 'precision': 89.47847583246258, 'recall': 91.71479030936025, 'auc_val': 0.9044705554288033, 'f_score': 0.9034409930526301}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 94.1900765102204, 'precision': 94.99091554763314, 'recall': 93.40448365317177, 'auc_val': 0.9419256639710667, 'f_score': 0.9357555417745687}\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold CV, FS\n",
      "age                               31.631852\n",
      "avg_glucose_level                 10.518743\n",
      "bmi                                7.323365\n",
      "ever_married_No                    5.093922\n",
      "Residence_type_Urban               4.831430\n",
      "smoking_status_never smoked        4.418934\n",
      "smoking_status_Unknown             4.383765\n",
      "Residence_type_Rural               3.941422\n",
      "gender_Female                      3.901323\n",
      "work_type_Govt_job                 3.858451\n",
      "work_type_Private                  3.405070\n",
      "smoking_status_formerly smoked     3.250129\n",
      "gender_Male                        3.115215\n",
      "smoking_status_smokes              2.949852\n",
      "work_type_Self-employed            2.630565\n",
      "ever_married_Yes                   2.288424\n",
      "hypertension                       0.881946\n",
      "heart_disease                      0.800801\n",
      "work_type_children                 0.770143\n",
      "work_type_Never_worked             0.004648\n",
      "gender_Other                       0.000000\n",
      "dtype: float64\n",
      "Selected Features =['age', 'avg_glucose_level', 'bmi', 'ever_married_No']\n",
      "(9722, 22)\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[00:21:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:21:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Info] Number of positive: 4374, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499943 -> initscore=-0.000229\n",
      "[LightGBM] [Info] Start training from score -0.000229\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8749, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500057 -> initscore=0.000229\n",
      "[LightGBM] [Info] Start training from score 0.000229\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 4375, number of negative: 4375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 8750, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ LogReg ===========\n",
      "{'accuracy': 77.24773620257233, 'precision': 74.74108229758006, 'recall': 82.35079135717967, 'auc_val': 0.772482275796216, 'f_score': 0.783398933941712}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 89.4978514542863, 'precision': 84.43985790575124, 'recall': 96.87306174529537, 'auc_val': 0.8949755367962074, 'f_score': 0.9022506344677508}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 84.55122674347294, 'precision': 81.13990819720512, 'recall': 89.984493962363, 'auc_val': 0.8455224731918776, 'f_score': 0.852816307558745}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 79.4799398576377, 'precision': 76.16146708352248, 'recall': 85.84848023930844, 'auc_val': 0.7948063224072807, 'f_score': 0.8068304461014458}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 76.3835809659151, 'precision': 74.18510639525172, 'recall': 80.99242865955163, 'auc_val': 0.7638388217101426, 'f_score': 0.7742010793357995}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 91.10321266796088, 'precision': 90.57666973253578, 'recall': 91.73384541283241, 'auc_val': 0.911042453587514, 'f_score': 0.9105184057866136}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 93.3558444249891, 'precision': 91.94198679558087, 'recall': 95.02336468341488, 'auc_val': 0.9335623325812694, 'f_score': 0.9344651309080584}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 76.06480952803895, 'precision': 69.11457948405388, 'recall': 94.28203243170161, 'auc_val': 0.7606501550603764, 'f_score': 0.7975069241589171}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 76.89792081678573, 'precision': 73.51158935859118, 'recall': 84.26272382352693, 'auc_val': 0.7689777845379032, 'f_score': 0.7848071363362494}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 79.21241842504833, 'precision': 75.93525892500762, 'recall': 85.55965388157952, 'auc_val': 0.7921263551938887, 'f_score': 0.8044749342227784}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 83.98505534196981, 'precision': 79.09813776967734, 'recall': 92.39004233528532, 'auc_val': 0.8398547418054605, 'f_score': 0.8521110353030522}\n",
      "============================== \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e4fdc38ff680>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#all results and with addressing class imbalancing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_CImbalance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhealthdf_bal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stroke'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_supported_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Machine Learning\\Assignment8\\New folder\\TempML1.py\u001b[0m in \u001b[0;36mall_CImbalance\u001b[1;34m(df, label_col, algo_list, threshold, cross_valid_method, feature_list)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results with stratified kfold CV, FS\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[0mR4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMachineLearningwithRFFS_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_supported_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mR1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "#all results and with addressing class imbalancing\n",
    "res_all=template.all_CImbalance(healthdf_bal, 'stroke', algo_list=template.get_supported_algorithms(), threshold=5, feature_list=[]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
