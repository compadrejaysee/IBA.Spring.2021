{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churn Data Results \n",
    "\n",
    "The churn dataset consists of rows= 5986 and columns= 22. The cleaning function in template is called to change columns to numeric, which are [\"SeniorCitizen\",\"tenure\",\"MonthlyCharges\",\"TotalCharges\"]. The Total Charges column has missing values which are filled by linear interpolation and un-necessary columns are deleted.\n",
    "•\tThe heatmap of correlation shows that the correlation among features is not so high.\n",
    "•\tt-stats for equality of mean of all numeric columns suggest that mean of numeric columns are not equal\n",
    "•\tThe data of numeric columns is not normal.\n",
    "The one hot encoding is applied to string columns to create dummies, except the churn column which results in \n",
    "Rows=5986, and columns= 45)\n",
    "\n",
    "Label encoding is applied to churn column. template.apply_label_encoding(churndf, cols=['Churn'])\n",
    "Machine Learning algorithms are applied in two stages.\n",
    "1.\tIn the first sage the issue of class imbalance is not addressed. Eleven different machine learning classification algorithms are applied and four different scenarios are considered\n",
    "a.\twithout focusing the cross validation (CV) and features selection.\n",
    "b.\tOnly cross validation (CV: Stratified K-Fold) is considered\n",
    "c.\tOnly feature selection (random forest based algorithm is used) criterion is considered\n",
    "d.\tBoth cross validation (CV: Stratified K-Fold) and features selection (random forest based algorithm is used) are considered.\n",
    "The results of this stage indicate that\n",
    "•\tWith the application of CV the precision and accuracy increase in comparison to the bench mark category which is (without CV and RFFS)\n",
    "•\tThe performance in terms all four criterions (precision, recall, AUC and accuracy) worsens with the application of features selection criterion in comparison to the benchmark category\n",
    "•\tThe final Selected Features are =['tenure', 'MonthlyCharges', 'Contract_Month-to-month', 'Contract_Two year', 'OnlineSecurity_No']\n",
    "•\tWith the application of both CV and RFFS criterions, almost all 11 algorithms outperform the benchmark and RFFS based strategies however, the results are not better than the only CV based strategy.\n",
    "•\t The best performing algorithm seems to be the XGBoost and Adaboost. \n",
    "\n",
    "2.\tIn the second stage the class imbalance issue is resolved through SMOT oversampling (to increase the under sampled category which is stroke=1). The results show that \n",
    "\n",
    "Original data shape: (5986, 45)\n",
    "Resampled data shape: (8798, 45)\n",
    "\n",
    "The above four different scenarios are considered\n",
    "a.\twithout focusing the cross validation (CV) and features selection.\n",
    "b.\tOnly cross validation (CV: Stratified K-Fold) is considered\n",
    "c.\tOnly feature selection (random forest based algorithm is used) criterion is considered\n",
    "d.\tBoth cross validation (CV: Stratified K-Fold) and features selection (random forest based algorithm is used) are considered.\n",
    "The results of this stage indicate that\n",
    "•\tWith the application of CV the precision and accuracy increase in comparison to the bench mark category which is (without CV and RFFS)\n",
    "•\tThe performance in terms all four criterions (precision, recall, AUC and accuracy) worsens a little bit with the application of features selection criterion in comparison to the benchmark category\n",
    "•\tSelected Features =['tenure', 'MonthlyCharges', 'Contract_Two year', 'Contract_One year', 'TechSupport_Yes', 'Contract_Month-to-month', 'PaperlessBilling_No']\n",
    "\n",
    "•\tWith the application of both CV and RFFS criterions, almost all 11 algorithms underperform than the CV only based scenario but outperform the rest of two scenarios.\n",
    "•\t The best performing algorithm seems to be the Random Forest.\n",
    "\n",
    "\n",
    "Overall it seems that \n",
    "•\tWith the application of SMOT oversampling the performance improves in comparison to the strategy of without addressing the class imbalancing issue.\n",
    "•\tThe Random forest outperforms all the remaining algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TempML1 as template\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1869</td>\n",
       "      <td>7010-BRBUU</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>24.10</td>\n",
       "      <td>1734.65</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4528</td>\n",
       "      <td>9688-YGXVR</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>44</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>88.15</td>\n",
       "      <td>3973.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6344</td>\n",
       "      <td>9286-DOJGF</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>74.95</td>\n",
       "      <td>2869.85</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6739</td>\n",
       "      <td>6994-KERXL</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>55.90</td>\n",
       "      <td>238.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432</td>\n",
       "      <td>2181-UAESM</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>53.45</td>\n",
       "      <td>119.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "0        1869  7010-BRBUU    Male              0     Yes        Yes      72   \n",
       "1        4528  9688-YGXVR  Female              0      No         No      44   \n",
       "2        6344  9286-DOJGF  Female              1     Yes         No      38   \n",
       "3        6739  6994-KERXL    Male              0      No         No       4   \n",
       "4         432  2181-UAESM    Male              0      No         No       2   \n",
       "\n",
       "  PhoneService MultipleLines InternetService  ...     DeviceProtection  \\\n",
       "0          Yes           Yes              No  ...  No internet service   \n",
       "1          Yes            No     Fiber optic  ...                  Yes   \n",
       "2          Yes           Yes     Fiber optic  ...                   No   \n",
       "3          Yes            No             DSL  ...                   No   \n",
       "4          Yes            No             DSL  ...                  Yes   \n",
       "\n",
       "           TechSupport          StreamingTV      StreamingMovies  \\\n",
       "0  No internet service  No internet service  No internet service   \n",
       "1                   No                  Yes                   No   \n",
       "2                   No                   No                   No   \n",
       "3                   No                   No                  Yes   \n",
       "4                   No                   No                   No   \n",
       "\n",
       "         Contract PaperlessBilling              PaymentMethod MonthlyCharges  \\\n",
       "0        Two year               No    Credit card (automatic)          24.10   \n",
       "1  Month-to-month              Yes    Credit card (automatic)          88.15   \n",
       "2  Month-to-month              Yes  Bank transfer (automatic)          74.95   \n",
       "3  Month-to-month              Yes           Electronic check          55.90   \n",
       "4  Month-to-month               No           Electronic check          53.45   \n",
       "\n",
       "  TotalCharges  Churn  \n",
       "0      1734.65     No  \n",
       "1       3973.2     No  \n",
       "2      2869.85    Yes  \n",
       "3        238.5     No  \n",
       "4        119.5     No  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5986, 22)\n",
      "Unnamed: 0            int64\n",
      "customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "Churn                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"churndata.csv\"\n",
    "LABEL_COL = \"Churn\"\n",
    "churndf = template.load_data(FILE_NAME)\n",
    "display(churndf.head())\n",
    "print(churndf.shape)\n",
    "print(churndf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is all cleaned up..\n"
     ]
    }
   ],
   "source": [
    "churndf = template.cleaningup(churndf, to_numeric=[\"SeniorCitizen\",\"tenure\",\"MonthlyCharges\",\"TotalCharges\"], cols_to_interpolate=[], cols_to_delete=[\"Unnamed: 0\",\"customerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "Churn                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(churndf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is:\n",
      " (5986, 19)\n",
      "\n",
      " Columns are:\n",
      " Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
      "       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
      "       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
      "       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
      "       'MonthlyCharges', 'Churn'],\n",
      "      dtype='object')\n",
      "\n",
      " Types are:\n",
      " gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "Churn                object\n",
      "dtype: object\n",
      "\n",
      " Statistical Analysis of Numerical Columns:\n",
      "        SeniorCitizen       tenure  MonthlyCharges\n",
      "count    5986.000000  5986.000000     5986.000000\n",
      "mean        0.161377    32.468760       64.802213\n",
      "std         0.367909    24.516391       30.114702\n",
      "min         0.000000     0.000000       18.250000\n",
      "25%         0.000000     9.000000       35.650000\n",
      "50%         0.000000    29.000000       70.400000\n",
      "75%         0.000000    56.000000       89.900000\n",
      "max         1.000000    72.000000      118.750000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num must be 1 <= num <= 8, not 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cf286b53a976>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasicanalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurndf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstringcolanalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurndf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumcolanalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurndf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Machine Learning\\Assignment8\\New folder\\TempML1.py\u001b[0m in \u001b[0;36mstringcolanalysis\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstringcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Categorical.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1400\u001b[0m                     \u001b[1;31m# more similar to add_axes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1402\u001b[1;33m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_axes_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subplotspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubplotSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_subplot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\gridspec.py\u001b[0m in \u001b[0;36m_from_subplot_args\u001b[1;34m(figure, args)\u001b[0m\n\u001b[0;32m    687\u001b[0m                     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    690\u001b[0m                         f\"num must be 1 <= num <= {rows*cols}, not {num}\")\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m# -1 due to MATLAB indexing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: num must be 1 <= num <= 8, not 9"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template.basicanalysis(churndf)\n",
    "template.stringcolanalysis(churndf)\n",
    "template.numcolanalysis(churndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "churndf=template.apply_label_encoding(churndf, cols=['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>24.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>44</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>88.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>74.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>55.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>53.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>95.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>91.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>21.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>99.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>26</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>19.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5986 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0       Male              0     Yes        Yes      72          Yes   \n",
       "1     Female              0      No         No      44          Yes   \n",
       "2     Female              1     Yes         No      38          Yes   \n",
       "3       Male              0      No         No       4          Yes   \n",
       "4       Male              0      No         No       2          Yes   \n",
       "...      ...            ...     ...        ...     ...          ...   \n",
       "5981    Male              0     Yes         No       1          Yes   \n",
       "5982  Female              0     Yes        Yes      23          Yes   \n",
       "5983    Male              0     Yes        Yes      12          Yes   \n",
       "5984    Male              1      No         No      12          Yes   \n",
       "5985    Male              0      No         No      26          Yes   \n",
       "\n",
       "     MultipleLines InternetService       OnlineSecurity         OnlineBackup  \\\n",
       "0              Yes              No  No internet service  No internet service   \n",
       "1               No     Fiber optic                   No                  Yes   \n",
       "2              Yes     Fiber optic                   No                   No   \n",
       "3               No             DSL                   No                   No   \n",
       "4               No             DSL                  Yes                   No   \n",
       "...            ...             ...                  ...                  ...   \n",
       "5981            No     Fiber optic                  Yes                   No   \n",
       "5982           Yes             DSL                  Yes                  Yes   \n",
       "5983            No              No  No internet service  No internet service   \n",
       "5984           Yes     Fiber optic                   No                   No   \n",
       "5985            No              No  No internet service  No internet service   \n",
       "\n",
       "         DeviceProtection          TechSupport          StreamingTV  \\\n",
       "0     No internet service  No internet service  No internet service   \n",
       "1                     Yes                   No                  Yes   \n",
       "2                      No                   No                   No   \n",
       "3                      No                   No                   No   \n",
       "4                     Yes                   No                   No   \n",
       "...                   ...                  ...                  ...   \n",
       "5981                   No                   No                  Yes   \n",
       "5982                  Yes                  Yes                  Yes   \n",
       "5983  No internet service  No internet service  No internet service   \n",
       "5984                  Yes                   No                  Yes   \n",
       "5985  No internet service  No internet service  No internet service   \n",
       "\n",
       "          StreamingMovies        Contract PaperlessBilling  \\\n",
       "0     No internet service        Two year               No   \n",
       "1                      No  Month-to-month              Yes   \n",
       "2                      No  Month-to-month              Yes   \n",
       "3                     Yes  Month-to-month              Yes   \n",
       "4                      No  Month-to-month               No   \n",
       "...                   ...             ...              ...   \n",
       "5981                  Yes  Month-to-month              Yes   \n",
       "5982                  Yes        Two year              Yes   \n",
       "5983  No internet service  Month-to-month              Yes   \n",
       "5984                  Yes  Month-to-month              Yes   \n",
       "5985  No internet service        One year               No   \n",
       "\n",
       "                  PaymentMethod  MonthlyCharges  Churn  \n",
       "0       Credit card (automatic)           24.10      0  \n",
       "1       Credit card (automatic)           88.15      0  \n",
       "2     Bank transfer (automatic)           74.95      1  \n",
       "3              Electronic check           55.90      0  \n",
       "4              Electronic check           53.45      0  \n",
       "...                         ...             ...    ...  \n",
       "5981           Electronic check           95.00      1  \n",
       "5982    Credit card (automatic)           91.10      0  \n",
       "5983           Electronic check           21.15      0  \n",
       "5984           Electronic check           99.45      1  \n",
       "5985    Credit card (automatic)           19.80      0  \n",
       "\n",
       "[5986 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template.correlation_anlysis(churndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template.correlation(churndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test for equality of mean between all numric columns\n",
      "['SeniorCitizen', 'tenure', 'MonthlyCharges']\n",
      "(SeniorCitizen,tenure) => t-value=-101.94471591064193, p-value=0.0\n",
      "(SeniorCitizen,MonthlyCharges) => t-value=-166.05974055295823, p-value=0.0\n",
      "(tenure,MonthlyCharges) => t-value=-64.42095600158622, p-value=0.0\n"
     ]
    }
   ],
   "source": [
    "template.t_test(churndf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality Test for all numric columns\n",
      "['SeniorCitizen', 'tenure', 'MonthlyCharges']\n",
      "Normaility Test for Column: SeniorCitizen\n",
      "Statistics=0.442, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Normaility Test for Column: tenure\n",
      "Statistics=0.905, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n",
      "Normaility Test for Column: MonthlyCharges\n",
      "Statistics=0.921, p_value=0.000\n",
      "Sample does not look Gaussian (reject H0)\n"
     ]
    }
   ],
   "source": [
    "template.Normality_test(churndf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\\n            ...\\n            0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\\n           dtype='int64', length=5986)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-809b672ef0d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mANOVA_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurndf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Machine Learning\\Assignment8\\New folder\\TempML1.py\u001b[0m in \u001b[0;36mANOVA_analysis\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mcol1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[0mcol2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'col2 ~ C(Q(\"%s\"))'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m             \u001b[0manova_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manova_lm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nAnova => - %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m         self._validate_read_indexer(\n\u001b[0m\u001b[0;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\\n            ...\\n            0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\\n           dtype='int64', length=5986)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "template.ANOVA_analysis(churndf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chisquare-test for Independence between all numric columns\n",
      "(SeniorCitizen,tenure) => chisqr-value=74.87983036427057, p-value=0.3850405784641637\n",
      "Independent (H0 holds true)\n",
      "(SeniorCitizen,MonthlyCharges) => chisqr-value=1945.7876747664236, p-value=1.069010672711686e-12\n",
      "Dependent (reject H0)\n",
      "(tenure,MonthlyCharges) => chisqr-value=113008.78033508014, p-value=5.87706126800887e-12\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "template.chisquare_test(churndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "churndf = template.onehotencoding(churndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SeniorCitizen', 'tenure', 'MonthlyCharges', 'Churn', 'gender_Female',\n",
       "       'gender_Male', 'Partner_No', 'Partner_Yes', 'Dependents_No',\n",
       "       'Dependents_Yes', 'PhoneService_No', 'PhoneService_Yes',\n",
       "       'MultipleLines_No', 'MultipleLines_No phone service',\n",
       "       'MultipleLines_Yes', 'InternetService_DSL',\n",
       "       'InternetService_Fiber optic', 'InternetService_No',\n",
       "       'OnlineSecurity_No', 'OnlineSecurity_No internet service',\n",
       "       'OnlineSecurity_Yes', 'OnlineBackup_No',\n",
       "       'OnlineBackup_No internet service', 'OnlineBackup_Yes',\n",
       "       'DeviceProtection_No', 'DeviceProtection_No internet service',\n",
       "       'DeviceProtection_Yes', 'TechSupport_No',\n",
       "       'TechSupport_No internet service', 'TechSupport_Yes', 'StreamingTV_No',\n",
       "       'StreamingTV_No internet service', 'StreamingTV_Yes',\n",
       "       'StreamingMovies_No', 'StreamingMovies_No internet service',\n",
       "       'StreamingMovies_Yes', 'Contract_Month-to-month', 'Contract_One year',\n",
       "       'Contract_Two year', 'PaperlessBilling_No', 'PaperlessBilling_Yes',\n",
       "       'PaymentMethod_Bank transfer (automatic)',\n",
       "       'PaymentMethod_Credit card (automatic)',\n",
       "       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5981    1\n",
       "5982    0\n",
       "5983    0\n",
       "5984    1\n",
       "5985    0\n",
       "Name: Churn, Length: 5986, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeniorCitizen                              0\n",
       "tenure                                     0\n",
       "MonthlyCharges                             0\n",
       "Churn                                      0\n",
       "gender_Female                              0\n",
       "gender_Male                                0\n",
       "Partner_No                                 0\n",
       "Partner_Yes                                0\n",
       "Dependents_No                              0\n",
       "Dependents_Yes                             0\n",
       "PhoneService_No                            0\n",
       "PhoneService_Yes                           0\n",
       "MultipleLines_No                           0\n",
       "MultipleLines_No phone service             0\n",
       "MultipleLines_Yes                          0\n",
       "InternetService_DSL                        0\n",
       "InternetService_Fiber optic                0\n",
       "InternetService_No                         0\n",
       "OnlineSecurity_No                          0\n",
       "OnlineSecurity_No internet service         0\n",
       "OnlineSecurity_Yes                         0\n",
       "OnlineBackup_No                            0\n",
       "OnlineBackup_No internet service           0\n",
       "OnlineBackup_Yes                           0\n",
       "DeviceProtection_No                        0\n",
       "DeviceProtection_No internet service       0\n",
       "DeviceProtection_Yes                       0\n",
       "TechSupport_No                             0\n",
       "TechSupport_No internet service            0\n",
       "TechSupport_Yes                            0\n",
       "StreamingTV_No                             0\n",
       "StreamingTV_No internet service            0\n",
       "StreamingTV_Yes                            0\n",
       "StreamingMovies_No                         0\n",
       "StreamingMovies_No internet service        0\n",
       "StreamingMovies_Yes                        0\n",
       "Contract_Month-to-month                    0\n",
       "Contract_One year                          0\n",
       "Contract_Two year                          0\n",
       "PaperlessBilling_No                        0\n",
       "PaperlessBilling_Yes                       0\n",
       "PaymentMethod_Bank transfer (automatic)    0\n",
       "PaymentMethod_Credit card (automatic)      0\n",
       "PaymentMethod_Electronic check             0\n",
       "PaymentMethod_Mailed check                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndf.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#churndf=template.MinMax_Transformation(churndf,'Churn')\n",
    "#churndf=template.Standard_Transformation(churndf,'Churn')\n",
    "churndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Addressing Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.79966611018364\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.28358208955224\n",
      "\n",
      " Recall of event Happening: \n",
      " 53.8235294117647\n",
      "\n",
      " AUC: \n",
      " 0.7195838475250239\n",
      "\n",
      " F-Score:\n",
      " 0.6019736842105263\n",
      "\n",
      " Confusion Matrix: \n",
      " [[773  85]\n",
      " [157 183]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 77.12854757929884\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.458333333333336\n",
      "\n",
      " Recall of event Happening: \n",
      " 52.05882352941177\n",
      "\n",
      " AUC: \n",
      " 0.6956088029617441\n",
      "\n",
      " F-Score:\n",
      " 0.5636942675159237\n",
      "\n",
      " Confusion Matrix: \n",
      " [[747 111]\n",
      " [163 177]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.88313856427379\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.8212927756654\n",
      "\n",
      " Recall of event Happening: \n",
      " 53.23529411764706\n",
      "\n",
      " AUC: \n",
      " 0.7183909228026875\n",
      "\n",
      " F-Score:\n",
      " 0.6003316749585406\n",
      "\n",
      " Confusion Matrix: \n",
      " [[776  82]\n",
      " [159 181]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.55091819699499\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.98039215686275\n",
      "\n",
      " Recall of event Happening: \n",
      " 53.23529411764706\n",
      "\n",
      " AUC: \n",
      " 0.7230529274646921\n",
      "\n",
      " F-Score:\n",
      " 0.6084033613445378\n",
      "\n",
      " Confusion Matrix: \n",
      " [[784  74]\n",
      " [159 181]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.54757929883138\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.85427135678391\n",
      "\n",
      " Recall of event Happening: \n",
      " 41.47058823529412\n",
      "\n",
      " AUC: \n",
      " 0.6735534073769368\n",
      "\n",
      " F-Score:\n",
      " 0.5231910946196661\n",
      "\n",
      " Confusion Matrix: \n",
      " [[800  58]\n",
      " [199 141]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 72.53756260434056\n",
      "\n",
      " Precision of event Happening: \n",
      " 51.62241887905604\n",
      "\n",
      " Recall of event Happening: \n",
      " 51.470588235294116\n",
      "\n",
      " AUC: \n",
      " 0.661781845605375\n",
      "\n",
      " F-Score:\n",
      " 0.5154639175257731\n",
      "\n",
      " Confusion Matrix: \n",
      " [[694 164]\n",
      " [165 175]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.12854757929884\n",
      "\n",
      " Precision of event Happening: \n",
      " 63.306451612903224\n",
      "\n",
      " Recall of event Happening: \n",
      " 46.1764705882353\n",
      "\n",
      " AUC: \n",
      " 0.6778520499108736\n",
      "\n",
      " F-Score:\n",
      " 0.534013605442177\n",
      "\n",
      " Confusion Matrix: \n",
      " [[767  91]\n",
      " [183 157]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 68.61435726210351\n",
      "\n",
      " Precision of event Happening: \n",
      " 47.0873786407767\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.58823529411764\n",
      "\n",
      " AUC: \n",
      " 0.7373817359111478\n",
      "\n",
      " F-Score:\n",
      " 0.6075156576200417\n",
      "\n",
      " Confusion Matrix: \n",
      " [[531 327]\n",
      " [ 49 291]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.21535893155259\n",
      "\n",
      " Precision of event Happening: \n",
      " 64.17445482866043\n",
      "\n",
      " Recall of event Happening: \n",
      " 60.588235294117645\n",
      "\n",
      " AUC: \n",
      " 0.7359248594542712\n",
      "\n",
      " F-Score:\n",
      " 0.6232980332829047\n",
      "\n",
      " Confusion Matrix: \n",
      " [[743 115]\n",
      " [134 206]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.88313856427379\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.96551724137932\n",
      "\n",
      " Recall of event Happening: \n",
      " 52.94117647058824\n",
      "\n",
      " AUC: \n",
      " 0.7175030851501439\n",
      "\n",
      " F-Score:\n",
      " 0.599001663893511\n",
      "\n",
      " Confusion Matrix: \n",
      " [[777  81]\n",
      " [160 180]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without REG, CV and RFFS and addressing class imbalancing\n",
    "results_without_cv_reg_rffs= template.run_algorithms(churndf,\"Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "[22:12:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:12:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "============ LogReg ===========\n",
      "{'accuracy': 80.01982121819532, 'precision': 65.06449510972968, 'recall': 53.49375049757185, 'auc_val': 0.7154121672735293, 'f_score': 0.5865334285538959}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 77.54758488227313, 'precision': 58.24347168721063, 'recall': 53.9407690470504, 'auc_val': 0.7000302585713464, 'f_score': 0.5595904563078875}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 80.00279172087258, 'precision': 65.6628720566599, 'recall': 51.47639519146564, 'auc_val': 0.7088478591629609, 'f_score': 0.5762501157004893}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 79.90265269317312, 'precision': 65.09280667043927, 'recall': 52.36008279595573, 'auc_val': 0.7109938287654487, 'f_score': 0.5794642258825381}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 78.83412152919303, 'precision': 67.5786603786477, 'recall': 38.751293686808374, 'auc_val': 0.6602272698422009, 'f_score': 0.49088014756723525}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 73.12066934299642, 'precision': 49.22086194906872, 'recall': 50.165989968951514, 'auc_val': 0.6578552138745773, 'f_score': 0.49618446765129576}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 78.26581091116186, 'precision': 61.84934515030879, 'recall': 47.06989889340021, 'auc_val': 0.6829507058979392, 'f_score': 0.5338293922334765}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 69.11117190858789, 'precision': 45.58737229111547, 'recall': 84.49526311599394, 'auc_val': 0.7402760670813158, 'f_score': 0.592067562740114}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 80.17032289043613, 'precision': 65.6012650260515, 'recall': 53.30905182708383, 'auc_val': 0.7158548988123709, 'f_score': 0.587138453199198}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 73.48817147866288, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 79.9195984388697, 'precision': 65.3989157910599, 'recall': 51.666666666666664, 'auc_val': 0.7088911610409332, 'f_score': 0.5760968095546256}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV and without addressing class imbalancing\n",
    "results_cv = template.run_algorithms_cv(churndf,\"Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure                                     18.969936\n",
      "MonthlyCharges                             18.756975\n",
      "Contract_Month-to-month                     5.083395\n",
      "Contract_Two year                           3.860528\n",
      "OnlineSecurity_No                           3.468817\n",
      "InternetService_Fiber optic                 2.460405\n",
      "PaymentMethod_Electronic check              2.378163\n",
      "OnlineBackup_No                             2.260497\n",
      "gender_Male                                 2.170554\n",
      "SeniorCitizen                               2.121540\n",
      "PaperlessBilling_Yes                        1.988469\n",
      "gender_Female                               1.868199\n",
      "PaperlessBilling_No                         1.755137\n",
      "Partner_No                                  1.729713\n",
      "Contract_One year                           1.718066\n",
      "TechSupport_Yes                             1.698950\n",
      "PaymentMethod_Credit card (automatic)       1.655844\n",
      "Partner_Yes                                 1.644719\n",
      "Dependents_No                               1.572277\n",
      "OnlineBackup_Yes                            1.556727\n",
      "MultipleLines_Yes                           1.523760\n",
      "MultipleLines_No                            1.475823\n",
      "DeviceProtection_Yes                        1.456130\n",
      "PaymentMethod_Bank transfer (automatic)     1.418241\n",
      "PaymentMethod_Mailed check                  1.403372\n",
      "Dependents_Yes                              1.331855\n",
      "StreamingMovies_Yes                         1.328920\n",
      "StreamingTV_No                              1.301808\n",
      "StreamingMovies_No                          1.275133\n",
      "TechSupport_No                              1.265346\n",
      "StreamingTV_Yes                             1.221257\n",
      "DeviceProtection_No                         1.145908\n",
      "OnlineSecurity_Yes                          1.077995\n",
      "InternetService_DSL                         1.045661\n",
      "InternetService_No                          0.614281\n",
      "StreamingTV_No internet service             0.597804\n",
      "PhoneService_Yes                            0.440078\n",
      "PhoneService_No                             0.350449\n",
      "OnlineSecurity_No internet service          0.336775\n",
      "MultipleLines_No phone service              0.302924\n",
      "TechSupport_No internet service             0.237363\n",
      "StreamingMovies_No internet service         0.059165\n",
      "DeviceProtection_No internet service        0.053159\n",
      "OnlineBackup_No internet service            0.017877\n",
      "dtype: float64\n",
      "Selected Features =['tenure', 'MonthlyCharges', 'Contract_Month-to-month', 'Contract_Two year', 'OnlineSecurity_No']\n",
      "(5986, 45)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.04841402337229\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.04980842911877\n",
      "\n",
      " Recall of event Happening: \n",
      " 51.470588235294116\n",
      "\n",
      " AUC: \n",
      " 0.7072363910599204\n",
      "\n",
      " F-Score:\n",
      " 0.5823627287853578\n",
      "\n",
      " Confusion Matrix: \n",
      " [[772  86]\n",
      " [165 175]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.62771285475793\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.19402985074627\n",
      "\n",
      " Recall of event Happening: \n",
      " 48.23529411764706\n",
      "\n",
      " AUC: \n",
      " 0.6805704099821748\n",
      "\n",
      " F-Score:\n",
      " 0.5394736842105263\n",
      "\n",
      " Confusion Matrix: \n",
      " [[754 104]\n",
      " [176 164]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.79966611018364\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.24793388429752\n",
      "\n",
      " Recall of event Happening: \n",
      " 50.0\n",
      "\n",
      " AUC: \n",
      " 0.708041958041958\n",
      "\n",
      " F-Score:\n",
      " 0.5841924398625429\n",
      "\n",
      " Confusion Matrix: \n",
      " [[786  72]\n",
      " [170 170]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.21535893155259\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.57142857142857\n",
      "\n",
      " Recall of event Happening: \n",
      " 49.411764705882355\n",
      "\n",
      " AUC: \n",
      " 0.702187028657617\n",
      "\n",
      " F-Score:\n",
      " 0.5743589743589744\n",
      "\n",
      " Confusion Matrix: \n",
      " [[781  77]\n",
      " [172 168]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.63105175292154\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.875\n",
      "\n",
      " Recall of event Happening: \n",
      " 40.588235294117645\n",
      "\n",
      " AUC: \n",
      " 0.6714726450020567\n",
      "\n",
      " F-Score:\n",
      " 0.5187969924812031\n",
      "\n",
      " Confusion Matrix: \n",
      " [[804  54]\n",
      " [202 138]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 71.03505843071787\n",
      "\n",
      " Precision of event Happening: \n",
      " 49.03047091412742\n",
      "\n",
      " Recall of event Happening: \n",
      " 52.05882352941177\n",
      "\n",
      " AUC: \n",
      " 0.6530680104209515\n",
      "\n",
      " F-Score:\n",
      " 0.5049928673323824\n",
      "\n",
      " Confusion Matrix: \n",
      " [[674 184]\n",
      " [163 177]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 75.12520868113522\n",
      "\n",
      " Precision of event Happening: \n",
      " 57.04697986577181\n",
      "\n",
      " Recall of event Happening: \n",
      " 50.0\n",
      "\n",
      " AUC: \n",
      " 0.6754079254079254\n",
      "\n",
      " F-Score:\n",
      " 0.5329153605015674\n",
      "\n",
      " Confusion Matrix: \n",
      " [[730 128]\n",
      " [170 170]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 73.53923205342237\n",
      "\n",
      " Precision of event Happening: \n",
      " 52.18216318785579\n",
      "\n",
      " Recall of event Happening: \n",
      " 80.88235294117648\n",
      "\n",
      " AUC: \n",
      " 0.7575586178527355\n",
      "\n",
      " F-Score:\n",
      " 0.6343713956170705\n",
      "\n",
      " Confusion Matrix: \n",
      " [[606 252]\n",
      " [ 65 275]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.54757929883138\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.72774869109948\n",
      "\n",
      " Recall of event Happening: \n",
      " 40.294117647058826\n",
      "\n",
      " AUC: \n",
      " 0.6700020567667626\n",
      "\n",
      " F-Score:\n",
      " 0.5160075329566856\n",
      "\n",
      " Confusion Matrix: \n",
      " [[804  54]\n",
      " [203 137]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 334\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:13:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.63272120200334\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 49.411764705882355\n",
      "\n",
      " AUC: \n",
      " 0.7051007815713698\n",
      "\n",
      " F-Score:\n",
      " 0.5793103448275863\n",
      "\n",
      " Confusion Matrix: \n",
      " [[786  72]\n",
      " [172 168]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 334\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with RFFS only and without addressing class imbalancing\n",
    "res_rffs = template.MachineLearningwithRFFS(churndf,\"Churn\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure                                     18.881704\n",
      "MonthlyCharges                             18.384412\n",
      "Contract_Month-to-month                     3.930834\n",
      "PaymentMethod_Electronic check              3.603530\n",
      "OnlineBackup_No                             3.186785\n",
      "TechSupport_No                              3.055247\n",
      "Contract_Two year                           2.897013\n",
      "InternetService_Fiber optic                 2.529747\n",
      "OnlineSecurity_No                           2.386870\n",
      "SeniorCitizen                               2.384005\n",
      "gender_Female                               2.268380\n",
      "DeviceProtection_No                         2.263836\n",
      "gender_Male                                 2.205164\n",
      "PaperlessBilling_No                         2.134228\n",
      "Partner_Yes                                 1.709797\n",
      "OnlineSecurity_Yes                          1.676472\n",
      "Contract_One year                           1.610750\n",
      "MultipleLines_No                            1.609141\n",
      "MultipleLines_Yes                           1.605930\n",
      "StreamingTV_No                              1.534992\n",
      "Partner_No                                  1.525127\n",
      "StreamingMovies_Yes                         1.490584\n",
      "Dependents_No                               1.437752\n",
      "PaymentMethod_Bank transfer (automatic)     1.433694\n",
      "DeviceProtection_Yes                        1.408570\n",
      "StreamingMovies_No                          1.380678\n",
      "StreamingTV_Yes                             1.373900\n",
      "PaymentMethod_Mailed check                  1.358412\n",
      "PaymentMethod_Credit card (automatic)       1.315625\n",
      "TechSupport_Yes                             1.279462\n",
      "PaperlessBilling_Yes                        1.223448\n",
      "Dependents_Yes                              1.204803\n",
      "OnlineBackup_Yes                            1.140608\n",
      "InternetService_DSL                         1.103015\n",
      "PhoneService_Yes                            0.424909\n",
      "PhoneService_No                             0.372746\n",
      "MultipleLines_No phone service              0.324902\n",
      "StreamingTV_No internet service             0.120972\n",
      "OnlineBackup_No internet service            0.090261\n",
      "TechSupport_No internet service             0.057934\n",
      "InternetService_No                          0.038461\n",
      "OnlineSecurity_No internet service          0.021082\n",
      "DeviceProtection_No internet service        0.012828\n",
      "StreamingMovies_No internet service         0.001392\n",
      "dtype: float64\n",
      "Selected Features =['tenure', 'MonthlyCharges', 'Contract_Month-to-month', 'PaymentMethod_Electronic check', 'OnlineBackup_No', 'TechSupport_No']\n",
      "(5986, 45)\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22:14:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 336\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "============ LogReg ===========\n",
      "{'accuracy': 79.33484458489903, 'precision': 63.59418448964218, 'recall': 51.54088050314465, 'auc_val': 0.704510677106736, 'f_score': 0.5689890671740996}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 76.89624848549143, 'precision': 57.646534363538116, 'recall': 48.0188679245283, 'auc_val': 0.6766710118115006, 'f_score': 0.5231988359683}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 79.50215241679277, 'precision': 64.91881446349248, 'recall': 49.335642066714435, 'auc_val': 0.698599933257573, 'f_score': 0.559523249479853}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 79.26789911837454, 'precision': 63.64461614011437, 'recall': 50.720484037895076, 'auc_val': 0.701432198611509, 'f_score': 0.5640946581798935}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 78.56667466959983, 'precision': 67.25105173103063, 'recall': 37.30117028898973, 'auc_val': 0.6537721073985622, 'f_score': 0.47796194249952445}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 72.4362231366659, 'precision': 48.00311350430279, 'recall': 47.388344877000236, 'auc_val': 0.6443076386529656, 'f_score': 0.47643817054736004}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 76.29499556116382, 'precision': 56.3434368090931, 'recall': 47.010190271475196, 'auc_val': 0.6693551551262723, 'f_score': 0.5114605655180895}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 75.09198720275151, 'precision': 52.187818462460406, 'recall': 72.14672398694371, 'auc_val': 0.7415026714981892, 'f_score': 0.6053401499497092}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 79.28470527802747, 'precision': 64.00687618292467, 'recall': 50.85224106360958, 'auc_val': 0.7019752765543288, 'f_score': 0.56451647987163}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 73.48817147866288, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 79.1013450511164, 'precision': 63.32985986238693, 'recall': 50.158426876841006, 'auc_val': 0.6985085352953668, 'f_score': 0.5594946294141162}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV and RFFS and without addressing class imbalancing\n",
    "res_rffs_cv = template.MachineLearningwithRFFS_CV(churndf,\"Churn\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without FS, REG and CV\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.79966611018364\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.28358208955224\n",
      "\n",
      " Recall of event Happening: \n",
      " 53.8235294117647\n",
      "\n",
      " AUC: \n",
      " 0.7195838475250239\n",
      "\n",
      " F-Score:\n",
      " 0.6019736842105263\n",
      "\n",
      " Confusion Matrix: \n",
      " [[773  85]\n",
      " [157 183]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 77.12854757929884\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.458333333333336\n",
      "\n",
      " Recall of event Happening: \n",
      " 52.05882352941177\n",
      "\n",
      " AUC: \n",
      " 0.6956088029617441\n",
      "\n",
      " F-Score:\n",
      " 0.5636942675159237\n",
      "\n",
      " Confusion Matrix: \n",
      " [[747 111]\n",
      " [163 177]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.88313856427379\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.8212927756654\n",
      "\n",
      " Recall of event Happening: \n",
      " 53.23529411764706\n",
      "\n",
      " AUC: \n",
      " 0.7183909228026875\n",
      "\n",
      " F-Score:\n",
      " 0.6003316749585406\n",
      "\n",
      " Confusion Matrix: \n",
      " [[776  82]\n",
      " [159 181]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.55091819699499\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.98039215686275\n",
      "\n",
      " Recall of event Happening: \n",
      " 53.23529411764706\n",
      "\n",
      " AUC: \n",
      " 0.7230529274646921\n",
      "\n",
      " F-Score:\n",
      " 0.6084033613445378\n",
      "\n",
      " Confusion Matrix: \n",
      " [[784  74]\n",
      " [159 181]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.54757929883138\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.85427135678391\n",
      "\n",
      " Recall of event Happening: \n",
      " 41.47058823529412\n",
      "\n",
      " AUC: \n",
      " 0.6735534073769368\n",
      "\n",
      " F-Score:\n",
      " 0.5231910946196661\n",
      "\n",
      " Confusion Matrix: \n",
      " [[800  58]\n",
      " [199 141]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 73.45575959933221\n",
      "\n",
      " Precision of event Happening: \n",
      " 53.142857142857146\n",
      "\n",
      " Recall of event Happening: \n",
      " 54.70588235294118\n",
      "\n",
      " AUC: \n",
      " 0.6779583161936104\n",
      "\n",
      " F-Score:\n",
      " 0.5391304347826088\n",
      "\n",
      " Confusion Matrix: \n",
      " [[694 164]\n",
      " [154 186]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 0 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.79465776293823\n",
      "\n",
      " Precision of event Happening: \n",
      " 62.704918032786885\n",
      "\n",
      " Recall of event Happening: \n",
      " 45.0\n",
      "\n",
      " AUC: \n",
      " 0.6719696969696969\n",
      "\n",
      " F-Score:\n",
      " 0.523972602739726\n",
      "\n",
      " Confusion Matrix: \n",
      " [[767  91]\n",
      " [187 153]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 68.61435726210351\n",
      "\n",
      " Precision of event Happening: \n",
      " 47.0873786407767\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.58823529411764\n",
      "\n",
      " AUC: \n",
      " 0.7373817359111478\n",
      "\n",
      " F-Score:\n",
      " 0.6075156576200417\n",
      "\n",
      " Confusion Matrix: \n",
      " [[531 327]\n",
      " [ 49 291]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.29883138564274\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.19718309859155\n",
      "\n",
      " Recall of event Happening: \n",
      " 55.294117647058826\n",
      "\n",
      " AUC: \n",
      " 0.7205265322912382\n",
      "\n",
      " F-Score:\n",
      " 0.6025641025641025\n",
      "\n",
      " Confusion Matrix: \n",
      " [[762  96]\n",
      " [152 188]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:14:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.88313856427379\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.96551724137932\n",
      "\n",
      " Recall of event Happening: \n",
      " 52.94117647058824\n",
      "\n",
      " AUC: \n",
      " 0.7175030851501439\n",
      "\n",
      " F-Score:\n",
      " 0.599001663893511\n",
      "\n",
      " Confusion Matrix: \n",
      " [[777  81]\n",
      " [160 180]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n",
      "Results with Features Selection\n",
      "MonthlyCharges                             19.456269\n",
      "tenure                                     19.191316\n",
      "Contract_Month-to-month                     5.597464\n",
      "OnlineSecurity_No                           4.605178\n",
      "PaymentMethod_Electronic check              2.609448\n",
      "SeniorCitizen                               2.535446\n",
      "InternetService_Fiber optic                 2.130062\n",
      "gender_Male                                 2.098882\n",
      "Contract_Two year                           2.003504\n",
      "gender_Female                               1.983827\n",
      "OnlineBackup_Yes                            1.851085\n",
      "OnlineBackup_No                             1.822822\n",
      "MultipleLines_No                            1.749730\n",
      "Partner_No                                  1.732928\n",
      "Partner_Yes                                 1.705491\n",
      "PaperlessBilling_No                         1.678576\n",
      "TechSupport_Yes                             1.594975\n",
      "DeviceProtection_No                         1.577721\n",
      "PaymentMethod_Credit card (automatic)       1.491039\n",
      "PaperlessBilling_Yes                        1.488458\n",
      "MultipleLines_Yes                           1.475850\n",
      "StreamingMovies_Yes                         1.451060\n",
      "Dependents_Yes                              1.384515\n",
      "Dependents_No                               1.381331\n",
      "PaymentMethod_Bank transfer (automatic)     1.380703\n",
      "PaymentMethod_Mailed check                  1.329794\n",
      "TechSupport_No                              1.300973\n",
      "StreamingTV_No                              1.288892\n",
      "StreamingTV_Yes                             1.266403\n",
      "DeviceProtection_Yes                        1.261582\n",
      "StreamingMovies_No                          1.192666\n",
      "OnlineBackup_No internet service            1.133201\n",
      "Contract_One year                           0.947632\n",
      "DeviceProtection_No internet service        0.908470\n",
      "OnlineSecurity_Yes                          0.803781\n",
      "InternetService_DSL                         0.762340\n",
      "TechSupport_No internet service             0.620682\n",
      "MultipleLines_No phone service              0.470692\n",
      "PhoneService_Yes                            0.385781\n",
      "PhoneService_No                             0.266652\n",
      "InternetService_No                          0.065207\n",
      "StreamingMovies_No internet service         0.010228\n",
      "StreamingTV_No internet service             0.006287\n",
      "OnlineSecurity_No internet service          0.001058\n",
      "dtype: float64\n",
      "Selected Features =['MonthlyCharges', 'tenure', 'Contract_Month-to-month']\n",
      "(5986, 45)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.54757929883138\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.27450980392156\n",
      "\n",
      " Recall of event Happening: \n",
      " 49.705882352941174\n",
      "\n",
      " AUC: \n",
      " 0.6984128616481557\n",
      "\n",
      " F-Score:\n",
      " 0.5680672268907564\n",
      "\n",
      " Confusion Matrix: \n",
      " [[772  86]\n",
      " [171 169]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.71118530884809\n",
      "\n",
      " Precision of event Happening: \n",
      " 61.42322097378277\n",
      "\n",
      " Recall of event Happening: \n",
      " 48.23529411764706\n",
      "\n",
      " AUC: \n",
      " 0.6811531605649254\n",
      "\n",
      " F-Score:\n",
      " 0.5403624382207578\n",
      "\n",
      " Confusion Matrix: \n",
      " [[755 103]\n",
      " [176 164]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.88146911519198\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.90123456790124\n",
      "\n",
      " Recall of event Happening: \n",
      " 48.529411764705884\n",
      "\n",
      " AUC: \n",
      " 0.697192513368984\n",
      "\n",
      " F-Score:\n",
      " 0.5660377358490567\n",
      "\n",
      " Confusion Matrix: \n",
      " [[780  78]\n",
      " [175 165]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.63105175292154\n",
      "\n",
      " Precision of event Happening: \n",
      " 67.5\n",
      "\n",
      " Recall of event Happening: \n",
      " 47.647058823529406\n",
      "\n",
      " AUC: \n",
      " 0.6927807486631016\n",
      "\n",
      " F-Score:\n",
      " 0.5586206896551724\n",
      "\n",
      " Confusion Matrix: \n",
      " [[780  78]\n",
      " [178 162]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.46410684474124\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.80851063829788\n",
      "\n",
      " Recall of event Happening: \n",
      " 39.705882352941174\n",
      "\n",
      " AUC: \n",
      " 0.667643630878925\n",
      "\n",
      " F-Score:\n",
      " 0.5113636363636364\n",
      "\n",
      " Confusion Matrix: \n",
      " [[805  53]\n",
      " [205 135]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 70.20033388981636\n",
      "\n",
      " Precision of event Happening: \n",
      " 47.55043227665706\n",
      "\n",
      " Recall of event Happening: \n",
      " 48.529411764705884\n",
      "\n",
      " AUC: \n",
      " 0.6365864527629234\n",
      "\n",
      " F-Score:\n",
      " 0.480349344978166\n",
      "\n",
      " Confusion Matrix: \n",
      " [[676 182]\n",
      " [175 165]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.12687813021702\n",
      "\n",
      " Precision of event Happening: \n",
      " 59.57446808510638\n",
      "\n",
      " Recall of event Happening: \n",
      " 49.411764705882355\n",
      "\n",
      " AUC: \n",
      " 0.6806252570958453\n",
      "\n",
      " F-Score:\n",
      " 0.5401929260450161\n",
      "\n",
      " Confusion Matrix: \n",
      " [[744 114]\n",
      " [172 168]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 74.87479131886478\n",
      "\n",
      " Precision of event Happening: \n",
      " 54.441913439635535\n",
      "\n",
      " Recall of event Happening: \n",
      " 70.29411764705881\n",
      "\n",
      " AUC: \n",
      " 0.7349204716851776\n",
      "\n",
      " F-Score:\n",
      " 0.613607188703466\n",
      "\n",
      " Confusion Matrix: \n",
      " [[658 200]\n",
      " [101 239]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.54757929883138\n",
      "\n",
      " Precision of event Happening: \n",
      " 66.02316602316603\n",
      "\n",
      " Recall of event Happening: \n",
      " 50.294117647058826\n",
      "\n",
      " AUC: \n",
      " 0.7001885369532429\n",
      "\n",
      " F-Score:\n",
      " 0.5709515859766277\n",
      "\n",
      " Confusion Matrix: \n",
      " [[770  88]\n",
      " [169 171]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:14:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 0 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 79.13188647746243\n",
      "\n",
      " Precision of event Happening: \n",
      " 68.59504132231406\n",
      "\n",
      " Recall of event Happening: \n",
      " 48.8235294117647\n",
      "\n",
      " AUC: \n",
      " 0.6998286027697793\n",
      "\n",
      " F-Score:\n",
      " 0.5704467353951891\n",
      "\n",
      " Confusion Matrix: \n",
      " [[782  76]\n",
      " [174 166]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 1247, number of negative: 3541\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 4788, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260443 -> initscore=-1.043669\n",
      "[LightGBM] [Info] Start training from score -1.043669\n",
      "Prediction Vector: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 71.61936560934892\n",
      "\n",
      " Precision of event Happening: \n",
      " 0.0\n",
      "\n",
      " Recall of event Happening: \n",
      " 0.0\n",
      "\n",
      " AUC: \n",
      " 0.5\n",
      "\n",
      " F-Score:\n",
      " 0.0\n",
      "\n",
      " Confusion Matrix: \n",
      " [[858   0]\n",
      " [340   0]]\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold cross validation\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "[22:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "============ LogReg ===========\n",
      "{'accuracy': 80.01982121819532, 'precision': 65.06449510972968, 'recall': 53.49375049757185, 'auc_val': 0.7154121672735293, 'f_score': 0.5865334285538959}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 77.54758488227313, 'precision': 58.24347168721063, 'recall': 53.9407690470504, 'auc_val': 0.7000302585713464, 'f_score': 0.5595904563078875}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 80.05293102774412, 'precision': 65.82310999907261, 'recall': 51.47639519146564, 'auc_val': 0.70918876825387, 'f_score': 0.5768464076676045}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 79.90265269317312, 'precision': 65.09280667043927, 'recall': 52.36008279595573, 'auc_val': 0.7109938287654487, 'f_score': 0.5794642258825381}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 78.83412152919303, 'precision': 67.5786603786477, 'recall': 38.751293686808374, 'auc_val': 0.6602272698422009, 'f_score': 0.49088014756723525}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 72.93689035795445, 'precision': 48.987255124535515, 'recall': 49.47018549478544, 'auc_val': 0.6543772269148052, 'f_score': 0.4913438762430803}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 77.94850391678438, 'precision': 60.99269560781654, 'recall': 46.944908844837194, 'auc_val': 0.6803954905898931, 'f_score': 0.5296850423665471}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 69.11117190858789, 'precision': 45.58737229111547, 'recall': 84.49526311599394, 'auc_val': 0.7402760670813158, 'f_score': 0.592067562740114}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 80.08654334705, 'precision': 65.82014296891899, 'recall': 52.61722792771277, 'auc_val': 0.71307397355863, 'f_score': 0.5831519705937938}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 73.48817147866288, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 79.9195984388697, 'precision': 65.3989157910599, 'recall': 51.666666666666664, 'auc_val': 0.7088911610409332, 'f_score': 0.5760968095546256}\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold CV, FS\n",
      "tenure                                     18.923731\n",
      "MonthlyCharges                             18.475376\n",
      "OnlineSecurity_No                           5.990441\n",
      "Contract_Month-to-month                     3.274461\n",
      "PaymentMethod_Electronic check              3.143642\n",
      "Contract_Two year                           2.906457\n",
      "TechSupport_No                              2.727074\n",
      "SeniorCitizen                               2.430916\n",
      "gender_Male                                 2.330576\n",
      "gender_Female                               2.011119\n",
      "PaperlessBilling_Yes                        1.818988\n",
      "MultipleLines_Yes                           1.816002\n",
      "MultipleLines_No                            1.728393\n",
      "OnlineBackup_No                             1.727589\n",
      "TechSupport_Yes                             1.715858\n",
      "PaymentMethod_Credit card (automatic)       1.682623\n",
      "OnlineBackup_Yes                            1.671615\n",
      "PaymentMethod_Bank transfer (automatic)     1.668657\n",
      "PaperlessBilling_No                         1.627686\n",
      "Partner_No                                  1.627311\n",
      "Partner_Yes                                 1.620657\n",
      "InternetService_Fiber optic                 1.548167\n",
      "DeviceProtection_No                         1.432066\n",
      "DeviceProtection_Yes                        1.409825\n",
      "Dependents_Yes                              1.396715\n",
      "Dependents_No                               1.354991\n",
      "StreamingMovies_Yes                         1.335582\n",
      "StreamingMovies_No                          1.322185\n",
      "Contract_One year                           1.315510\n",
      "StreamingTV_Yes                             1.255546\n",
      "PaymentMethod_Mailed check                  1.207917\n",
      "StreamingTV_No                              1.089635\n",
      "StreamingTV_No internet service             1.017746\n",
      "OnlineSecurity_Yes                          0.999087\n",
      "InternetService_DSL                         0.779335\n",
      "PhoneService_No                             0.380146\n",
      "PhoneService_Yes                            0.375800\n",
      "MultipleLines_No phone service              0.250038\n",
      "DeviceProtection_No internet service        0.210474\n",
      "StreamingMovies_No internet service         0.178406\n",
      "TechSupport_No internet service             0.124490\n",
      "InternetService_No                          0.053041\n",
      "OnlineBackup_No internet service            0.037076\n",
      "OnlineSecurity_No internet service          0.007049\n",
      "dtype: float64\n",
      "Selected Features =['tenure', 'MonthlyCharges', 'OnlineSecurity_No']\n",
      "(5986, 45)\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "[22:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5387, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265083 -> initscore=-1.019717\n",
      "[LightGBM] [Info] Start training from score -1.019717\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265219 -> initscore=-1.019017\n",
      "[LightGBM] [Info] Start training from score -1.019017\n",
      "[LightGBM] [Info] Number of positive: 1428, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 5388, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265033 -> initscore=-1.019969\n",
      "[LightGBM] [Info] Start training from score -1.019969\n",
      "============ LogReg ===========\n",
      "{'accuracy': 78.34900419316475, 'precision': 62.37921784763955, 'recall': 46.06002706790861, 'auc_val': 0.6802882281123739, 'f_score': 0.5292465475857433}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 77.13005510857002, 'precision': 58.3525899391999, 'recall': 47.700023883448765, 'auc_val': 0.6772384710428392, 'f_score': 0.5238471824447486}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 79.58537361600438, 'precision': 65.89726625986277, 'recall': 47.57105326009076, 'auc_val': 0.693526212666161, 'f_score': 0.5517992551612436}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 78.83375860547959, 'precision': 63.46707386726938, 'recall': 47.762916965209776, 'auc_val': 0.6890289149150941, 'f_score': 0.5436047926259292}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 78.61681397647136, 'precision': 68.34260942590437, 'recall': 36.292492635936625, 'auc_val': 0.6508885866006813, 'f_score': 0.4716750886927755}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 71.76693597467352, 'precision': 46.6686198014029, 'recall': 46.69254040283416, 'auc_val': 0.6375339382949743, 'f_score': 0.46603919605911254}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 74.74081663418966, 'precision': 52.62475948967523, 'recall': 44.36231191784093, 'auc_val': 0.6503174614322363, 'f_score': 0.48050531969996085}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 75.64273789649415, 'precision': 53.67426870904203, 'recall': 60.299339224584024, 'auc_val': 0.7073837845470244, 'f_score': 0.5676309572302751}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 78.64964461393292, 'precision': 64.58643445938235, 'recall': 44.04068147440491, 'auc_val': 0.6758686589769116, 'f_score': 0.5202810475147965}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 73.48817147866288, 'precision': 0.0, 'recall': 0.0, 'auc_val': 0.5, 'f_score': 0.0}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 78.91734272840463, 'precision': 64.34366209572423, 'recall': 45.87174588010508, 'auc_val': 0.6835508499223726, 'f_score': 0.5345707650345242}\n",
      "============================== \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-df0b4fa492ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#all results without addressing class imbalancing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_CImbalance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurndf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Churn\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_supported_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Machine Learning\\Assignment8\\New folder\\TempML1.py\u001b[0m in \u001b[0;36mall_CImbalance\u001b[1;34m(df, label_col, algo_list, threshold, cross_valid_method, feature_list)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results with stratified kfold CV, FS\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[0mR4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMachineLearningwithRFFS_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_supported_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mR1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "#all results without addressing class imbalancing\n",
    "res_all=template.all_CImbalance(churndf,\"Churn\", algo_list=template.get_supported_algorithms(), threshold=3, feature_list=[]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  With Adressing Class Imbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep copy\n",
    "churndf_bal1 = churndf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "churndf_bal=template.SMOT_OverSampling(churndf_bal1,\"Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal data shape: (5986, 45)\n",
      "Resampled data shape: (8798, 45)\n"
     ]
    }
   ],
   "source": [
    "print('Orignal data shape:', churndf.shape)\n",
    "print('Resampled data shape:', churndf_bal.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 83.97727272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.17200474495849\n",
      "\n",
      " Recall of event Happening: \n",
      " 82.05714285714286\n",
      "\n",
      " AUC: \n",
      " 0.8396642453591607\n",
      "\n",
      " F-Score:\n",
      " 0.8358556461001164\n",
      "\n",
      " Confusion Matrix: \n",
      " [[760 125]\n",
      " [157 718]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.85227272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 75.42533081285444\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.2\n",
      "\n",
      " AUC: \n",
      " 0.8091073446327685\n",
      "\n",
      " F-Score:\n",
      " 0.825659596482152\n",
      "\n",
      " Confusion Matrix: \n",
      " [[625 260]\n",
      " [ 77 798]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.9090909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.5039637599094\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.28571428571429\n",
      "\n",
      " AUC: \n",
      " 0.8591121872477805\n",
      "\n",
      " F-Score:\n",
      " 0.8589306029579067\n",
      "\n",
      " Confusion Matrix: \n",
      " [[757 128]\n",
      " [120 755]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.51136363636364\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.06787330316742\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.94285714285715\n",
      "\n",
      " AUC: \n",
      " 0.8551380145278451\n",
      "\n",
      " F-Score:\n",
      " 0.855031267765776\n",
      "\n",
      " Confusion Matrix: \n",
      " [[753 132]\n",
      " [123 752]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.02272727272728\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.18321392016377\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.71428571428572\n",
      "\n",
      " AUC: \n",
      " 0.760548829701372\n",
      "\n",
      " F-Score:\n",
      " 0.7721382289416848\n",
      "\n",
      " Confusion Matrix: \n",
      " [[623 262]\n",
      " [160 715]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.42045454545455\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.30973451327434\n",
      "\n",
      " Recall of event Happening: \n",
      " 82.97142857142858\n",
      "\n",
      " AUC: \n",
      " 0.8142921711057305\n",
      "\n",
      " F-Score:\n",
      " 0.8161888701517707\n",
      "\n",
      " Confusion Matrix: \n",
      " [[707 178]\n",
      " [149 726]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.17045454545455\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.03286384976526\n",
      "\n",
      " Recall of event Happening: \n",
      " 83.77142857142857\n",
      "\n",
      " AUC: \n",
      " 0.8516255044390637\n",
      "\n",
      " F-Score:\n",
      " 0.8488708743485813\n",
      "\n",
      " Confusion Matrix: \n",
      " [[766 119]\n",
      " [142 733]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.8409090909091\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.79784102060843\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.94285714285715\n",
      "\n",
      " AUC: \n",
      " 0.7788668280871671\n",
      "\n",
      " F-Score:\n",
      " 0.7940865892291447\n",
      "\n",
      " Confusion Matrix: \n",
      " [[618 267]\n",
      " [123 752]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 84.26136363636364\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.68019093078759\n",
      "\n",
      " Recall of event Happening: \n",
      " 82.05714285714286\n",
      "\n",
      " AUC: \n",
      " 0.8424891041162228\n",
      "\n",
      " F-Score:\n",
      " 0.8382953882078226\n",
      "\n",
      " Confusion Matrix: \n",
      " [[765 120]\n",
      " [157 718]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "Prediction Vector: \n",
      " [0. 1. 1. ... 1. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 81.5340909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.70563674321504\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.17142857142858\n",
      "\n",
      " AUC: \n",
      " 0.8156029055690073\n",
      "\n",
      " F-Score:\n",
      " 0.822695035460993\n",
      "\n",
      " Confusion Matrix: \n",
      " [[681 204]\n",
      " [121 754]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:22:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 83.97727272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.12351029252439\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.62857142857143\n",
      "\n",
      " AUC: \n",
      " 0.8399225181598063\n",
      "\n",
      " F-Score:\n",
      " 0.8431590656284762\n",
      "\n",
      " Confusion Matrix: \n",
      " [[720 165]\n",
      " [117 758]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "Prediction Vector: \n",
      " [0. 1. 1. ... 1. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 81.5340909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.70563674321504\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.17142857142858\n",
      "\n",
      " AUC: \n",
      " 0.8156029055690073\n",
      "\n",
      " F-Score:\n",
      " 0.822695035460993\n",
      "\n",
      " Confusion Matrix: \n",
      " [[681 204]\n",
      " [121 754]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without REG, CV and RFFS and with addressing class imbalancing\n",
    "results_without_cv_rffs = template.run_algorithms(churndf_bal,\"Churn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "[22:26:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:26:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "============ LogReg ===========\n",
      "{'accuracy': 84.10030768435205, 'precision': 85.63483569407603, 'recall': 81.54478152826672, 'auc_val': 0.8410030544626217, 'f_score': 0.8245930239586865}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 82.33728927500258, 'precision': 76.87022486628439, 'recall': 92.47618554566164, 'auc_val': 0.8233720749637607, 'f_score': 0.8392557693911593}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 85.04361878167337, 'precision': 84.837303854767, 'recall': 84.88615655415201, 'auc_val': 0.8504359080554981, 'f_score': 0.840780286195192}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 84.10015254938463, 'precision': 83.46493247399623, 'recall': 84.56781942431145, 'auc_val': 0.8410030544626217, 'f_score': 0.8325660416728832}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 75.75592098458993, 'precision': 73.30627673165226, 'recall': 81.01894802236488, 'auc_val': 0.7575608303996686, 'f_score': 0.7695556046529428}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 80.12222049850037, 'precision': 79.23667553987805, 'recall': 80.56699109546491, 'auc_val': 0.8012215261958998, 'f_score': 0.7913906753984347}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 85.07774847450614, 'precision': 85.9738987900058, 'recall': 83.29524746324292, 'auc_val': 0.850778629115759, 'f_score': 0.8354613467632003}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 77.34759282242217, 'precision': 73.54245128082627, 'recall': 85.36141022986126, 'auc_val': 0.7734756160695796, 'f_score': 0.7897005070714036}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 83.69113920777741, 'precision': 85.03180760278897, 'recall': 81.52252019051564, 'auc_val': 0.8369124042244772, 'f_score': 0.8182625323999713}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 80.91693815285964, 'precision': 78.42903076857223, 'recall': 85.0441085110789, 'auc_val': 0.8091716711534479, 'f_score': 0.8141402915849152}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 83.52005119453925, 'precision': 81.86753748767237, 'recall': 85.81724994822945, 'auc_val': 0.835200869745289, 'f_score': 0.8347104103926248}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV only and with addressing class imbalancing\n",
    "results_cv = template.run_algorithms_cv(churndf_bal,\"Churn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure                                     15.839126\n",
      "MonthlyCharges                             12.716963\n",
      "Contract_Two year                           8.602325\n",
      "Contract_One year                           4.545012\n",
      "TechSupport_Yes                             3.870991\n",
      "Contract_Month-to-month                     3.514295\n",
      "PaperlessBilling_No                         3.208902\n",
      "Dependents_Yes                              2.744490\n",
      "OnlineSecurity_Yes                          2.697649\n",
      "InternetService_Fiber optic                 2.521541\n",
      "gender_Male                                 2.016974\n",
      "Partner_Yes                                 1.950253\n",
      "DeviceProtection_Yes                        1.888442\n",
      "Partner_No                                  1.822096\n",
      "OnlineBackup_Yes                            1.780603\n",
      "gender_Female                               1.772812\n",
      "PaymentMethod_Credit card (automatic)       1.723012\n",
      "PaymentMethod_Bank transfer (automatic)     1.722352\n",
      "PaperlessBilling_Yes                        1.702227\n",
      "PaymentMethod_Mailed check                  1.662099\n",
      "PaymentMethod_Electronic check              1.500136\n",
      "MultipleLines_No                            1.447768\n",
      "DeviceProtection_No                         1.359166\n",
      "OnlineBackup_No                             1.314057\n",
      "Dependents_No                               1.301458\n",
      "TechSupport_No                              1.290263\n",
      "InternetService_DSL                         1.258370\n",
      "SeniorCitizen                               1.224319\n",
      "StreamingMovies_No internet service         1.196546\n",
      "OnlineSecurity_No                           1.188521\n",
      "MultipleLines_Yes                           1.130529\n",
      "StreamingMovies_No                          1.073158\n",
      "StreamingTV_No                              0.944155\n",
      "StreamingMovies_Yes                         0.938084\n",
      "StreamingTV_No internet service             0.908379\n",
      "StreamingTV_Yes                             0.810260\n",
      "TechSupport_No internet service             0.671932\n",
      "InternetService_No                          0.665874\n",
      "PhoneService_Yes                            0.387704\n",
      "DeviceProtection_No internet service        0.376899\n",
      "MultipleLines_No phone service              0.278218\n",
      "PhoneService_No                             0.209809\n",
      "OnlineSecurity_No internet service          0.201356\n",
      "OnlineBackup_No internet service            0.020877\n",
      "dtype: float64\n",
      "Selected Features =['tenure', 'MonthlyCharges', 'Contract_Two year', 'Contract_One year', 'TechSupport_Yes', 'Contract_Month-to-month', 'PaperlessBilling_No']\n",
      "(8798, 45)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 79.88636363636363\n",
      "\n",
      " Precision of event Happening: \n",
      " 77.16371220020855\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.57142857142857\n",
      "\n",
      " AUC: \n",
      " 0.7991283292978208\n",
      "\n",
      " F-Score:\n",
      " 0.806979280261723\n",
      "\n",
      " Confusion Matrix: \n",
      " [[666 219]\n",
      " [135 740]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.1590909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.48560079443894\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.57142857142857\n",
      "\n",
      " AUC: \n",
      " 0.7720096852300241\n",
      "\n",
      " F-Score:\n",
      " 0.7863974495217855\n",
      "\n",
      " Confusion Matrix: \n",
      " [[618 267]\n",
      " [135 740]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 82.32954545454545\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.51948051948052\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.02857142857142\n",
      "\n",
      " AUC: \n",
      " 0.8234479418886199\n",
      "\n",
      " F-Score:\n",
      " 0.8271261812117844\n",
      "\n",
      " Confusion Matrix: \n",
      " [[705 180]\n",
      " [131 744]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.9090909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.94736842105263\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.0\n",
      "\n",
      " AUC: \n",
      " 0.8092655367231637\n",
      "\n",
      " F-Score:\n",
      " 0.8139534883720929\n",
      "\n",
      " Confusion Matrix: \n",
      " [[689 196]\n",
      " [140 735]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 74.48863636363636\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.64634146341463\n",
      "\n",
      " Recall of event Happening: \n",
      " 80.57142857142857\n",
      "\n",
      " AUC: \n",
      " 0.745230024213075\n",
      "\n",
      " F-Score:\n",
      " 0.7584722969338353\n",
      "\n",
      " Confusion Matrix: \n",
      " [[606 279]\n",
      " [170 705]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 78.97727272727273\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.66061293984109\n",
      "\n",
      " Recall of event Happening: \n",
      " 79.2\n",
      "\n",
      " AUC: \n",
      " 0.7897853107344632\n",
      "\n",
      " F-Score:\n",
      " 0.7892938496583144\n",
      "\n",
      " Confusion Matrix: \n",
      " [[697 188]\n",
      " [182 693]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 81.93181818181819\n",
      "\n",
      " Precision of event Happening: \n",
      " 81.9747416762342\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.6\n",
      "\n",
      " AUC: \n",
      " 0.8192994350282485\n",
      "\n",
      " F-Score:\n",
      " 0.81786941580756\n",
      "\n",
      " Confusion Matrix: \n",
      " [[728 157]\n",
      " [161 714]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 1 1 ... 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 76.13636363636364\n",
      "\n",
      " Precision of event Happening: \n",
      " 70.58823529411765\n",
      "\n",
      " Recall of event Happening: \n",
      " 89.14285714285714\n",
      "\n",
      " AUC: \n",
      " 0.7620984665052462\n",
      "\n",
      " F-Score:\n",
      " 0.7878787878787878\n",
      "\n",
      " Confusion Matrix: \n",
      " [[560 325]\n",
      " [ 95 780]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.22727272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 77.24922440537746\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.37142857142858\n",
      "\n",
      " AUC: \n",
      " 0.8025633575464083\n",
      "\n",
      " F-Score:\n",
      " 0.8110749185667753\n",
      "\n",
      " Confusion Matrix: \n",
      " [[665 220]\n",
      " [128 747]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Prediction Vector: \n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      "\n",
      " Accuracy: \n",
      " 79.43181818181819\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.63976945244957\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.8\n",
      "\n",
      " AUC: \n",
      " 0.7948474576271186\n",
      "\n",
      " F-Score:\n",
      " 0.8110647181628393\n",
      "\n",
      " Confusion Matrix: \n",
      " [[621 264]\n",
      " [ 98 777]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:26:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 82.04545454545455\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.68057080131723\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.0\n",
      "\n",
      " AUC: \n",
      " 0.8205649717514124\n",
      "\n",
      " F-Score:\n",
      " 0.8230683090705487\n",
      "\n",
      " Confusion Matrix: \n",
      " [[709 176]\n",
      " [140 735]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      "\n",
      " Accuracy: \n",
      " 79.43181818181819\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.63976945244957\n",
      "\n",
      " Recall of event Happening: \n",
      " 88.8\n",
      "\n",
      " AUC: \n",
      " 0.7948474576271186\n",
      "\n",
      " F-Score:\n",
      " 0.8110647181628393\n",
      "\n",
      " Confusion Matrix: \n",
      " [[621 264]\n",
      " [ 98 777]]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with RFFS and with addressing class imbalancing\n",
    "res_rffs = template.MachineLearningwithRFFS(churndf_bal,\"Churn\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure                                     13.541512\n",
      "MonthlyCharges                             13.058656\n",
      "Contract_Month-to-month                     5.805804\n",
      "OnlineSecurity_No                           5.775249\n",
      "PaperlessBilling_No                         4.499791\n",
      "Contract_One year                           3.964695\n",
      "OnlineSecurity_Yes                          3.680114\n",
      "Contract_Two year                           3.210732\n",
      "Partner_Yes                                 2.681092\n",
      "PaymentMethod_Credit card (automatic)       2.246605\n",
      "TechSupport_Yes                             2.233888\n",
      "OnlineBackup_Yes                            2.180396\n",
      "PaymentMethod_Bank transfer (automatic)     2.173260\n",
      "PaperlessBilling_Yes                        1.894088\n",
      "Partner_No                                  1.761447\n",
      "Dependents_Yes                              1.729577\n",
      "gender_Female                               1.729218\n",
      "DeviceProtection_No internet service        1.697240\n",
      "gender_Male                                 1.675385\n",
      "InternetService_Fiber optic                 1.603931\n",
      "SeniorCitizen                               1.581929\n",
      "PaymentMethod_Mailed check                  1.577136\n",
      "DeviceProtection_Yes                        1.477867\n",
      "PaymentMethod_Electronic check              1.451863\n",
      "DeviceProtection_No                         1.422281\n",
      "StreamingMovies_No internet service         1.374364\n",
      "StreamingMovies_No                          1.344059\n",
      "Dependents_No                               1.287818\n",
      "MultipleLines_No                            1.266335\n",
      "OnlineBackup_No                             1.226595\n",
      "StreamingTV_No                              1.101227\n",
      "TechSupport_No                              1.093724\n",
      "MultipleLines_Yes                           1.082051\n",
      "InternetService_DSL                         1.081346\n",
      "StreamingTV_Yes                             1.001679\n",
      "OnlineBackup_No internet service            0.991218\n",
      "StreamingMovies_Yes                         0.925663\n",
      "OnlineSecurity_No internet service          0.363437\n",
      "PhoneService_No                             0.333935\n",
      "PhoneService_Yes                            0.316772\n",
      "MultipleLines_No phone service              0.294170\n",
      "TechSupport_No internet service             0.143538\n",
      "InternetService_No                          0.063381\n",
      "StreamingTV_No internet service             0.054929\n",
      "dtype: float64\n",
      "Selected Features =['tenure', 'MonthlyCharges', 'Contract_Month-to-month', 'OnlineSecurity_No', 'PaperlessBilling_No', 'Contract_One year', 'OnlineSecurity_Yes', 'Contract_Two year']\n",
      "(8798, 45)\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "[22:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "============ LogReg ===========\n",
      "{'accuracy': 79.35986141276243, 'precision': 77.54983917102747, 'recall': 82.47520190515635, 'auc_val': 0.7935952060468006, 'f_score': 0.7972933646184923}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 79.37073378839591, 'precision': 75.33798518507326, 'recall': 87.29317664112652, 'auc_val': 0.7937059950300269, 'f_score': 0.8084709989518869}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 81.88314458578964, 'precision': 80.01578976070667, 'recall': 84.77112238558706, 'auc_val': 0.8188302443570098, 'f_score': 0.8211389800036836}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 80.90554866066812, 'precision': 78.4324231600152, 'recall': 85.0894077448747, 'auc_val': 0.8090551874094016, 'f_score': 0.8144144315140343}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 74.2782992036405, 'precision': 71.74922205985811, 'recall': 80.1095464899565, 'auc_val': 0.7427839614827085, 'f_score': 0.7569450775165361}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 79.17850863584651, 'precision': 78.60200402534471, 'recall': 79.95226755021744, 'auc_val': 0.7917860840753779, 'f_score': 0.7901994373946692}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 82.22455786534286, 'precision': 81.95742983780247, 'recall': 82.38496583143508, 'auc_val': 0.8222450300269207, 'f_score': 0.8188676223313776}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 75.90408780639156, 'precision': 71.36963659294392, 'recall': 86.42964381859598, 'auc_val': 0.7590391385379996, 'f_score': 0.7814052914822807}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 76.37112162581445, 'precision': 74.67765276070291, 'recall': 84.42995444191344, 'auc_val': 0.763708842410437, 'f_score': 0.7843943993405286}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 78.08659116764917, 'precision': 76.66680312473738, 'recall': 80.63315386208323, 'auc_val': 0.7808666390557052, 'f_score': 0.7855989995962794}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 81.73552073637397, 'precision': 80.16385564759874, 'recall': 84.08935597432182, 'auc_val': 0.8173545247463243, 'f_score': 0.8192987710851509}\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with CV and RFFS and with addressing class imbalancing\n",
    "res_rffs_cv = template.MachineLearningwithRFFS_CV(churndf_bal,\"Churn\", threshold=3,\n",
    "                                    algo_list=template.get_supported_algorithms())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without FS, REG and CV\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 83.97727272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.17200474495849\n",
      "\n",
      " Recall of event Happening: \n",
      " 82.05714285714286\n",
      "\n",
      " AUC: \n",
      " 0.8396642453591607\n",
      "\n",
      " F-Score:\n",
      " 0.8358556461001164\n",
      "\n",
      " Confusion Matrix: \n",
      " [[760 125]\n",
      " [157 718]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.85227272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 75.42533081285444\n",
      "\n",
      " Recall of event Happening: \n",
      " 91.2\n",
      "\n",
      " AUC: \n",
      " 0.8091073446327685\n",
      "\n",
      " F-Score:\n",
      " 0.825659596482152\n",
      "\n",
      " Confusion Matrix: \n",
      " [[625 260]\n",
      " [ 77 798]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.9090909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.5039637599094\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.28571428571429\n",
      "\n",
      " AUC: \n",
      " 0.8591121872477805\n",
      "\n",
      " F-Score:\n",
      " 0.8589306029579067\n",
      "\n",
      " Confusion Matrix: \n",
      " [[757 128]\n",
      " [120 755]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.51136363636364\n",
      "\n",
      " Precision of event Happening: \n",
      " 85.06787330316742\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.94285714285715\n",
      "\n",
      " AUC: \n",
      " 0.8551380145278451\n",
      "\n",
      " F-Score:\n",
      " 0.855031267765776\n",
      "\n",
      " Confusion Matrix: \n",
      " [[753 132]\n",
      " [123 752]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.02272727272728\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.18321392016377\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.71428571428572\n",
      "\n",
      " AUC: \n",
      " 0.760548829701372\n",
      "\n",
      " F-Score:\n",
      " 0.7721382289416848\n",
      "\n",
      " Confusion Matrix: \n",
      " [[623 262]\n",
      " [160 715]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 80.9090909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 80.38331454340474\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.48571428571428\n",
      "\n",
      " AUC: \n",
      " 0.8091234866828088\n",
      "\n",
      " F-Score:\n",
      " 0.8093076049943247\n",
      "\n",
      " Confusion Matrix: \n",
      " [[711 174]\n",
      " [162 713]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 85.56818181818183\n",
      "\n",
      " Precision of event Happening: \n",
      " 86.48648648648648\n",
      "\n",
      " Recall of event Happening: \n",
      " 84.11428571428571\n",
      "\n",
      " AUC: \n",
      " 0.8555996771589992\n",
      "\n",
      " F-Score:\n",
      " 0.8528389339513326\n",
      "\n",
      " Confusion Matrix: \n",
      " [[770 115]\n",
      " [139 736]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.8409090909091\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.79784102060843\n",
      "\n",
      " Recall of event Happening: \n",
      " 85.94285714285715\n",
      "\n",
      " AUC: \n",
      " 0.7788668280871671\n",
      "\n",
      " F-Score:\n",
      " 0.7940865892291447\n",
      "\n",
      " Confusion Matrix: \n",
      " [[618 267]\n",
      " [123 752]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 83.80681818181817\n",
      "\n",
      " Precision of event Happening: \n",
      " 81.8574514038877\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.62857142857143\n",
      "\n",
      " AUC: \n",
      " 0.838227602905569\n",
      "\n",
      " F-Score:\n",
      " 0.8417545807884509\n",
      "\n",
      " Confusion Matrix: \n",
      " [[717 168]\n",
      " [117 758]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "Prediction Vector: \n",
      " [0. 1. 1. ... 1. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 81.5340909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.70563674321504\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.17142857142858\n",
      "\n",
      " AUC: \n",
      " 0.8156029055690073\n",
      "\n",
      " F-Score:\n",
      " 0.822695035460993\n",
      "\n",
      " Confusion Matrix: \n",
      " [[681 204]\n",
      " [121 754]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 83.97727272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 82.12351029252439\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.62857142857143\n",
      "\n",
      " AUC: \n",
      " 0.8399225181598063\n",
      "\n",
      " F-Score:\n",
      " 0.8431590656284762\n",
      "\n",
      " Confusion Matrix: \n",
      " [[720 165]\n",
      " [117 758]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "Prediction Vector: \n",
      " [0. 1. 1. ... 1. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 81.5340909090909\n",
      "\n",
      " Precision of event Happening: \n",
      " 78.70563674321504\n",
      "\n",
      " Recall of event Happening: \n",
      " 86.17142857142858\n",
      "\n",
      " AUC: \n",
      " 0.8156029055690073\n",
      "\n",
      " F-Score:\n",
      " 0.822695035460993\n",
      "\n",
      " Confusion Matrix: \n",
      " [[681 204]\n",
      " [121 754]]\n",
      "============================== \n",
      "\n",
      "Results with Features Selection\n",
      "tenure                                     15.094303\n",
      "MonthlyCharges                             13.556623\n",
      "Contract_Month-to-month                     8.463045\n",
      "OnlineSecurity_Yes                          5.490732\n",
      "TechSupport_No                              3.524556\n",
      "TechSupport_Yes                             2.987346\n",
      "PaperlessBilling_No                         2.942459\n",
      "Contract_One year                           2.451411\n",
      "Dependents_Yes                              2.403432\n",
      "Partner_Yes                                 2.366795\n",
      "OnlineSecurity_No                           2.249967\n",
      "PaymentMethod_Credit card (automatic)       2.152248\n",
      "DeviceProtection_Yes                        1.999048\n",
      "Contract_Two year                           1.892364\n",
      "PaymentMethod_Bank transfer (automatic)     1.851036\n",
      "gender_Female                               1.845757\n",
      "gender_Male                                 1.766409\n",
      "PaperlessBilling_Yes                        1.760957\n",
      "OnlineBackup_Yes                            1.695517\n",
      "OnlineSecurity_No internet service          1.667009\n",
      "Partner_No                                  1.615611\n",
      "MultipleLines_No                            1.521140\n",
      "PaymentMethod_Electronic check              1.425976\n",
      "InternetService_Fiber optic                 1.423285\n",
      "PaymentMethod_Mailed check                  1.373650\n",
      "SeniorCitizen                               1.315355\n",
      "DeviceProtection_No                         1.245930\n",
      "StreamingTV_No                              1.217360\n",
      "Dependents_No                               1.123352\n",
      "MultipleLines_Yes                           1.120691\n",
      "StreamingMovies_Yes                         1.111482\n",
      "StreamingMovies_No                          1.029573\n",
      "OnlineBackup_No                             1.029471\n",
      "InternetService_DSL                         0.916357\n",
      "StreamingTV_Yes                             0.915665\n",
      "OnlineBackup_No internet service            0.722777\n",
      "InternetService_No                          0.652508\n",
      "TechSupport_No internet service             0.637089\n",
      "PhoneService_Yes                            0.440547\n",
      "MultipleLines_No phone service              0.319838\n",
      "StreamingTV_No internet service             0.310522\n",
      "PhoneService_No                             0.271181\n",
      "StreamingMovies_No internet service         0.077211\n",
      "DeviceProtection_No internet service        0.022415\n",
      "dtype: float64\n",
      "Selected Features =['tenure', 'MonthlyCharges', 'Contract_Month-to-month', 'OnlineSecurity_Yes']\n",
      "(8798, 45)\n",
      "============ LogReg ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 75.56818181818183\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.80490523968784\n",
      "\n",
      " Recall of event Happening: \n",
      " 76.68571428571428\n",
      "\n",
      " AUC: \n",
      " 0.7557449556093623\n",
      "\n",
      " F-Score:\n",
      " 0.7573363431151242\n",
      "\n",
      " Confusion Matrix: \n",
      " [[659 226]\n",
      " [204 671]]\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector: \n",
      " [0 1 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.38636363636363\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.31192660550458\n",
      "\n",
      " Recall of event Happening: \n",
      " 83.31428571428572\n",
      "\n",
      " AUC: \n",
      " 0.7741985472154964\n",
      "\n",
      " F-Score:\n",
      " 0.7855603448275862\n",
      "\n",
      " Confusion Matrix: \n",
      " [[633 252]\n",
      " [146 729]]\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.89772727272727\n",
      "\n",
      " Precision of event Happening: \n",
      " 76.64473684210526\n",
      "\n",
      " Recall of event Happening: \n",
      " 79.88571428571429\n",
      "\n",
      " AUC: \n",
      " 0.779089588377724\n",
      "\n",
      " F-Score:\n",
      " 0.7823167319529938\n",
      "\n",
      " Confusion Matrix: \n",
      " [[672 213]\n",
      " [176 699]]\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.5\n",
      "\n",
      " Precision of event Happening: \n",
      " 75.18401682439537\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.71428571428572\n",
      "\n",
      " AUC: \n",
      " 0.7752380952380953\n",
      "\n",
      " F-Score:\n",
      " 0.7831325301204819\n",
      "\n",
      " Confusion Matrix: \n",
      " [[649 236]\n",
      " [160 715]]\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 74.48863636363636\n",
      "\n",
      " Precision of event Happening: \n",
      " 72.28033472803347\n",
      "\n",
      " Recall of event Happening: \n",
      " 78.97142857142858\n",
      "\n",
      " AUC: \n",
      " 0.7451396287328491\n",
      "\n",
      " F-Score:\n",
      " 0.7547788093937738\n",
      "\n",
      " Confusion Matrix: \n",
      " [[620 265]\n",
      " [184 691]]\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 74.88636363636364\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.2441209406495\n",
      "\n",
      " Recall of event Happening: \n",
      " 75.77142857142857\n",
      "\n",
      " AUC: \n",
      " 0.748913640032284\n",
      "\n",
      " F-Score:\n",
      " 0.7499999999999999\n",
      "\n",
      " Confusion Matrix: \n",
      " [[655 230]\n",
      " [212 663]]\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "Prediction Vector: \n",
      " [0 0 1 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.67045454545455\n",
      "\n",
      " Precision of event Happening: \n",
      " 77.13963963963964\n",
      "\n",
      " Recall of event Happening: \n",
      " 78.28571428571428\n",
      "\n",
      " AUC: \n",
      " 0.7767393058918484\n",
      "\n",
      " F-Score:\n",
      " 0.7770845150311968\n",
      "\n",
      " Confusion Matrix: \n",
      " [[682 203]\n",
      " [190 685]]\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "Prediction Vector: \n",
      " [1 0 1 ... 1 1 1]\n",
      "\n",
      " Accuracy: \n",
      " 74.14772727272727\n",
      "\n",
      " Precision of event Happening: \n",
      " 71.42857142857143\n",
      "\n",
      " Recall of event Happening: \n",
      " 80.0\n",
      "\n",
      " AUC: \n",
      " 0.7418079096045198\n",
      "\n",
      " F-Score:\n",
      " 0.7547169811320756\n",
      "\n",
      " Confusion Matrix: \n",
      " [[605 280]\n",
      " [175 700]]\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 76.42045454545455\n",
      "\n",
      " Precision of event Happening: \n",
      " 73.71134020618557\n",
      "\n",
      " Recall of event Happening: \n",
      " 81.71428571428572\n",
      "\n",
      " AUC: \n",
      " 0.7645036319612591\n",
      "\n",
      " F-Score:\n",
      " 0.7750677506775068\n",
      "\n",
      " Confusion Matrix: \n",
      " [[630 255]\n",
      " [160 715]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 332\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "Prediction Vector: \n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 75.39772727272728\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.17943107221006\n",
      "\n",
      " Recall of event Happening: \n",
      " 77.4857142857143\n",
      "\n",
      " AUC: \n",
      " 0.7540952380952382\n",
      "\n",
      " F-Score:\n",
      " 0.7579653437674679\n",
      "\n",
      " Confusion Matrix: \n",
      " [[649 236]\n",
      " [197 678]]\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "[22:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Prediction Vector: \n",
      " [0 1 0 ... 1 1 0]\n",
      "\n",
      " Accuracy: \n",
      " 77.10227272727272\n",
      "\n",
      " Precision of event Happening: \n",
      " 75.05307855626327\n",
      "\n",
      " Recall of event Happening: \n",
      " 80.80000000000001\n",
      "\n",
      " AUC: \n",
      " 0.7712316384180791\n",
      "\n",
      " F-Score:\n",
      " 0.7782058337919647\n",
      "\n",
      " Confusion Matrix: \n",
      " [[650 235]\n",
      " [168 707]]\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "[LightGBM] [Info] Number of positive: 3524, number of negative: 3514\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 332\n",
      "[LightGBM] [Info] Number of data points in the train set: 7038, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500710 -> initscore=0.002842\n",
      "[LightGBM] [Info] Start training from score 0.002842\n",
      "Prediction Vector: \n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      "\n",
      " Accuracy: \n",
      " 75.39772727272728\n",
      "\n",
      " Precision of event Happening: \n",
      " 74.17943107221006\n",
      "\n",
      " Recall of event Happening: \n",
      " 77.4857142857143\n",
      "\n",
      " AUC: \n",
      " 0.7540952380952382\n",
      "\n",
      " F-Score:\n",
      " 0.7579653437674679\n",
      "\n",
      " Confusion Matrix: \n",
      " [[649 236]\n",
      " [197 678]]\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold cross validation\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "[22:33:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:33:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 412\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "============ LogReg ===========\n",
      "{'accuracy': 84.10030768435205, 'precision': 85.63483569407603, 'recall': 81.54478152826672, 'auc_val': 0.8410030544626217, 'f_score': 0.8245930239586865}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 82.33728927500258, 'precision': 76.87022486628439, 'recall': 92.47618554566164, 'auc_val': 0.8233720749637607, 'f_score': 0.8392557693911593}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 85.04361878167337, 'precision': 84.837303854767, 'recall': 84.88615655415201, 'auc_val': 0.8504359080554981, 'f_score': 0.840780286195192}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 84.10015254938463, 'precision': 83.46493247399623, 'recall': 84.56781942431145, 'auc_val': 0.8410030544626217, 'f_score': 0.8325660416728832}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 75.75592098458993, 'precision': 73.30627673165226, 'recall': 81.01894802236488, 'auc_val': 0.7575608303996686, 'f_score': 0.7695556046529428}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 80.22466128865446, 'precision': 79.45784657051445, 'recall': 80.40821080969144, 'auc_val': 0.8022468419962726, 'f_score': 0.7911517329810414}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 85.03233271279346, 'precision': 85.94795751547318, 'recall': 83.22696210395527, 'auc_val': 0.8503240836612136, 'f_score': 0.8347887856196579}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 77.34759282242217, 'precision': 73.54245128082627, 'recall': 85.36141022986126, 'auc_val': 0.7734756160695796, 'f_score': 0.7897005070714036}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 83.68008584134864, 'precision': 86.56060863689656, 'recall': 79.59065023814453, 'auc_val': 0.8367990267136053, 'f_score': 0.8109238630478199}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 80.91693815285964, 'precision': 78.42903076857223, 'recall': 85.0441085110789, 'auc_val': 0.8091716711534479, 'f_score': 0.8141402915849152}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 83.52005119453925, 'precision': 81.86753748767237, 'recall': 85.81724994822945, 'auc_val': 0.835200869745289, 'f_score': 0.8347104103926248}\n",
      "============================== \n",
      "\n",
      "Results with stratified kfold CV, FS\n",
      "tenure                                     16.530051\n",
      "MonthlyCharges                             12.993968\n",
      "Contract_Month-to-month                     5.975544\n",
      "OnlineSecurity_Yes                          4.741053\n",
      "InternetService_Fiber optic                 3.596694\n",
      "TechSupport_Yes                             3.505368\n",
      "Contract_Two year                           3.001855\n",
      "OnlineSecurity_No                           2.928139\n",
      "PaperlessBilling_No                         2.844471\n",
      "Contract_One year                           2.234487\n",
      "TechSupport_No                              2.124243\n",
      "PaperlessBilling_Yes                        2.026926\n",
      "PaymentMethod_Bank transfer (automatic)     1.901286\n",
      "OnlineBackup_Yes                            1.900711\n",
      "gender_Male                                 1.892089\n",
      "gender_Female                               1.844951\n",
      "PaymentMethod_Credit card (automatic)       1.836797\n",
      "Dependents_Yes                              1.795499\n",
      "Partner_Yes                                 1.766435\n",
      "Partner_No                                  1.696357\n",
      "MultipleLines_No                            1.623889\n",
      "PaymentMethod_Electronic check              1.572247\n",
      "InternetService_DSL                         1.554734\n",
      "PaymentMethod_Mailed check                  1.429994\n",
      "StreamingTV_No                              1.385421\n",
      "DeviceProtection_Yes                        1.382314\n",
      "StreamingMovies_No internet service         1.360331\n",
      "Dependents_No                               1.315850\n",
      "SeniorCitizen                               1.253233\n",
      "MultipleLines_Yes                           1.238865\n",
      "OnlineBackup_No                             1.207583\n",
      "DeviceProtection_No                         1.134318\n",
      "StreamingMovies_No                          1.091492\n",
      "StreamingMovies_Yes                         0.987646\n",
      "StreamingTV_No internet service             0.910281\n",
      "StreamingTV_Yes                             0.894483\n",
      "OnlineBackup_No internet service            0.837303\n",
      "OnlineSecurity_No internet service          0.324415\n",
      "InternetService_No                          0.294160\n",
      "PhoneService_Yes                            0.291433\n",
      "PhoneService_No                             0.262462\n",
      "MultipleLines_No phone service              0.201500\n",
      "TechSupport_No internet service             0.200708\n",
      "DeviceProtection_No internet service        0.108417\n",
      "dtype: float64\n",
      "Selected Features =['tenure', 'MonthlyCharges', 'Contract_Month-to-month']\n",
      "(8798, 45)\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "[22:35:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7918, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 3960, number of negative: 3959\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500063 -> initscore=0.000253\n",
      "[LightGBM] [Info] Start training from score 0.000253\n",
      "[LightGBM] [Info] Number of positive: 3959, number of negative: 3960\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330\n",
      "[LightGBM] [Info] Number of data points in the train set: 7919, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499937 -> initscore=-0.000253\n",
      "[LightGBM] [Info] Start training from score -0.000253\n",
      "============ LogReg ===========\n",
      "{'accuracy': 73.66436549798325, 'precision': 72.80540374089654, 'recall': 75.54017394905777, 'auc_val': 0.7366437150548768, 'f_score': 0.741449153711992}\n",
      "============================== \n",
      "\n",
      "============ KNN ===========\n",
      "{'accuracy': 77.3815156686317, 'precision': 74.57820329028308, 'recall': 83.06466142058397, 'auc_val': 0.7738149720439014, 'f_score': 0.7857780469372055}\n",
      "============================== \n",
      "\n",
      "============ GadientBoosting ===========\n",
      "{'accuracy': 75.97181714758506, 'precision': 74.28512914530263, 'recall': 79.44957548146614, 'auc_val': 0.7597178504866433, 'f_score': 0.7677637085979223}\n",
      "============================== \n",
      "\n",
      "============ AdaBoost ===========\n",
      "{'accuracy': 75.40349312234977, 'precision': 73.30630799655007, 'recall': 79.92710706150342, 'auc_val': 0.7540342203354732, 'f_score': 0.7646644581760585}\n",
      "============================== \n",
      "\n",
      "============ SVM ===========\n",
      "{'accuracy': 73.55078084600268, 'precision': 71.80426182857828, 'recall': 77.58614620004141, 'auc_val': 0.7355094222406297, 'f_score': 0.7457743052354046}\n",
      "============================== \n",
      "\n",
      "============ DecisionTree ===========\n",
      "{'accuracy': 74.73334884683007, 'precision': 74.62815797610986, 'recall': 74.90391385379996, 'auc_val': 0.7473309691447504, 'f_score': 0.7474892057308302}\n",
      "============================== \n",
      "\n",
      "============ RandomForest ===========\n",
      "{'accuracy': 77.56352776915917, 'precision': 76.9630127422228, 'recall': 78.6775212259267, 'auc_val': 0.775634448125906, 'f_score': 0.7777941090909414}\n",
      "============================== \n",
      "\n",
      "============ NaiveBayes ===========\n",
      "{'accuracy': 72.92574206226082, 'precision': 68.87653282602629, 'recall': 83.67788361979706, 'auc_val': 0.729256316007455, 'f_score': 0.7555345607313487}\n",
      "============================== \n",
      "\n",
      "============ MultiLayerPerceptron ===========\n",
      "{'accuracy': 74.07355983038578, 'precision': 73.32030160204397, 'recall': 75.9247773866225, 'auc_val': 0.7407221992130876, 'f_score': 0.7449198547831851}\n",
      "============================== \n",
      "\n",
      "============ LightGbm ===========\n",
      "{'accuracy': 72.35744389285345, 'precision': 68.14478870929273, 'recall': 83.99611720853179, 'auc_val': 0.723573203561814, 'f_score': 0.7523745286487225}\n",
      "============================== \n",
      "\n",
      "============ XgBoost ===========\n",
      "{'accuracy': 76.57428379356706, 'precision': 74.51770855414819, 'recall': 80.81336715676123, 'auc_val': 0.7657418720231932, 'f_score': 0.7752541089421822}\n",
      "============================== \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4a189b48698d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#all results and with addressing class imbalancing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m res_all=template.all_CImbalance(churndf_bal,\"Churn\", algo_list=template.get_supported_algorithms(),\n\u001b[0m\u001b[0;32m      3\u001b[0m                                 threshold=5, feature_list=[]) \n",
      "\u001b[1;32m~\\Desktop\\Machine Learning\\Assignment8\\New folder\\TempML1.py\u001b[0m in \u001b[0;36mall_CImbalance\u001b[1;34m(df, label_col, algo_list, threshold, cross_valid_method, feature_list)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results with stratified kfold CV, FS\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[0mR4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMachineLearningwithRFFS_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_supported_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mR1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "#all results and with addressing class imbalancing\n",
    "res_all=template.all_CImbalance(churndf_bal,\"Churn\", algo_list=template.get_supported_algorithms(),\n",
    "                                threshold=5, feature_list=[]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
